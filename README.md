# ğŸ“š ArXiv è®ºæ–‡æ—¥æŠ¥

> æ¯å¤©è‡ªåŠ¨æ›´æ–°ï¼Œå…³æ³¨ **åŒ–å­¦å¤§æ¨¡å‹, è´¨è°±ç»“æ„æ¨ç†** ç›¸å…³çš„æœ€æ–°è®ºæ–‡

## æ›´æ–°æ—¶é—´
â° 2026-03-01 01:25:28

## ğŸ“… 2026-03-01 (ä»Šæ—¥æœ€æ–°)

**ç›¸å…³è®ºæ–‡æ•°ï¼š52**

### 1. [Zatom-1: A Multimodal Flow Foundation Model for 3D Molecules and Materials](https://arxiv.org/abs/2602.22251)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22251`](https://arxiv.org/abs/2602.22251)
- ğŸ‘¥ ä½œè€…: Alex Morehead, Miruna Cretu, Antonia Panescu ç­‰17äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22251.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªç”¨äº3Dåˆ†å­å’Œææ–™çš„ç»Ÿä¸€åŸºç¡€æ¨¡å‹ï¼ˆZatom-1ï¼‰ï¼Œè¿™ç›´æ¥å±äºâ€œåŒ–å­¦å¤§æ¨¡å‹â€çš„ç ”ç©¶èŒƒç•´ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†Zatom-1ï¼Œä¸€ä¸ªç”¨äº3Dåˆ†å­å’Œææ–™çš„ç»Ÿä¸€åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ˜¯ä¸€ä¸ªTransformerï¼Œé€šè¿‡å¤šæ¨¡æ€æµåŒ¹é…ç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œè”åˆå»ºæ¨¡ç¦»æ•£åŸå­ç±»å‹å’Œè¿ç»­3Då‡ ä½•ç»“æ„ã€‚è¿™ç§æ–¹æ³•æ”¯æŒå¯æ‰©å±•çš„é¢„è®­ç»ƒï¼Œå¹¶èƒ½å¤Ÿå®ç°å¿«é€Ÿç¨³å®šçš„é‡‡æ ·ã€‚Zatom-1å°†è”åˆç”Ÿæˆå¼é¢„è®­ç»ƒä½œä¸ºä¸‹æ¸¸å¤šä»»åŠ¡é¢„æµ‹ï¼ˆå¦‚æ€§è´¨ã€èƒ½é‡å’ŒåŠ›ï¼‰çš„é€šç”¨åˆå§‹åŒ–ã€‚è¯¥æ¨¡å‹åœ¨ç”Ÿæˆå’Œé¢„æµ‹åŸºå‡†æµ‹è¯•ä¸­åŒ¹é…æˆ–è¶…è¶Šäº†ä¸“é—¨çš„åŸºçº¿æ¨¡å‹ï¼ŒåŒæ—¶å°†ç”Ÿæˆæ¨ç†æ—¶é—´å‡å°‘äº†ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚å®éªŒè¡¨æ˜ï¼Œè”åˆç”Ÿæˆå¼é¢„è®­ç»ƒåœ¨åŒ–å­¦é¢†åŸŸä¹‹é—´å®ç°äº†æ­£å‘çš„é¢„æµ‹è¿ç§»ï¼šåœ¨é¢„è®­ç»ƒä¸­å»ºæ¨¡ææ–™å¯ä»¥æé«˜åˆ†å­æ€§è´¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒæ˜¯å¼€å‘ä¸€ä¸ªé€šç”¨çš„3DåŒ–å­¦æ¨¡å‹ï¼Œç›´æ¥ä¸åŒ–å­¦ä¿¡æ¯å­¦ä¸­çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€ä¸»é¢˜ç›¸å…³ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

General-purpose 3D chemical modeling encompasses molecules and materials, requiring both generative and predictive capabilities. However, most existing AI approaches are optimized for a single domain (molecules or materials) and a single task (generation or prediction), which limits representation sharing and transfer. We introduce Zatom-1, the first foundation model that unifies generative and predictive learning of 3D molecules and materials. Zatom-1 is a Transformer trained with a multimodal flow matching objective that jointly models discrete atom types and continuous 3D geometries. This approach supports scalable pretraining with predictable gains as model capacity increases, while enabling fast and stable sampling. We use joint generative pretraining as a universal initialization for downstream multi-task prediction of properties, energies, and forces. Empirically, Zatom-1 matches or outperforms specialized baselines on both generative and predictive benchmarks, while reducing the generative inference time by more than an order of magnitude. Our experiments demonstrate positive predictive transfer between chemical domains from joint generative pretraining: modeling materials during pretraining improves molecular property prediction accuracy.

</details>

---

### 2. [AR&D: A Framework for Retrieving and Describing Concepts for Interpreting AudioLLMs](https://arxiv.org/abs/2602.22253)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22253`](https://arxiv.org/abs/2602.22253)
- ğŸ‘¥ ä½œè€…: Townim Faisal Chowdhury, Ta Duc Huy, Siqi Pan ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22253.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªç”¨äºç†è§£å¤§å‹æ¨¡å‹ï¼ˆAudioLLMsï¼‰å†…éƒ¨è¡¨ç¤ºçš„å¯è§£é‡Šæ€§æ¡†æ¶ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯éŸ³é¢‘ï¼Œä½†å…¶æ–¹æ³•è®ºï¼ˆç¨€ç–è‡ªç¼–ç å™¨ã€ç‰¹å¾è§£è€¦ï¼‰ä¸åŒ–å­¦ä¿¡æ¯å­¦å’Œè´¨è°±åˆ†æä¸­ç†è§£å’Œæ„å»ºâ€œåŒ–å­¦å¤§æ¨¡å‹â€ã€è¿›è¡Œâ€œè´¨è°±ç»“æ„æ¨ç†â€æ‰€ä¾èµ–çš„è¡¨ç¤ºå­¦ä¹ å’Œå¯è§£é‡Šæ€§æŠ€æœ¯ç›´æ¥ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

å°½ç®¡å¤§å‹éŸ³é¢‘-è¯­è¨€æ¨¡å‹åœ¨éŸ³é¢‘æ„ŸçŸ¥ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å†…éƒ¨æœºåˆ¶ä»ç„¶ä¸é€æ˜ã€‚ç¼ºä¹å¯è§£é‡Šæ€§çš„ä¸€ä¸ªä¸»è¦å› ç´ æ˜¯æ¨¡å‹ä¸­çš„å•ä¸ªç¥ç»å…ƒç»å¸¸å¯¹å¤šä¸ªä¸ç›¸å…³çš„æ¦‚å¿µäº§ç”Ÿå“åº”ã€‚æœ¬æ–‡å¼•å…¥äº†ç¬¬ä¸€ä¸ªç”¨äºAudioLLMsçš„æœºåˆ¶å¯è§£é‡Šæ€§æ¡†æ¶ï¼Œåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨å°†å¤šä¹‰æ¿€æ´»åˆ†è§£ä¸ºå•ä¹‰ç‰¹å¾ã€‚è¯¥æµç¨‹é€šè¿‡è‡ªåŠ¨æ ‡æ³¨è¯†åˆ«ä»£è¡¨æ€§éŸ³é¢‘ç‰‡æ®µã€åˆ†é…æœ‰æ„ä¹‰çš„åç§°ï¼Œå¹¶é€šè¿‡äººå·¥è¯„ä¼°å’Œå¼•å¯¼æ¥éªŒè¯æ¦‚å¿µã€‚å®éªŒè¡¨æ˜ï¼ŒAudioLLMsç¼–ç äº†ç»“æ„åŒ–å’Œå¯è§£é‡Šçš„ç‰¹å¾ï¼Œä»è€Œå¢å¼ºäº†é€æ˜åº¦å’Œå¯æ§æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºé«˜é£é™©é¢†åŸŸçš„å¯ä¿¡éƒ¨ç½²å¥ å®šäº†åŸºç¡€ï¼Œå¹¶æ”¯æŒæœªæ¥æ‰©å±•åˆ°æ›´å¤§çš„æ¨¡å‹ã€å¤šè¯­è¨€éŸ³é¢‘å’Œæ›´ç»†ç²’åº¦çš„å‰¯è¯­è¨€ç‰¹å¾ã€‚è™½ç„¶è®ºæ–‡ä¸»è¦å…³æ³¨éŸ³é¢‘æ¨¡å‹ï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•è®ºâ€”â€”ä½¿ç”¨ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œç‰¹å¾è§£è€¦å’Œå¯è§£é‡Šæ€§åˆ†æâ€”â€”æ˜¯æœºå™¨å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§çš„é€šç”¨æŠ€æœ¯ã€‚è¿™ç§å¯¹æ¨¡å‹å†…éƒ¨è¡¨ç¤ºè¿›è¡Œè§£è€¦å’Œåˆ†æçš„æ€è·¯ï¼Œä¸åŒ–å­¦ä¿¡æ¯å­¦ä¸­ç†è§£â€œåŒ–å­¦å¤§æ¨¡å‹â€å†…éƒ¨å·¥ä½œæœºåˆ¶ã€è¿›è¡Œâ€œè´¨è°±ç»“æ„æ¨ç†â€ç­‰ä»»åŠ¡èƒŒåçš„è¡¨ç¤ºå­¦ä¹ åŸç†é«˜åº¦ç›¸å…³ï¼Œæä¾›äº†æ–¹æ³•è®ºä¸Šçš„å€Ÿé‰´ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Despite strong performance in audio perception tasks, large audio-language models (AudioLLMs) remain opaque to interpretation. A major factor behind this lack of interpretability is that individual neurons in these models frequently activate in response to several unrelated concepts. We introduce the first mechanistic interpretability framework for AudioLLMs, leveraging sparse autoencoders (SAEs) to disentangle polysemantic activations into monosemantic features. Our pipeline identifies representative audio clips, assigns meaningful names via automated captioning, and validates concepts through human evaluation and steering. Experiments show that AudioLLMs encode structured and interpretable features, enhancing transparency and control. This work provides a foundation for trustworthy deployment in high-stakes domains and enables future extensions to larger models, multilingual audio, and more fine-grained paralinguistic features. Project URL: this https URL

</details>

---

### 3. [Multi-Level Causal Embeddings](https://arxiv.org/abs/2602.22287)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22287`](https://arxiv.org/abs/2602.22287)
- ğŸ‘¥ ä½œè€…: Willem Schooltink, Fabio Massimo Zennaro
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22287.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å› æœè¡¨ç¤ºå­¦ä¹ å’Œæ¨¡å‹æŠ½è±¡çš„ç†è®ºæ¡†æ¶ã€‚è¿™å¯¹äºæ„å»ºèƒ½å¤Ÿè¿›è¡Œå¯é ç§‘å­¦æ¨ç†ï¼ˆå¦‚â€œè´¨è°±ç»“æ„æ¨ç†â€ï¼‰çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€å…·æœ‰é‡è¦çš„æ–¹æ³•è®ºå’Œç†è®ºåŸºç¡€ï¼Œå› ä¸ºå› æœç†è§£æ˜¯ç§‘å­¦æ¨¡å‹çš„æ ¸å¿ƒã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

å› æœæ¨¡å‹çš„æŠ½è±¡åŒ–å…è®¸å¯¹æ¨¡å‹è¿›è¡Œç²—åŒ–ï¼ŒåŒæ—¶ä¿ç•™å› æœæ•ˆåº”å…³ç³»ã€‚è™½ç„¶æŠ½è±¡åŒ–å…³æ³¨ä¸¤ä¸ªæ¨¡å‹ä¹‹é—´çš„å…³ç³»ï¼Œä½†æœ¬æ–‡ç ”ç©¶äº†ä¸€ä¸ªå› æœåµŒå…¥æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å…è®¸å¤šä¸ªè¯¦ç»†æ¨¡å‹è¢«æ˜ å°„åˆ°ä¸€ä¸ªæ›´ç²—ç²’åº¦å› æœæ¨¡å‹çš„å­ç³»ç»Ÿä¸­ã€‚æˆ‘ä»¬å°†å› æœåµŒå…¥å®šä¹‰ä¸ºæŠ½è±¡åŒ–çš„æ³›åŒ–ï¼Œå¹¶æå‡ºäº†ä¸€ç§å¹¿ä¹‰çš„ä¸€è‡´æ€§æ¦‚å¿µã€‚é€šè¿‡å®šä¹‰ä¸€ä¸ªå¤šåˆ†è¾¨ç‡è¾¹é™…é—®é¢˜ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å› æœåµŒå…¥å¯¹äºç»Ÿè®¡è¾¹é™…é—®é¢˜å’Œå› æœè¾¹é™…é—®é¢˜çš„ç›¸å…³æ€§ï¼›æ­¤å¤–ï¼Œæˆ‘ä»¬è¯´æ˜äº†å…¶åœ¨åˆå¹¶æ¥è‡ªä¸åŒè¡¨ç¤ºæ¨¡å‹çš„æ•°æ®é›†æ–¹é¢çš„å®é™…ç”¨é€”ã€‚è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒæ˜¯ç ”ç©¶å› æœè¡¨ç¤ºå’Œæ¨¡å‹æŠ½è±¡/åµŒå…¥çš„ç†è®ºæ¡†æ¶ã€‚è™½ç„¶ä¸ç›´æ¥åº”ç”¨åŒ–å­¦æˆ–è´¨è°±ï¼Œä½†å…¶å…³äºä»æ•°æ®ä¸­å­¦ä¹ ç»“æ„åŒ–ã€å¯è§£é‡Šçš„å› æœè¡¨ç¤ºçš„ç†è®ºï¼Œæ˜¯æ„å»ºèƒ½å¤Ÿè¿›è¡Œå¯é æ¨ç†ï¼ˆå¦‚è´¨è°±ç»“æ„æ¨ç†ï¼‰çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„é‡è¦ç†è®ºåŸºç¡€ã€‚ç†è§£æ•°æ®èƒŒåçš„å› æœç»“æ„å¯¹äºæé«˜æ¨¡å‹åœ¨ç§‘å­¦å‘ç°ä»»åŠ¡ä¸­çš„æ³›åŒ–æ€§å’Œå¯è§£é‡Šæ€§è‡³å…³é‡è¦ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Abstractions of causal models allow for the coarsening of models such that relations of cause and effect are preserved. Whereas abstractions focus on the relation between two models, in this paper we study a framework for causal embeddings which enable multiple detailed models to be mapped into sub-systems of a coarser causal model. We define causal embeddings as a generalization of abstraction, and present a generalized notion of consistency. By defining a multi-resolution marginal problem, we showcase the relevance of causal embeddings for both the statistical marginal problem and the causal marginal problem; furthermore, we illustrate its practical use in merging datasets coming from models with different representations.

</details>

---

### 4. [Disentangling Shared and Target-Enriched Topics via Background-Contrastive Non-negative Matrix Factorization](https://arxiv.org/abs/2602.22387)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22387`](https://arxiv.org/abs/2602.22387)
- ğŸ‘¥ ä½œè€…: Yixuan Li, Archer Y. Yang, Yue Li
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22387.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§æ–°çš„æ•°æ®åˆ†æå’Œç‰¹å¾æå–æ–¹æ³•ï¼ˆèƒŒæ™¯å¯¹æ¯”éè´ŸçŸ©é˜µåˆ†è§£ï¼‰ï¼Œç”¨äºä»é«˜ç»´æ•°æ®ä¸­åˆ†ç¦»ç›®æ ‡ä¿¡å·ã€‚è¿™ç§æ–¹æ³•ä¸åŒ–å­¦ä¿¡æ¯å­¦å’Œè´¨è°±åˆ†æä¸­å¤„ç†å¤æ‚æ•°æ®é›†ï¼ˆå¦‚è´¨è°±æ•°æ®ï¼‰ä»¥è¿›è¡Œâ€œè´¨è°±ç»“æ„æ¨ç†â€çš„æ ¸å¿ƒæ•°æ®åˆ†æä»»åŠ¡ç›´æ¥ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

é«˜ç»´æ•°æ®ä¸­æ„Ÿå…´è¶£çš„ç”Ÿç‰©ä¿¡å·å¸¸å¸¸è¢«è·¨æ¡ä»¶å…±äº«çš„ä¸»å¯¼å˜å¼‚æ‰€æ©ç›–ã€‚è¿™ç§å˜å¼‚æºäºåŸºçº¿ç”Ÿç‰©ç»“æ„æˆ–æŠ€æœ¯æ•ˆåº”ï¼Œä¼šé˜»ç¢æ ‡å‡†é™ç»´æ–¹æ³•è§£ææ¡ä»¶ç‰¹å¼‚æ€§ç»“æ„ã€‚æŒ‘æˆ˜åœ¨äºè¿™äº›æ··æ‚ä¸»é¢˜é€šå¸¸æ˜¯æœªçŸ¥çš„ï¼Œå¹¶ä¸ç”Ÿç‰©ä¿¡å·æ··åˆåœ¨ä¸€èµ·ã€‚ç°æœ‰çš„èƒŒæ™¯æ ¡æ­£æ–¹æ³•è¦ä¹ˆæ— æ³•æ‰©å±•åˆ°é«˜ç»´åº¦ï¼Œè¦ä¹ˆä¸å¯è§£é‡Šã€‚æˆ‘ä»¬å¼•å…¥äº†èƒŒæ™¯å¯¹æ¯”éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆBCNMFï¼‰ï¼Œå®ƒé€šè¿‡ä½¿ç”¨å…±äº«çš„éè´ŸåŸºè”åˆåˆ†è§£ç›®æ ‡æ•°æ®é›†å’ŒåŒ¹é…çš„èƒŒæ™¯ï¼Œå¹¶åœ¨æŠ‘åˆ¶èƒŒæ™¯è¡¨è¾¾ç»“æ„çš„å¯¹æ¯”ç›®æ ‡ä¸‹ï¼Œæå–ç›®æ ‡å¯Œé›†çš„æ½œåœ¨ä¸»é¢˜ã€‚è¿™ç§æ–¹æ³•äº§ç”Ÿåœ¨ç‰¹å¾çº§åˆ«å¯ç›´æ¥è§£é‡Šçš„éè´Ÿæˆåˆ†ï¼Œå¹¶æ˜ç¡®éš”ç¦»ç›®æ ‡ç‰¹å¼‚æ€§å˜å¼‚ã€‚BCNMFé€šè¿‡é«˜æ•ˆçš„ä¹˜æ³•æ›´æ–°ç®—æ³•å­¦ä¹ ï¼Œè¯¥ç®—æ³•é€šè¿‡çŸ©é˜µä¹˜æ³•å®ç°ï¼Œä½¿å…¶åœ¨GPUç¡¬ä»¶ä¸Šé«˜åº¦é«˜æ•ˆï¼Œå¹¶ä¸”é€šè¿‡ç±»ä¼¼äºæ·±åº¦å­¦ä¹ æ–¹æ³•çš„å°æ‰¹é‡è®­ç»ƒå¯æ‰©å±•åˆ°å¤§æ•°æ®ã€‚åœ¨æ¨¡æ‹Ÿå’Œå¤šæ ·åŒ–çš„ç”Ÿç‰©æ•°æ®é›†ä¸Šï¼ŒBCNMFæ­ç¤ºäº†ä¼ ç»Ÿæ–¹æ³•æ‰€æ©ç›–çš„ä¿¡å·ï¼ŒåŒ…æ‹¬æ­»åæŠ‘éƒå¤§è„‘å•ç»†èƒRNA-seqä¸­ä¸ç–¾ç—…ç›¸å…³çš„ç¨‹åºã€å°é¼ ä¸­ä¸åŸºå› å‹ç›¸å…³çš„è›‹ç™½è´¨è¡¨è¾¾æ¨¡å¼ã€ç™½è¡€ç—…ä¸­æ²»ç–—ç‰¹å¼‚æ€§çš„è½¬å½•å˜åŒ–ä»¥åŠç™Œç—‡ç»†èƒç³»ä¸­TP53ä¾èµ–çš„è¯ç‰©ååº”ã€‚è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒæ˜¯å¼€å‘ä¸€ç§æ–°çš„é™ç»´å’Œç‰¹å¾æå–æ–¹æ³•ï¼Œç”¨äºä»é«˜ç»´ç”Ÿç‰©æ•°æ®ä¸­åˆ†ç¦»ç‰¹å®šä¿¡å·ã€‚è¯¥æ–¹æ³•ï¼ˆéè´ŸçŸ©é˜µåˆ†è§£çš„å˜ä½“ï¼‰æ˜¯åŒ–å­¦ä¿¡æ¯å­¦ï¼ˆå¦‚åˆ†æè´¨è°±æ•°æ®ã€åˆ†å­æè¿°ç¬¦ï¼‰å’Œè´¨è°±åˆ†æï¼ˆå¦‚ä»å¤æ‚è°±å›¾ä¸­æå–åŒ–åˆç‰©ç‰¹å¾ï¼‰ä¸­å¸¸ç”¨çš„æ•°æ®åˆ†ææŠ€æœ¯çš„æ ¸å¿ƒã€‚è®ºæ–‡æå‡ºçš„â€œèƒŒæ™¯å¯¹æ¯”â€æ€æƒ³å¯¹äºå¤„ç†è´¨è°±æ•°æ®ä¸­çš„åŸºçº¿å™ªå£°å’ŒèƒŒæ™¯å¹²æ‰°å…·æœ‰ç›´æ¥å€Ÿé‰´æ„ä¹‰ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Biological signals of interest in high-dimensional data are often masked by dominant variation shared across conditions. This variation, arising from baseline biological structure or technical effects, can prevent standard dimensionality reduction methods from resolving condition-specific structure. The challenge is that these confounding topics are often unknown and mixed with biological signals. Existing background correction methods are either unscalable to high dimensions or not interpretable. We introduce background contrastive Non-negative Matrix Factorization (\model), which extracts target-enriched latent topics by jointly factorizing a target dataset and a matched background using shared non-negative bases under a contrastive objective that suppresses background-expressed structure. This approach yields non-negative components that are directly interpretable at the feature level, and explicitly isolates target-specific variation. \model is learned by an efficient multiplicative update algorithm via matrix multiplication such that it is highly efficient on GPU hardware and scalable to big data via minibatch training akin to deep learning approach. Across simulations and diverse biological datasets, \model reveals signals obscured by conventional methods, including disease-associated programs in postmortem depressive brain single-cell RNA-seq, genotype-linked protein expression patterns in mice, treatment-specific transcriptional changes in leukemia, and TP53-dependent drug responses in cancer cell lines.

</details>

---

### 5. [A Reduced Order Model approach for First-Principles Molecular Dynamics Computations](https://arxiv.org/abs/2602.22390)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22390`](https://arxiv.org/abs/2602.22390)
- ğŸ‘¥ ä½œè€…: Siu Wun Cheung, Youngsoo Choi, Jean-Luc Fattebert ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22390.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘æ•°æ®é©±åŠ¨çš„é™é˜¶æ¨¡å‹æ¥åŠ é€Ÿç¬¬ä¸€æ€§åŸç†åˆ†å­åŠ¨åŠ›å­¦è®¡ç®—ã€‚è¿™å±äºè®¡ç®—åŒ–å­¦å’ŒåŒ–å­¦ä¿¡æ¯å­¦ä¸­æ„å»ºé«˜æ•ˆâ€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆåŸºäºç‰©ç†çš„æ¨¡å‹ï¼‰çš„æ ¸å¿ƒæ–¹æ³•å­¦ï¼Œä¸åˆ©ç”¨æœºå™¨å­¦ä¹ åŠ é€Ÿé‡å­åŒ–å­¦è®¡ç®—çš„ç ”ç©¶ä¸»é¢˜ç›´æ¥ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

ä¸ºäº†åˆ©ç”¨ç¬¬ä¸€æ€§åŸç†åˆ†å­åŠ¨åŠ›å­¦æ¯ä¸€æ­¥è®¡ç®—å‡ºçš„ç”µå­ç»“æ„ä¹‹é—´çš„å†—ä½™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç”¨äºKohn-Shamå¯†åº¦æ³›å‡½ç†è®ºçš„æ•°æ®é©±åŠ¨å»ºæ¨¡æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»•è¿‡äº†ç”µå­æ³¢å‡½æ•°çš„æ˜¾å¼ä¼˜åŒ–ã€‚æˆ‘ä»¬é¢„å…ˆé‡‡æ ·å…·æœ‰ä»£è¡¨æ€§çš„åŸå­æ„å‹ï¼Œå¹¶æ„å»ºä¸€ä¸ªä½ç»´åŸºï¼Œè¯¥åŸºèƒ½æœ‰æ•ˆè¿‘ä¼¼ç”µå­ç»“æ„å­ç©ºé—´ã€‚éšåï¼Œæˆ‘ä»¬åœ¨ç”µå­å•ç²’å­å¯†åº¦çŸ©é˜µçš„ç›´æ¥æ±‚è§£å™¨ä¸­é‡‡ç”¨è¿™ä¸ªçº¦åŒ–åŸºï¼Œä»è€Œèƒ½å¤Ÿåœ¨æ— éœ€è¿­ä»£æ³¢å‡½æ•°ä¼˜åŒ–çš„æƒ…å†µä¸‹é«˜æ•ˆç¡®å®šåŸºæ€ã€‚æˆ‘ä»¬åœ¨æ°´åˆ†å­çš„Born-Oppenheimeråˆ†å­åŠ¨åŠ›å­¦ä¸­è¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¡¨æ˜æ‰€å¾—æ¨¡æ‹Ÿå‡†ç¡®å†ç°äº†ä»å®Œæ•´ç¬¬ä¸€æ€§åŸç†åˆ†å­åŠ¨åŠ›å­¦è·å¾—çš„å…³é”®ç»“æ„ç‰¹æ€§ï¼Œå¦‚é”®é•¿å’Œé”®è§’ã€‚è¿™é¡¹å·¥ä½œçªå‡ºäº†æ•°æ®é©±åŠ¨æ–¹æ³•ä¸ºç¬¬ä¸€æ€§åŸç†æ¨¡æ‹Ÿå¼€å‘é«˜æ•ˆç”µå­ç»“æ„æ±‚è§£å™¨çš„æ½œåŠ›ã€‚è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒæ˜¯ä½¿ç”¨é™é˜¶æ¨¡å‹ï¼ˆROMï¼‰å’Œæ•°æ®é©±åŠ¨æ–¹æ³•åŠ é€Ÿç¬¬ä¸€æ€§åŸç†è®¡ç®—ã€‚è¿™å±äºè®¡ç®—åŒ–å­¦é¢†åŸŸçš„å‰æ²¿æ–¹æ³•å­¦ï¼Œæ˜¯æ„å»ºæ›´é«˜æ•ˆã€æ›´å¿«é€Ÿçš„â€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆç‰¹åˆ«æ˜¯åŸºäºç‰©ç†åŸç†çš„æ¨¡å‹ï¼‰çš„å…³é”®æŠ€æœ¯ã€‚è™½ç„¶ä¸ç›´æ¥æ¶‰åŠè´¨è°±ï¼Œä½†å…¶åŠ é€Ÿé‡å­åŒ–å­¦è®¡ç®—çš„æ–¹æ³•å¯¹åŒ–å­¦ä¿¡æ¯å­¦è‡³å…³é‡è¦ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

To leverage the redundancy between the electronic structure computed at each step of first-principles molecular dynamics, we present a data-driven modeling framework for Kohn-Sham Density Functional Theory that bypasses the explicit optimization of electronic wavefunctions. We sample a priori representative atomic configurations and construct a low-dimensional basis that efficiently approximates the electronic structure subspace. Subsequently, we employ this reduced basis in a direct solver for the electronic single particle density matrix, thereby enabling the efficient determination of ground state without iterative wavefunction optimization. We demonstrate the efficacy of our approach in a Born-Oppenheimer molecular dynamics of a water molecule, showing that the resulting simulations accurately reproduce key structural properties, such as bond lengths and bond angle, obtained from full first-principles molecular dynamics. This work highlights the potential of data-driven approaches to develop efficient electronic structure solvers for first-principles simulations.

</details>

---

### 6. [MolFM-Lite: Multi-Modal Molecular Property Prediction with Conformer Ensemble Attention and Cross-Modal Fusion](https://arxiv.org/abs/2602.22405)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22405`](https://arxiv.org/abs/2602.22405)
- ğŸ‘¥ ä½œè€…: Syed Omer Shah, Mohammed Maqsood Ahmed, Danish Mohiuddin Mohammed ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22405.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªæ•´åˆ1Dã€2Dã€3Dåˆ†å­è¡¨ç¤ºçš„å¤šæ¨¡æ€æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆMolFM-Liteï¼‰ï¼Œè¿™ç›´æ¥å±äºâ€œåŒ–å­¦å¤§æ¨¡å‹â€çš„ç ”ç©¶èŒƒç•´ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†MolFM-Liteï¼Œä¸€ä¸ªç”¨äºåˆ†å­æ€§è´¨é¢„æµ‹çš„å¤šæ¨¡æ€æ¨¡å‹ã€‚å®ƒè”åˆç¼–ç SELFIESåºåˆ—ï¼ˆ1Dï¼‰ã€åˆ†å­å›¾ï¼ˆ2Dï¼‰å’Œæ„è±¡ä½“é›†åˆï¼ˆ3Dï¼‰ï¼Œå¹¶é€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›è¿›è¡Œèåˆã€‚è¯¥æ¨¡å‹çš„æ ¸å¿ƒè´¡çŒ®åŒ…æ‹¬æ„è±¡ä½“é›†åˆæ³¨æ„åŠ›æœºåˆ¶å’Œè·¨æ¨¡æ€èåˆå±‚ã€‚è™½ç„¶è®ºæ–‡ä¸»è¦å…³æ³¨åˆ†å­æ€§è´¨é¢„æµ‹ï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•â€”â€”æ•´åˆå¤šæ¨¡æ€åˆ†å­è¡¨ç¤ºï¼ˆåŒ…æ‹¬3Dç»“æ„ï¼‰å¹¶è¿›è¡Œè·¨æ¨¡æ€ä¿¡æ¯å…±äº«â€”â€”ä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„ä¸»é¢˜é«˜åº¦ç›¸å…³ã€‚MolFM-Liteä»£è¡¨äº†ä¸€ç§æ„å»ºèƒ½å¤Ÿå¤„ç†å¤æ‚ã€å¤šç»´åº¦åŒ–å­¦ä¿¡æ¯çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå³åŒ–å­¦å¤§æ¨¡å‹ï¼‰çš„åŠªåŠ›ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Most machine learning models for molecular property prediction rely on a single molecular representation (either a sequence, a graph, or a 3D structure) and treat molecular geometry as static. We present MolFM-Lite, a multi-modal model that jointly encodes SELFIES sequences (1D), molecular graphs (2D), and conformer ensembles (3D) through cross-attention fusion, while conditioning predictions on experimental context via Feature-wise Linear Modulation (FiLM). Our main methodological contributions are: (1) a conformer ensemble attention mechanism that combines learnable attention with Boltzmann-weighted priors over multiple RDKit-generated conformers, capturing the thermodynamic distribution of molecular shapes; and (2) a cross-modal fusion layer where each modality can attend to others, enabling complementary information sharing. We evaluate on four MoleculeNet scaffold-split benchmarks using our model's own splits, and report all baselines re-evaluated under the same protocol. Comprehensive ablation studies across all four datasets confirm that each architectural component contributes independently, with tri-modal fusion providing 7-11% AUC improvement over single-modality baselines and conformer ensembles adding approximately 2% over single-conformer variants. Pre-training on ZINC250K (~250K molecules) using cross-modal contrastive and masked-atom objectives enables effective weight initialization at modest compute cost. We release all code, trained models, and data splits to support reproducibility.

</details>

---

### 7. [Revisiting Chebyshev Polynomial and Anisotropic RBF Models for Tabular Regression](https://arxiv.org/abs/2602.22422)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22422`](https://arxiv.org/abs/2602.22422)
- ğŸ‘¥ ä½œè€…: Luciano Gerber, Huw Lloyd
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22422.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡å¼€å‘å¹¶å‘å¸ƒäº†ç”¨äºè¡¨æ ¼å›å½’çš„scikit-learnå…¼å®¹æ¨¡å‹åŒ…ï¼ˆå¦‚å„å‘å¼‚æ€§RBFç½‘ç»œã€åˆ‡æ¯”é›ªå¤«å›å½’å™¨ï¼‰ï¼Œè¿™äº›å·¥å…·å’Œä»£ç èµ„æºå¯ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦é¢†åŸŸçš„åˆ†å­æ€§è´¨é¢„æµ‹ç­‰ä»»åŠ¡ï¼Œå±äºâ€œåŒ–å­¦å¤§æ¨¡å‹â€æ„å»ºçš„æ•°æ®å¤„ç†æˆ–åŸºç¡€æ¨¡å‹ç»„ä»¶ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡é‡æ–°å®¡è§†äº†åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼å›å½’å’Œå„å‘å¼‚æ€§å¾„å‘åŸºå‡½æ•°ï¼ˆRBFï¼‰ç½‘ç»œåœ¨è¡¨æ ¼å›å½’ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚ä½œè€…å¼€å‘äº†å„å‘å¼‚æ€§RBFç½‘ç»œã€å²­æ­£åˆ™åŒ–åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼å›å½’å™¨ä»¥åŠå¹³æ»‘æ ‘æ··åˆæ¨¡å‹ï¼ˆChebyshev model treeï¼‰ï¼Œå¹¶å°†å®ƒä»¬ä½œä¸ºscikit-learnå…¼å®¹çš„åŒ…å‘å¸ƒã€‚è®ºæ–‡å¯¹è¿™äº›å¹³æ»‘åŸºæ¨¡å‹ä¸æ ‘é›†æˆã€é¢„è®­ç»ƒTransformerç­‰åŸºçº¿æ¨¡å‹åœ¨55ä¸ªå›å½’æ•°æ®é›†ä¸Šè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚è™½ç„¶è®ºæ–‡ä¸»é¢˜æ˜¯é€šç”¨çš„è¡¨æ ¼å›å½’ï¼Œä½†å…¶æ ¸å¿ƒè´¡çŒ®æ˜¯å‘å¸ƒäº†ä¸€ç³»åˆ—æ–°çš„ã€å¯å¤ç”¨çš„å›å½’æ¨¡å‹ï¼ˆå·¥å…·ï¼‰ï¼Œè¿™äº›æ¨¡å‹åœ¨åŒ–å­¦ä¿¡æ¯å­¦ç­‰é¢†åŸŸï¼ˆä½œä¸ºè¡¨æ ¼æ•°æ®çš„ä¸€ç§ï¼‰çš„å®šé‡æ„æ•ˆå…³ç³»ï¼ˆQSARï¼‰å»ºæ¨¡ç­‰ä»»åŠ¡ä¸­å…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Smooth-basis models such as Chebyshev polynomial regressors and radial basis function (RBF) networks are well established in numerical analysis. Their continuously differentiable prediction surfaces suit surrogate optimisation, sensitivity analysis, and other settings where the response varies gradually with inputs. Despite these properties, smooth models seldom appear in tabular regression, where tree ensembles dominate. We ask whether they can compete, benchmarking models across 55 regression datasets organised by application domain. We develop an anisotropic RBF network with data-driven centre placement and gradient-based width optimisation, a ridge-regularised Chebyshev polynomial regressor, and a smooth-tree hybrid (Chebyshev model tree); all three are released as scikit-learn-compatible packages. We benchmark these against tree ensembles, a pre-trained transformer, and standard baselines, evaluating accuracy alongside generalisation behaviour. The transformer ranks first on accuracy across a majority of datasets, but its GPU dependence, inference latency, and dataset-size limits constrain deployment in the CPU-based settings common across applied science and industry. Among CPU-viable models, smooth models and tree ensembles are statistically tied on accuracy, but the former tend to exhibit tighter generalisation gaps. We recommend routinely including smooth-basis models in the candidate pool, particularly when downstream use benefits from tighter generalisation and gradually varying predictions.

</details>

---

### 8. [Predicting Known Vulnerabilities from Attack Descriptions Using Sentence Transformers](https://arxiv.org/abs/2602.22433)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22433`](https://arxiv.org/abs/2602.22433)
- ğŸ‘¥ ä½œè€…: Refat Othman
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22433.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘åŸºäºå¥å­Transformerçš„è¯­ä¹‰ç›¸ä¼¼æ€§æ–¹æ³•ï¼Œç”¨äºä»æ–‡æœ¬æè¿°æ¨ç†å‡ºå¯¹åº”çš„ç»“æ„åŒ–å®ä½“ï¼ˆæ¼æ´ï¼‰ã€‚è¿™ç§æ–¹æ³•è®ºä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­ä»è´¨è°±æ•°æ®æˆ–æè¿°æ¨ç†å‡ºåˆ†å­ç»“æ„çš„ä»»åŠ¡åœ¨æ ¸å¿ƒé€»è¾‘ä¸Šç›´æ¥ç›¸å…³ï¼Œéƒ½æ˜¯è·¨æ¨¡æ€æˆ–è·¨è¡¨ç¤ºçš„æ¨ç†é—®é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºTransformerå¥å­åµŒå…¥çš„æ–¹æ³•ï¼Œç”¨äºä»ç½‘ç»œæ”»å‡»çš„è‡ªç„¶è¯­è¨€æè¿°ä¸­é¢„æµ‹å·²çŸ¥æ¼æ´ï¼ˆCVEï¼‰ã€‚ä½œè€…è¯„ä¼°äº†14ç§æœ€å…ˆè¿›çš„Transformeræ¨¡å‹åœ¨å››ç§æ”»å‡»æè¿°ç±»å‹ä¸Šçš„æ€§èƒ½ï¼Œå¹¶å®ç°äº†VULDATå·¥å…·ï¼Œç”¨äºè‡ªåŠ¨å°†æ”»å‡»é“¾æ¥åˆ°æ¼æ´ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯åˆ©ç”¨è¯­ä¹‰å‘é‡è¡¨ç¤ºè¿›è¡ŒåŸºäºç›¸ä¼¼æ€§çš„æ’åºå’Œæ¨èã€‚è™½ç„¶è®ºæ–‡ä¸»é¢˜æ˜¯ç½‘ç»œå®‰å…¨ï¼Œä½†å…¶æ ¸å¿ƒæŠ€æœ¯â€”â€”ä½¿ç”¨å¥å­Transformerå°†æ–‡æœ¬æè¿°ç¼–ç ä¸ºè¯­ä¹‰å‘é‡å¹¶è¿›è¡Œç›¸ä¼¼æ€§åŒ¹é…â€”â€”ä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­å¯èƒ½ç”¨åˆ°çš„ã€å°†è´¨è°±ç‰¹å¾æˆ–æè¿°ä¸å·²çŸ¥åŒ–åˆç‰©ç»“æ„æ•°æ®åº“è¿›è¡ŒåŒ¹é…çš„æ€è·¯åœ¨æ–¹æ³•è®ºä¸Šé«˜åº¦ç›¸ä¼¼ã€‚è¿™ç§æ–‡æœ¬/æè¿°åˆ°ç»“æ„åŒ–æ ‡è¯†ï¼ˆæ¼æ´ID/åŒ–åˆç‰©ç»“æ„ï¼‰çš„æ˜ å°„æ¡†æ¶å…·æœ‰å€Ÿé‰´æ„ä¹‰ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Modern infrastructures rely on software systems that remain vulnerable to cyberattacks. These attacks frequently exploit vulnerabilities documented in repositories such as MITRE's Common Vulnerabilities and Exposures (CVE). However, Cyber Threat Intelligence resources, including MITRE ATT&CK and CVE, provide only partial coverage of attack-vulnerability relationships. Attack information often appears before vulnerabilities are formally linked, creating the need for automated methods that infer likely vulnerabilities directly from attack descriptions. This thesis addresses the problem of predicting known vulnerabilities from natural-language descriptions of cyberattacks. We develop transformer-based sentence embedding methods that encode attack and vulnerability descriptions into semantic vector representations, enabling similarity-based ranking and recommendation. Fourteen state-of-the-art transformer models were evaluated across four attack description types (Tactic, Technique, Procedure, and Attack Pattern). Results show that Technique descriptions in MITRE ATT&CK provide the strongest predictive signal. The multi-qa-mpnet-base-dot-v1 (MMPNet) model achieved the best performance due to its hybrid pre-training and optimization for semantic similarity. The approach was implemented in the VULDAT tool, which automatically links attacks to vulnerabilities. Manual validation revealed previously undocumented relationships in MITRE repositories. Evaluation on unseen cyberattack reports demonstrates that the models generalize beyond curated datasets and support proactive vulnerability awareness.

</details>

---

### 9. [MammoWise: Multi-Model Local RAG Pipeline for Mammography Report Generation](https://arxiv.org/abs/2602.22462)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22462`](https://arxiv.org/abs/2602.22462)
- ğŸ‘¥ ä½œè€…: Raiyan Jahangir, Nafiz Imtiaz Khan, Amritanand Sudheerkumar ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22462.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2å’Œé—´æ¥æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡æå‡ºäº†ä¸€ä¸ªé›†æˆäº†VLMã€RAGå’Œå¾®è°ƒæŠ€æœ¯çš„æœ¬åœ°å¤šæ¨¡å‹æµç¨‹æ¡†æ¶ï¼ˆMammoWiseï¼‰ï¼Œå¹¶å‘å¸ƒäº†ç›¸å…³å®ç°ã€‚è¿™ä¸ºæ„å»ºç”¨äºç§‘å­¦æ•°æ®ï¼ˆå¦‚è´¨è°±å›¾åƒï¼‰åˆ†æçš„å¤šæ¨¡æ€AIç³»ç»Ÿæä¾›äº†å¯å‚è€ƒçš„å·¥å…·é“¾å’Œæ¶æ„èŒƒä¾‹ã€‚å…¶æ ¸å¿ƒä»»åŠ¡ï¼ˆä»å›¾åƒç”Ÿæˆè§£é‡Šæ€§æŠ¥å‘Š/åˆ†ç±»ï¼‰ä¹Ÿä¸â€œè´¨è°±ç»“æ„æ¨ç†â€çš„ç›®æ ‡ï¼ˆä»è°±å›¾ç”Ÿæˆç»“æ„ä¿¡æ¯ï¼‰åœ¨å½¢å¼ä¸Šç±»ä¼¼ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†MammoWiseï¼Œä¸€ä¸ªç”¨äºä¹³è…ºXå…‰æ£€æŸ¥æŠ¥å‘Šç”Ÿæˆå’Œå¤šé¡¹åˆ†ç±»çš„æœ¬åœ°å¤šæ¨¡å‹æµç¨‹ã€‚å®ƒæ”¯æŒä»»ä½•é€šè¿‡Ollamaæ‰˜ç®¡çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œå¹¶æ”¯æŒé›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œæ€ç»´é“¾æç¤ºï¼Œè¿˜å¯é€‰æ‹©ä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œå¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€‚è®ºæ–‡åœ¨VinDr-Mammoå’ŒDMIDæ•°æ®é›†ä¸Šè¯„ä¼°äº†MedGemmaã€LLaVA-Medå’ŒQwen2.5-VLç­‰æ¨¡å‹ï¼Œæ¶‰åŠæŠ¥å‘Šè´¨é‡ã€BI-RADSåˆ†ç±»ã€ä¹³è…ºå¯†åº¦å’Œå…³é”®å‘ç°ç­‰ä»»åŠ¡ã€‚MammoWiseæä¾›äº†ä¸€ä¸ªå®ç”¨ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äºåœ¨ç»Ÿä¸€ä¸”å¯å¤ç°çš„å·¥ä½œæµç¨‹ä¸­éƒ¨ç½²æœ¬åœ°VLMsã€‚è™½ç„¶åº”ç”¨äºåŒ»å­¦å½±åƒï¼Œä½†å…¶æ ¸å¿ƒæ¡†æ¶â€”â€”æ•´åˆå¤šæ¨¡æ€VLMã€RAGå’Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆQLoRAï¼‰ä»¥å®Œæˆä»å›¾åƒåˆ°ç»“æ„åŒ–æŠ¥å‘Š/åˆ†ç±»çš„ç”Ÿæˆä»»åŠ¡â€”â€”å±•ç¤ºäº†æ„å»ºé¢†åŸŸä¸“ç”¨å¤šæ¨¡æ€AIç³»ç»Ÿï¼ˆå¯è§†ä¸ºä¸€ç§ç‰¹å®šé¢†åŸŸçš„â€œåŒ–å­¦å¤§æ¨¡å‹â€é›å½¢ï¼‰çš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œå¯¹æ„å»ºç”¨äºè´¨è°±å›¾åƒåˆ†ææˆ–å…‰è°±è§£é‡Šçš„ç±»ä¼¼ç³»ç»Ÿå…·æœ‰å‚è€ƒä»·å€¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Screening mammography is high volume, time sensitive, and documentation heavy. Radiologists must translate subtle visual findings into consistent BI-RADS assessments, breast density categories, and structured narrative reports. While recent Vision Language Models (VLMs) enable image-to-text reporting, many rely on closed cloud systems or tightly coupled architectures that limit privacy, reproducibility, and adaptability. We present MammoWise, a local multi-model pipeline that transforms open source VLMs into mammogram report generators and multi-task classifiers. MammoWise supports any Ollama-hosted VLM and mammography dataset, and enables zero-shot, few-shot, and Chain-of-Thought prompting, with optional multimodal Retrieval Augmented Generation (RAG) using a vector database for case-specific context. We evaluate MedGemma, LLaVA-Med, and Qwen2.5-VL on VinDr-Mammo and DMID datasets, assessing report quality (BERTScore, ROUGE-L), BI-RADS classification, breast density, and key findings. Report generation is consistently strong and improves with few-shot prompting and RAG. Classification is feasible but sensitive to model and dataset choice. Parameter-efficient fine-tuning (QLoRA) of MedGemma improves reliability, achieving BI-RADS accuracy of 0.7545, density accuracy of 0.8840, and calcification accuracy of 0.9341 while preserving report quality. MammoWise provides a practical and extensible framework for deploying local VLMs for mammography reporting within a unified and reproducible workflow.

</details>

---

### 10. [Mapping the Landscape of Artificial Intelligence in Life Cycle Assessment Using Large Language Models](https://arxiv.org/abs/2602.22500)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22500`](https://arxiv.org/abs/2602.22500)
- ğŸ‘¥ ä½œè€…: Anastasija Mensikova, Donna M. Rizzo, Kathryn Hinkelman
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22500.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†3ï¼šè®ºæ–‡æ˜¯ä¸€ç¯‡åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè¾…åŠ©çš„ç»¼è¿°æ€§æ–‡ç« ï¼Œç³»ç»Ÿæ€§åœ°å›é¡¾å’Œå±•æœ›äº†äººå·¥æ™ºèƒ½ï¼ˆåŒ…æ‹¬æœºå™¨å­¦ä¹ å’Œå¤§è¯­è¨€æ¨¡å‹ï¼‰åœ¨ç”Ÿå‘½å‘¨æœŸè¯„ä¼°ï¼ˆLCAï¼‰é¢†åŸŸçš„æ•´åˆã€è¶‹åŠ¿å’Œæœªæ¥æ–¹å‘ã€‚è¿™å±äºå¯¹AIåœ¨ç§‘å­¦é¢†åŸŸåº”ç”¨çš„ç»¼è¿°ï¼Œä¸å¹¿ä¹‰çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆä½œä¸ºç§‘å­¦AIçš„ä¸€éƒ¨åˆ†ï¼‰çš„è®¨è®ºç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡å¯¹äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åœ¨ç”Ÿå‘½å‘¨æœŸè¯„ä¼°ï¼ˆLCAï¼‰ä¸­çš„æ•´åˆç ”ç©¶è¿›è¡Œäº†è¯¦ç»†ç»¼è¿°ã€‚ä½œè€…åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¾…åŠ©æ–‡æœ¬æŒ–æ˜æ–¹æ³•ï¼Œç»“åˆä¼ ç»Ÿæ–‡çŒ®ç»¼è¿°æŠ€æœ¯ï¼Œè¯†åˆ«äº†AI-LCAäº¤å‰é¢†åŸŸçš„å½“å‰è¶‹åŠ¿ã€æ–°å…´ä¸»é¢˜å’Œæœªæ¥æ–¹å‘ã€‚åˆ†æè¡¨æ˜ï¼Œéšç€LCAç ”ç©¶çš„æ‰©å±•ï¼ŒAIæŠ€æœ¯çš„é‡‡ç”¨æ€¥å‰§å¢é•¿ï¼Œå¹¶æ˜æ˜¾è½¬å‘LLMé©±åŠ¨çš„æ–¹æ³•ã€‚è®ºæ–‡å¼•å…¥äº†ä¸€ä¸ªåŠ¨æ€æœ‰æ•ˆçš„æ¡†æ¶ï¼Œèƒ½å¤Ÿæ•æ‰è¯¥é¢†åŸŸçš„é«˜å±‚ç ”ç©¶è¶‹åŠ¿å’Œç»†å¾®çš„æ¦‚å¿µæ¨¡å¼ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†LLMè¾…åŠ©æ–¹æ³•åœ¨æ”¯æŒå¤§è§„æ¨¡ã€å¯å¤ç°çš„è·¨é¢†åŸŸæ–‡çŒ®ç»¼è¿°æ–¹é¢çš„æ½œåŠ›ã€‚è™½ç„¶ä¸»é¢˜æ˜¯LCAï¼Œä½†è®ºæ–‡æœ¬èº«æ˜¯ä¸€ç¯‡å…³äºAIåœ¨ç‰¹å®šç§‘å­¦é¢†åŸŸï¼ˆLCAï¼‰åº”ç”¨çš„ç»¼è¿°ï¼Œå¹¶ä¸”é‡ç‚¹ä»‹ç»äº†LLMåœ¨è¯¥ç»¼è¿°è¿‡ç¨‹ä¸­çš„ä½œç”¨ã€‚è¿™ç¬¦åˆâ€œç»¼è¿°å±•æœ›ç›¸å…³â€çš„æ ‡å‡†ï¼Œå› ä¸ºå®ƒç³»ç»Ÿåœ°å›é¡¾äº†AIï¼ˆåŒ…æ‹¬æœºå™¨å­¦ä¹ å’Œå¤§è¯­è¨€æ¨¡å‹ï¼‰åœ¨ä¸€ä¸ªé‡è¦çš„ç¯å¢ƒç§‘å­¦å’Œå·¥ç¨‹é¢†åŸŸçš„åº”ç”¨ç°çŠ¶ä¸æœªæ¥ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Integration of artificial intelligence (AI) into life cycle assessment (LCA) has accelerated in recent years, with numerous studies successfully adapting machine learning algorithms to support various stages of LCA. Despite this rapid development, comprehensive and broad synthesis of AI-LCA research remains limited. To address this gap, this study presents a detailed review of published work at the intersection of AI and LCA, leveraging large language models (LLMs) to identify current trends, emerging themes, and future directions. Our analyses reveal that as LCA research continues to expand, the adoption of AI technologies has grown dramatically, with a noticeable shift toward LLM-driven approaches, continued increases in ML applications, and statistically significant correlations between AI approaches and corresponding LCA stages. By integrating LLM-based text-mining methods with traditional literature review techniques, this study introduces a dynamic and effective framework capable of capturing both high-level research trends and nuanced conceptual patterns (themes) across the field. Collectively, these findings demonstrate the potential of LLM-assisted methodologies to support large-scale, reproducible reviews across broad research domains, while also evaluating pathways for computationally-efficient LCA in the context of rapidly developing AI technologies. In doing so, this work helps LCA practitioners incorporate state-of-the-art tools and timely insights into environmental assessments that can enhance the rigor and quality of sustainability-driven decisions and decision-making processes.

</details>

---

### 11. [LUMOS: Democratizing SciML Workflows with L0-Regularized Learning for Unified Feature and Parameter Adaptation](https://arxiv.org/abs/2602.22537)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22537`](https://arxiv.org/abs/2602.22537)
- ğŸ‘¥ ä½œè€…: Shouwei Gao, Xu Zheng, Dongsheng Luo ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22537.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºäº†LUMOSæ¡†æ¶ï¼Œå¹¶è¿›è¡Œäº†å¹¿æ³›çš„è¯„ä¼°ã€‚è¯¥æ¡†æ¶æä¾›äº†ç”¨äºç§‘å­¦æœºå™¨å­¦ä¹ æ¨¡å‹è‡ªåŠ¨åŒ–è®¾è®¡ï¼ˆç‰¹åˆ«æ˜¯ç‰¹å¾é€‰æ‹©å’Œæ¨¡å‹å‰ªæï¼‰çš„å·¥å…·å’Œæ–¹æ³•ï¼Œè¿™äº›å·¥å…·å¯ç›´æ¥åº”ç”¨äºæ„å»ºæ›´é«˜æ•ˆã€æ›´ç²¾ç®€çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼Œå±äºé‡è¦çš„æ–¹æ³•å­¦èµ„æºã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†LUMOSï¼Œä¸€ä¸ªåŸºäºL0æ­£åˆ™åŒ–å­¦ä¹ çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç»Ÿä¸€ç‰¹å¾é€‰æ‹©å’Œæ¨¡å‹å‰ªææ¥ democratize ç§‘å­¦æœºå™¨å­¦ä¹ ï¼ˆSciMLï¼‰æ¨¡å‹çš„è®¾è®¡ã€‚LUMOSé‡‡ç”¨åŠéšæœºé—¨æ§å’Œé‡å‚æ•°åŒ–æŠ€æœ¯ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€é€‰æ‹©ä¿¡æ¯ç‰¹å¾å¹¶å‰ªæå†—ä½™å‚æ•°ï¼Œå‡å°‘å¯¹æ‰‹åŠ¨è°ƒä¼˜çš„ä¾èµ–ï¼ŒåŒæ—¶ä¿æŒé¢„æµ‹å‡†ç¡®æ€§ã€‚è®ºæ–‡åœ¨åŒ…æ‹¬å®‡å®™å­¦å’Œåˆ†å­ç§‘å­¦åœ¨å†…çš„13ä¸ªä¸åŒçš„SciMLå·¥ä½œè´Ÿè½½ä¸Šè¯„ä¼°äº†LUMOSï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒLUMOSå¹³å‡å®ç°äº†71.45%çš„å‚æ•°å‡å°‘å’Œ6.4å€çš„æ¨ç†åŠ é€Ÿã€‚è¯¥æ¡†æ¶ç›´æ¥é’ˆå¯¹SciMLæ¨¡å‹è®¾è®¡ä¸­çš„è‡ªåŠ¨åŒ–æŒ‘æˆ˜ï¼Œå…¶æ–¹æ³•ï¼ˆç‰¹å¾é€‰æ‹©ã€æ¨¡å‹å‹ç¼©ï¼‰å¯¹äºæ„å»ºé«˜æ•ˆã€å¯è§£é‡Šçš„â€œåŒ–å­¦å¤§æ¨¡å‹â€å…·æœ‰ç›´æ¥çš„å·¥å…·ä»·å€¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

The rapid growth of scientific machine learning (SciML) has accelerated discovery across diverse domains, yet designing effective SciML models remains a challenging task. In practice, building such models often requires substantial prior knowledge and manual expertise, particularly in determining which input features to use and how large the model should be. We introduce LUMOS, an end-to-end framework based on L0-regularized learning that unifies feature selection and model pruning to democratize SciML model design. By employing semi-stochastic gating and reparameterization techniques, LUMOS dynamically selects informative features and prunes redundant parameters during training, reducing the reliance on manual tuning while maintaining predictive accuracy. We evaluate LUMOS across 13 diverse SciML workloads, including cosmology and molecular sciences, and demonstrate its effectiveness and generalizability. Experiments on 13 SciML models show that LUMOS achieves 71.45% parameter reduction and a 6.4x inference speedup on average. Furthermore, Distributed Data Parallel (DDP) training on up to eight GPUs confirms the scalability of

</details>

---

### 12. [DisQ-HNet: A Disentangled Quantized Half-UNet for Interpretable Multimodal Image Synthesis Applications to Tau-PET Synthesis from T1 and FLAIR MRI](https://arxiv.org/abs/2602.22545)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22545`](https://arxiv.org/abs/2602.22545)
- ğŸ‘¥ ä½œè€…: Agamdeep S. Chopra, Caitlin Neher, Tianyi Ren ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22545.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯æå‡ºä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€å›¾åƒåˆæˆæ¡†æ¶ï¼ˆDisQ-HNetï¼‰ï¼Œå…¶å…³é”®æŠ€æœ¯ï¼ˆPIDå¼•å¯¼çš„æ½œåœ¨è§£è€¦ã€é‡åŒ–è¡¨ç¤ºã€å¯è§£é‡Šæ€§åˆ†æï¼‰ç›´æ¥æ¶‰åŠå¤šæ¨¡æ€æ•°æ®çš„ä¿¡æ¯èåˆä¸å½’å› ã€‚è¿™ä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­æ•´åˆå¤šç§å…‰è°±æ•°æ®ä»¥æ¨ç†åˆ†å­ç»“æ„ï¼Œå¹¶ç†è§£ä¸åŒæ•°æ®æºè´¡çŒ®çš„æ ¸å¿ƒæŒ‘æˆ˜é«˜åº¦ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†DisQ-HNetï¼ˆDQHï¼‰ï¼Œä¸€ä¸ªç”¨äºä»é…å¯¹çš„T1åŠ æƒå’ŒFLAIR MRIåˆæˆtau-PETå›¾åƒçš„æ¡†æ¶ï¼Œå¹¶æ­ç¤ºäº†æ¯ç§æ¨¡æ€å¯¹é¢„æµ‹çš„è´¡çŒ®ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ï¼ˆiï¼‰åŸºäºéƒ¨åˆ†ä¿¡æ¯åˆ†è§£ï¼ˆPIDï¼‰æŒ‡å¯¼çš„ã€çŸ¢é‡é‡åŒ–çš„ç¼–ç å™¨ï¼Œå°†æ½œåœ¨ä¿¡æ¯åˆ’åˆ†ä¸ºå†—ä½™ã€ç‹¬ç‰¹å’Œäº’è¡¥æˆåˆ†ï¼›ï¼ˆiiï¼‰Half-UNetè§£ç å™¨ï¼Œä½¿ç”¨ä»¥ç»“æ„è¾¹ç¼˜çº¿ç´¢ä¸ºæ¡ä»¶çš„ä¼ªè·³è·ƒè¿æ¥æ¥ä¿ç•™è§£å‰–ç»†èŠ‚ã€‚è¯¥æ¡†æ¶åœ¨å¤šä¸ªåŸºçº¿æ¨¡å‹ä¸Šä¿æŒäº†é‡å»ºä¿çœŸåº¦ï¼Œå¹¶æ›´å¥½åœ°ä¿ç•™äº†ç”¨äºä¸‹æ¸¸é˜¿å°”èŒ¨æµ·é»˜ç—…ä»»åŠ¡çš„ç›¸å…³ä¿¡å·ã€‚è™½ç„¶åº”ç”¨äºåŒ»å­¦å½±åƒï¼Œä½†å…¶æ ¸å¿ƒåˆ›æ–°â€”â€”ä½¿ç”¨PIDæŒ‡å¯¼çš„é‡åŒ–ç¼–ç å™¨æ¥è§£è€¦å¤šæ¨¡æ€ä¿¡æ¯è´¡çŒ®ï¼Œå¹¶å®ç°å¯è§£é‡Šçš„åˆæˆâ€”â€”ä¸ºå¤šæ¨¡æ€æ•°æ®èåˆå’Œè§£é‡Šæä¾›äº†å…ˆè¿›çš„æ–¹æ³•è®ºã€‚è¿™ç§æ–¹æ³•å¯¹äºâ€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­å¯èƒ½æ¶‰åŠçš„å¤šè°±å›¾ï¼ˆå¦‚MS/MS, IRï¼‰èåˆä»¥æ¨æ–­ç»“æ„ï¼Œä»¥åŠå¢å¼ºæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œå…·æœ‰é‡è¦çš„å‚è€ƒä»·å€¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Tau positron emission tomography (tau-PET) provides an in vivo marker of Alzheimer's disease pathology, but cost and limited availability motivate MRI-based alternatives. We introduce DisQ-HNet (DQH), a framework that synthesizes tau-PET from paired T1-weighted and FLAIR MRI while exposing how each modality contributes to the prediction. The method combines (i) a Partial Information Decomposition (PID)-guided, vector-quantized encoder that partitions latent information into redundant, unique, and complementary components, and (ii) a Half-UNet decoder that preserves anatomical detail using pseudo-skip connections conditioned on structural edge cues rather than direct encoder feature reuse. Across multiple baselines (VAE, VQ-VAE, and UNet), DisQ-HNet maintains reconstruction fidelity and better preserves disease-relevant signal for downstream AD tasks, including Braak staging, tau localization, and classification. PID-based Shapley analysis provides modality-specific attribution of synthesized uptake patterns.

</details>

---

### 13. [Relatron: Automating Relational Machine Learning over Relational Databases](https://arxiv.org/abs/2602.22552)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22552`](https://arxiv.org/abs/2602.22552)
- ğŸ‘¥ ä½œè€…: Zhikai Chen, Han Xie, Jian Zhang ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22552.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºäº†Relatronæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå…³ç³»æ•°æ®åº“ä¸Šé¢„æµ‹å»ºæ¨¡çš„è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰å…ƒé€‰æ‹©å™¨ã€‚è¯¥å·¥å…·å’Œæ–¹æ³•å¯ç”¨äºä¼˜åŒ–åŒ–å­¦ä¿¡æ¯å­¦ä¸­åŸºäºå…³ç³»å‹åˆ†å­æ•°æ®åº“çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå³åŒ–å­¦å¤§æ¨¡å‹ï¼‰çš„æ¶æ„é€‰æ‹©ï¼Œå±äºé‡è¦çš„æ¨¡å‹æ„å»ºä¸ä¼˜åŒ–èµ„æºã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡å¯¹å…³ç³»æ•°æ®åº“ï¼ˆRDBï¼‰ä¸Šçš„é¢„æµ‹å»ºæ¨¡è¿›è¡Œäº†å…¨é¢ç ”ç©¶ï¼Œå°†å…³ç³»æ·±åº¦å­¦ä¹ ï¼ˆRDLï¼‰å’Œç»å…¸æ–¹æ³•ï¼ˆå¦‚æ·±åº¦ç‰¹å¾åˆæˆDFSï¼‰ç»Ÿä¸€åœ¨ä¸€ä¸ªå…±äº«çš„è®¾è®¡ç©ºé—´ä¸­ï¼Œå¹¶åœ¨å¤šæ ·åŒ–çš„RDBä»»åŠ¡ä¸Šè¿›è¡Œäº†ä»¥æ¶æ„ä¸ºä¸­å¿ƒçš„æœç´¢ã€‚åˆ†æå¾—å‡ºäº†ä¸‰ä¸ªå…³é”®å‘ç°ï¼Œå¹¶åŸºäºæ­¤æå‡ºäº†Relatronï¼Œä¸€ä¸ªåŸºäºä»»åŠ¡åµŒå…¥çš„å…ƒé€‰æ‹©å™¨ï¼Œç”¨äºåœ¨RDLå’ŒDFSä¹‹é—´è¿›è¡Œé€‰æ‹©ï¼Œå¹¶å¯¹æ—å†…æœç´¢è¿›è¡Œå‰ªæã€‚è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†Relatronçš„æœ‰æ•ˆæ€§ã€‚è™½ç„¶ä¸»è¦é¢å‘é€šç”¨çš„å…³ç³»å‹æ•°æ®é¢„æµ‹ï¼Œä½†å…³ç³»æ•°æ®åº“æ˜¯åŒ–å­¦ä¿¡æ¯å­¦ä¸­å­˜å‚¨åˆ†å­ã€ååº”ã€æ€§è´¨æ•°æ®çš„æ ¸å¿ƒå½¢å¼ã€‚å› æ­¤ï¼Œè¯¥ç ”ç©¶æä¾›çš„è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ æ¡†æ¶å’Œè§è§£ï¼ˆRelatronï¼‰å¯¹äºåœ¨åŒ–å­¦ä¿¡æ¯å­¦é¢†åŸŸæ„å»ºå’Œä¼˜åŒ–åŸºäºå…³ç³»æ•°æ®çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€å…·æœ‰ç›´æ¥çš„å·¥å…·å’Œæ–¹æ³•è®ºæ„ä¹‰ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Predictive modeling over relational databases (RDBs) powers applications, yet remains challenging due to capturing both cross-table dependencies and complex feature interactions. Relational Deep Learning (RDL) methods automate feature engineering via message passing, while classical approaches like Deep Feature Synthesis (DFS) rely on predefined non-parametric aggregators. Despite performance gains, the comparative advantages of RDL over DFS and the design principles for selecting effective architectures remain poorly understood. We present a comprehensive study that unifies RDL and DFS in a shared design space and conducts architecture-centric searches across diverse RDB tasks. Our analysis yields three key findings: (1) RDL does not consistently outperform DFS, with performance being highly task-dependent; (2) no single architecture dominates across tasks, underscoring the need for task-aware model selection; and (3) validation accuracy is an unreliable guide for architecture choice. This search yields a model performance bank that links architecture configurations to their performance; leveraging this bank, we analyze the drivers of the RDL-DFS performance gap and introduce two task signals -- RDB task homophily and an affinity embedding that captures size, path, feature, and temporal structure -- whose correlation with the gap enables principled routing. Guided by these signals, we propose Relatron, a task embedding-based meta-selector that chooses between RDL and DFS and prunes the within-family search. Lightweight loss-landscape metrics further guard against brittle checkpoints by preferring flatter optima. In experiments, Relatron resolves the "more tuning, worse performance" effect and, in joint hyperparameter-architecture optimization, achieves up to 18.5% improvement over strong baselines with 10x lower cost than Fisher information-based alternatives.

</details>

---

### 14. [Autoregressive Visual Decoding from EEG Signals](https://arxiv.org/abs/2602.22555)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22555`](https://arxiv.org/abs/2602.22555)
- ğŸ‘¥ ä½œè€…: Sicheng Dai, Hongwang Xiao, Shan Yu ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22555.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯æå‡ºä¸€ç§æ–°é¢–çš„è·¨æ¨¡æ€è‡ªå›å½’ç”Ÿæˆæ¡†æ¶ï¼ˆAVDEï¼‰ï¼Œç”¨äºä»EEGä¿¡å·è§£ç è§†è§‰å›¾åƒã€‚è¿™ç§æ–¹æ³•è®ºï¼ˆä½¿ç”¨ä¸€ç§æ¨¡æ€çš„åµŒå…¥ä½œä¸ºæ¡ä»¶ï¼Œè‡ªå›å½’ç”Ÿæˆå¦ä¸€ç§æ¨¡æ€çš„å±‚æ¬¡åŒ–ä»¤ç‰Œåºåˆ—ï¼‰ä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­ä»è´¨è°±æ•°æ®ç”Ÿæˆåˆ†å­ç»“æ„åºåˆ—ï¼ˆå¦‚SMILESï¼‰çš„ä»»åŠ¡åœ¨é—®é¢˜å®šä¹‰å’Œè§£å†³æ€è·¯ä¸Šé«˜åº¦ç›¸ä¼¼ï¼Œå…·æœ‰ç›´æ¥çš„ç›¸å…³æ€§ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†AVDEï¼Œä¸€ä¸ªä»è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·è¿›è¡Œè§†è§‰è§£ç çš„è½»é‡é«˜æ•ˆæ¡†æ¶ã€‚é¦–å…ˆï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„EEGæ¨¡å‹ï¼ˆLaBraMï¼‰å¹¶é€šè¿‡å¯¹æ¯”å­¦ä¹ è¿›è¡Œå¾®è°ƒï¼Œä»¥å¯¹é½EEGå’Œå›¾åƒè¡¨ç¤ºã€‚å…¶æ¬¡ï¼Œé‡‡ç”¨åŸºäºâ€œä¸‹ä¸€å°ºåº¦é¢„æµ‹â€ç­–ç•¥çš„è‡ªå›å½’ç”Ÿæˆæ¡†æ¶ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„VQ-VAEå°†å›¾åƒç¼–ç ä¸ºå¤šå°ºåº¦ä»¤ç‰Œæ˜ å°„ï¼Œå¹¶è®­ç»ƒä¸€ä¸ªTransformerä»¥EEGåµŒå…¥ä½œä¸ºæœ€ç²—è¡¨ç¤ºï¼Œè‡ªå›å½’åœ°é¢„æµ‹æ›´ç»†å°ºåº¦çš„ä»¤ç‰Œã€‚è¯¥è®¾è®¡åœ¨ä¿æŒè¾“å…¥EEGä¿¡å·ä¸é‡å»ºå›¾åƒä¹‹é—´ç›´æ¥è”ç³»çš„åŒæ—¶ï¼Œå®ç°äº†è¿è´¯çš„ç”Ÿæˆã€‚å®éªŒè¡¨æ˜AVDEåœ¨å›¾åƒæ£€ç´¢å’Œé‡å»ºä»»åŠ¡ä¸Šä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚è™½ç„¶åº”ç”¨äºç¥ç»ç§‘å­¦ï¼Œä½†å…¶æ ¸å¿ƒæ¡†æ¶â€”â€”å°†ä¸€ç§æ¨¡æ€ï¼ˆEEGï¼‰çš„åµŒå…¥ä½œä¸ºç§å­ï¼Œé€šè¿‡è‡ªå›å½’æ–¹å¼ç”Ÿæˆå¦ä¸€ç§æ¨¡æ€ï¼ˆå›¾åƒï¼‰çš„å±‚æ¬¡åŒ–è¡¨ç¤ºâ€”â€”ä¸ºè·¨æ¨¡æ€ç”Ÿæˆä»»åŠ¡æä¾›äº†æ–°é¢–çš„æ¶æ„ã€‚è¿™ç§æ–¹æ³•å¯¹äºâ€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­ä»è´¨è°±æ•°æ®è‡ªå›å½’åœ°ç”Ÿæˆåˆ†å­ç»“æ„è¡¨ç¤ºï¼ˆå¦‚SMILESæˆ–å›¾ä»¤ç‰Œï¼‰å…·æœ‰ç›´æ¥çš„å¯å‘æ€§å’Œå‚è€ƒä»·å€¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Electroencephalogram (EEG) signals have become a popular medium for decoding visual information due to their cost-effectiveness and high temporal resolution. However, current approaches face significant challenges in bridging the modality gap between EEG and image data. These methods typically rely on complex adaptation processes involving multiple stages, making it hard to maintain consistency and manage compounding errors. Furthermore, the computational overhead imposed by large-scale diffusion models limit their practicality in real-world brain-computer interface (BCI) applications. In this work, we present AVDE, a lightweight and efficient framework for visual decoding from EEG signals. First, we leverage LaBraM, a pre-trained EEG model, and fine-tune it via contrastive learning to align EEG and image representations. Second, we adopt an autoregressive generative framework based on a "next-scale prediction" strategy: images are encoded into multi-scale token maps using a pre-trained VQ-VAE, and a transformer is trained to autoregressively predict finer-scale tokens starting from EEG embeddings as the coarsest representation. This design enables coherent generation while preserving a direct connection between the input EEG signals and the reconstructed images. Experiments on two datasets show that AVDE outperforms previous state-of-the-art methods in both image retrieval and reconstruction tasks, while using only 10% of the parameters. In addition, visualization of intermediate outputs shows that the generative process of AVDE reflects the hierarchical nature of human visual perception. These results highlight the potential of autoregressive models as efficient and interpretable tools for practical BCI applications.

</details>

---

### 15. [dLLM: Simple Diffusion Language Modeling](https://arxiv.org/abs/2602.22661)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22661`](https://arxiv.org/abs/2602.22661)
- ğŸ‘¥ ä½œè€…: Zhanhui Zhou, Lingjie Chen, Hanghang Tong ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22661.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ‰©æ•£è¯­è¨€å»ºæ¨¡æ¡†æ¶ï¼ˆdLLMï¼‰ï¼Œè¯¥æ¡†æ¶ä½œä¸ºå·¥å…·å’Œèµ„æºï¼Œå¯ç”¨äºæ„å»ºå’Œè¯„ä¼°åŒ–å­¦é¢†åŸŸï¼ˆå¦‚åˆ†å­ç»“æ„ç”Ÿæˆã€æ€§è´¨é¢„æµ‹ï¼‰çš„ä¸“ç”¨å¤§æ¨¡å‹ï¼Œä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€ä¸»é¢˜é«˜åº¦ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡æå‡ºäº†dLLMï¼Œä¸€ä¸ªç”¨äºæ‰©æ•£è¯­è¨€å»ºæ¨¡ï¼ˆDLMï¼‰çš„ç»Ÿä¸€å¼€æºæ¡†æ¶ã€‚DLMæ˜¯ç”Ÿæˆæ¨¡å‹çš„ä¸€ç§ï¼Œä¸åŒ–å­¦ä¿¡æ¯å­¦ä¸­ç”¨äºåˆ†å­ç”Ÿæˆå’Œæ€§è´¨é¢„æµ‹çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€åœ¨æ–¹æ³•è®ºä¸Šé«˜åº¦ç›¸å…³ã€‚è¯¥æ¡†æ¶æ ‡å‡†åŒ–äº†DLMçš„æ ¸å¿ƒç»„ä»¶ï¼ˆè®­ç»ƒã€æ¨ç†ã€è¯„ä¼°ï¼‰ï¼Œå¹¶æä¾›äº†å°†ä»»ä½•BERTé£æ ¼ç¼–ç å™¨æˆ–è‡ªå›å½’è¯­è¨€æ¨¡å‹è½¬æ¢ä¸ºDLMçš„é…æ–¹ã€‚è¿™å¯¹äºæ„å»ºå’Œè¯„ä¼°ä¸“é—¨ç”¨äºåŒ–å­¦é¢†åŸŸï¼ˆå¦‚åˆ†å­ç”Ÿæˆã€è´¨è°±è§£æï¼‰çš„æ‰©æ•£æ¨¡å‹æˆ–å¤§è¯­è¨€æ¨¡å‹å…·æœ‰é‡è¦çš„å·¥å…·å’Œèµ„æºä»·å€¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Although diffusion language models (DLMs) are evolving quickly, many recent models converge on a set of shared components. These components, however, are distributed across ad-hoc research codebases or lack transparent implementations, making them difficult to reproduce or extend. As the field accelerates, there is a clear need for a unified framework that standardizes these common components while remaining flexible enough to support new methods and architectures. To address this gap, we introduce dLLM, an open-source framework that unifies the core components of diffusion language modeling -- training, inference, and evaluation -- and makes them easy to customize for new designs. With dLLM, users can reproduce, finetune, deploy, and evaluate open-source large DLMs such as LLaDA and Dream through a standardized pipeline. The framework also provides minimal, reproducible recipes for building small DLMs from scratch with accessible compute, including converting any BERT-style encoder or autoregressive LM into a DLM. We also release the checkpoints of these small DLMs to make DLMs more accessible and accelerate future research.

</details>

---

### 16. [Tokenization, Fusion and Decoupling: Bridging the Granularity Mismatch Between Large Language Models and Knowledge Graphs](https://arxiv.org/abs/2602.22698)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22698`](https://arxiv.org/abs/2602.22698)
- ğŸ‘¥ ä½œè€…: Siyue Su, Jian Yang, Bo Li ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22698.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯è§£å†³LLMä¸çŸ¥è¯†å›¾è°±çš„èåˆé—®é¢˜ï¼Œå…¶æå‡ºçš„ç»Ÿä¸€è¡¨ç¤ºã€ç‰¹å¾èåˆå’Œæ¨ç†æ–¹æ³•å¯ç›´æ¥åº”ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦é¢†åŸŸï¼Œç”¨äºæ„å»ºèƒ½å¤Ÿå¤„ç†åˆ†å­ç»“æ„å›¾ä¸æ–‡æœ¬ä¿¡æ¯çš„åŒ–å­¦å¤§æ¨¡å‹ï¼Œå¹¶æ”¯æŒä»å¤šæ¨¡æ€æ•°æ®ï¼ˆå¦‚è´¨è°±ï¼‰ä¸­è¿›è¡Œç»“æ„æ¨ç†ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†KGTæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰åœ¨ç²’åº¦ä¸Šçš„ä¸åŒ¹é…é—®é¢˜ï¼Œä»¥æ”¹è¿›çŸ¥è¯†å›¾è°±è¡¥å…¨ï¼ˆKGCï¼‰ã€‚è™½ç„¶è®ºæ–‡ä¸»è¦å…³æ³¨é€šç”¨çŸ¥è¯†å›¾è°±ï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•â€”â€”ä½¿ç”¨ä¸“ç”¨å®ä½“ä»¤ç‰Œè¿›è¡Œé«˜æ•ˆçš„å…¨ç©ºé—´é¢„æµ‹ã€èåˆé¢„è®­ç»ƒçš„ç»“æ„å’Œæ–‡æœ¬ç‰¹å¾ã€ä»¥åŠè§£è€¦çš„è¯­ä¹‰ä¸ç»“æ„æ¨ç†â€”â€”ä¸ºè§£å†³åŒ–å­¦ä¿¡æ¯å­¦ä¸­çš„å…³é”®é—®é¢˜æä¾›äº†ç›´æ¥æ€è·¯ã€‚ä¾‹å¦‚ï¼Œå°†åˆ†å­ç»“æ„ï¼ˆå›¾ï¼‰ä¸æ–‡æœ¬æè¿°ï¼ˆæ–‡çŒ®ã€å±æ€§ï¼‰å¯¹é½ï¼Œæˆ–ä»è´¨è°±æ•°æ®ä¸­æ¨ç†åˆ†å­ç»“æ„ï¼ˆè´¨è°±ç»“æ„æ¨ç†ï¼‰ï¼Œéƒ½å¯ä»¥è¢«è§†ä¸ºä¸€ç§ç‰¹æ®Šçš„â€œçŸ¥è¯†å›¾è°±è¡¥å…¨â€ä»»åŠ¡ã€‚è®ºæ–‡æå‡ºçš„ç»Ÿä¸€åµŒå…¥å’Œå…³ç³»å¼•å¯¼é—¨æ§æœºåˆ¶ç­‰æ–¹æ³•ï¼Œå¯¹äºæ„å»ºèƒ½å¤ŸåŒæ—¶ç†è§£åŒ–å­¦ç»“æ„ï¼ˆå›¾ï¼‰å’Œæ–‡æœ¬æè¿°ï¼ˆå¦‚è´¨è°±è§£ææŠ¥å‘Šï¼‰çš„å¤šæ¨¡æ€åŒ–å­¦å¤§æ¨¡å‹å…·æœ‰é‡è¦çš„æ–¹æ³•è®ºå‚è€ƒä»·å€¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Leveraging Large Language Models (LLMs) for Knowledge Graph Completion (KGC) is promising but hindered by a fundamental granularity mismatch. LLMs operate on fragmented token sequences, whereas entities are the fundamental units in knowledge graphs (KGs) scenarios. Existing approaches typically constrain predictions to limited candidate sets or align entities with the LLM's vocabulary by pooling multiple tokens or decomposing entities into fixed-length token sequences, which fail to capture both the semantic meaning of the text and the structural integrity of the graph. To address this, we propose KGT, a novel framework that uses dedicated entity tokens to enable efficient, full-space prediction. Specifically, we first introduce specialized tokenization to construct feature representations at the level of dedicated entity tokens. We then fuse pre-trained structural and textual features into these unified embeddings via a relation-guided gating mechanism, avoiding training from scratch. Finally, we implement decoupled prediction by leveraging independent heads to separate and combine semantic and structural reasoning. Experimental results show that KGT consistently outperforms state-of-the-art methods across multiple benchmarks.

</details>

---

### 17. [BRepMAE: Self-Supervised Masked BRep Autoencoders for Machining Feature Recognition](https://arxiv.org/abs/2602.22701)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22701`](https://arxiv.org/abs/2602.22701)
- ğŸ‘¥ ä½œè€…: Can Yao, Kang Wu, Zuheng Zheng ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22701.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1å’Œ2ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ–¹æ³•ï¼ˆåŸºäºå›¾çš„æ©ç è‡ªç¼–ç é¢„è®­ç»ƒï¼‰ä¸åŒ–å­¦ä¿¡æ¯å­¦ä¸­ç”¨äºåˆ†å­è¡¨ç¤ºå­¦ä¹ çš„å›¾ç¥ç»ç½‘ç»œæ–¹æ³•é«˜åº¦ä¸€è‡´ï¼Œä¸ºæ„å»ºåŒ–å­¦å¤§æ¨¡å‹æä¾›äº†ç›´æ¥çš„æ–¹æ³•è®ºå‚è€ƒï¼ˆæ ‡å‡†1ï¼‰ã€‚åŒæ—¶ï¼Œå…¶æå‡ºçš„æ¡†æ¶æœ¬èº«å¯è¢«è§†ä¸ºä¸€ç§å¤„ç†ç»“æ„åŒ–æ•°æ®çš„å·¥å…·æˆ–èŒƒå¼ï¼Œå¯è¿ç§»è‡³åŒ–å­¦é¢†åŸŸï¼ˆæ ‡å‡†2ï¼‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†BRepMAEï¼Œä¸€ä¸ªç”¨äºè®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰æ¨¡å‹ä¸­åŠ å·¥ç‰¹å¾è¯†åˆ«çš„æ©ç è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ˜¯ä½¿ç”¨è¾¹ç•Œè¡¨ç¤ºï¼ˆBRepï¼‰è¡ç”Ÿçš„å‡ ä½•å±æ€§é‚»æ¥å›¾ï¼ˆgAAGï¼‰ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡æ©ç å›¾è‡ªç¼–ç å™¨ï¼ˆMAEï¼‰è¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ CADæ¨¡å‹çš„æœ‰ä»·å€¼è¡¨ç¤ºã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯æœºæ¢°åˆ¶é€ ï¼Œä½†å…¶æ–¹æ³•è®ºä¸åŒ–å­¦ä¿¡æ¯å­¦é«˜åº¦ç›¸ä¼¼ï¼š1ï¼‰å°†å¤æ‚ç»“æ„ï¼ˆCADæ¨¡å‹/åˆ†å­ï¼‰è¡¨ç¤ºä¸ºå›¾ï¼ˆgAAG/åˆ†å­å›¾ï¼‰ï¼›2ï¼‰ä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ ï¼ˆæ©ç è‡ªåŠ¨ç¼–ç ï¼‰ä»æ— æ ‡ç­¾æ•°æ®ä¸­å­¦ä¹ é€šç”¨è¡¨ç¤ºï¼›3ï¼‰ä¸‹æ¸¸ä»»åŠ¡æ˜¯å¯¹ç»“æ„ä¸­çš„åŠŸèƒ½å•å…ƒè¿›è¡Œè¯†åˆ«ï¼ˆåŠ å·¥ç‰¹å¾/å®˜èƒ½å›¢ã€å­ç»“æ„ï¼‰ã€‚è¿™ç§åŸºäºå›¾çš„æ©ç è‡ªç¼–ç é¢„è®­ç»ƒèŒƒå¼ï¼Œæ­£æ˜¯æ„å»ºèƒ½å¤Ÿç†è§£åˆ†å­å‡ ä½•å’Œæ‹“æ‰‘ç»“æ„çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„ä¸€ç§ä¸»æµä¸”æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚è®ºæ–‡ä¸ºåœ¨åŒ–å­¦é¢†åŸŸåº”ç”¨ç±»ä¼¼æŠ€æœ¯æä¾›äº†å¯å€Ÿé‰´çš„æ¡†æ¶å’ŒéªŒè¯ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

We propose a masked self-supervised learning framework, called BRepMAE, for automatically extracting a valuable representation of the input computer-aided design (CAD) model to recognize its machining features. Representation learning is conducted on a large-scale, unlabeled CAD model dataset using the geometric Attributed Adjacency Graph (gAAG) representation, derived from the boundary representation (BRep). The self-supervised network is a masked graph autoencoder (MAE) that focuses on reconstructing geometries and attributes of BRep facets, rather than graph structures. After pre-training, we fine-tune a network that contains both the encoder and a task-specific classification network for machining feature recognition (MFR). In the experiments, our fine-tuned network achieves high recognition rates with only a small amount of data (e.g., 0.1% of the training data), significantly enhancing its practicality in real-world (or private) scenarios where only limited data is available. Compared with other MFR methods, our fine-tuned network achieves a significant improvement in recognition rate with the same amount of training data, especially when the number of training samples is limited.

</details>

---

### 18. [Molecule Mixture Detection and Design for MC Systems with Non-linear, Cross-reactive Receiver Arrays](https://arxiv.org/abs/2602.22799)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22799`](https://arxiv.org/abs/2602.22799)
- ğŸ‘¥ ä½œè€…: Bastian Heinlein, Kaikai Zhu, SÃ¼meyye Carkit-Yilmaz ç­‰9äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22799.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯åˆ†å­é€šä¿¡ç³»ç»Ÿä¸­çš„åˆ†å­æ··åˆç‰©æ£€æµ‹ä¸è®¾è®¡ï¼Œè¿™ç›´æ¥æ¶‰åŠåŒ–å­¦ä¿¡æ¯å­¦ä¸­é€šè¿‡ä¼ æ„Ÿå™¨ä¿¡å·è¿›è¡ŒåŒ–å­¦ç‰©è´¨è¯†åˆ«å’Œæ¨ç†çš„é—®é¢˜ï¼Œä¸â€˜è´¨è°±ç»“æ„æ¨ç†â€™çš„ä¸»é¢˜åœ¨æ–¹æ³•è®ºä¸Šé«˜åº¦ç›¸å…³ï¼ˆéƒ½æ˜¯é€šè¿‡åˆ†æä¿¡å·æ¥æ¨æ–­åŒ–å­¦ç»„æˆ/ç»“æ„ï¼‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶ç©ºæ°”åˆ†å­é€šä¿¡ï¼ˆMCï¼‰ç³»ç»Ÿï¼Œé‡ç‚¹å…³æ³¨åˆ†å­æ··åˆç‰©æ£€æµ‹ä¸è®¾è®¡ã€‚ç³»ç»Ÿä½¿ç”¨éçº¿æ€§å’Œäº¤å‰ååº”ä¼ æ„Ÿå™¨ä½œä¸ºæ¥æ”¶å™¨ï¼ˆRXï¼‰ï¼Œè¿™ä¸MCæ–‡çŒ®ä¸­å¸¸è§çš„ç†æƒ³çº¿æ€§ã€åˆ†å­ç±»å‹ç‰¹å¼‚æ€§ä¼ æ„Ÿå‡è®¾ä¸åŒã€‚è®ºæ–‡æå‡ºäº†å‡ ç§æ£€æµ‹å™¨å’Œä¼ è¾“æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ç”¨äºæ— ç é—´å¹²æ‰°ï¼ˆISIï¼‰åœºæ™¯çš„è¿‘ä¼¼æœ€å¤§ä¼¼ç„¶ï¼ˆAMLï¼‰ç¬¦å·æ£€æµ‹å™¨ï¼Œä»¥åŠä¸€ç§è€ƒè™‘æ¥æ”¶å™¨ç‰¹æ€§çš„äº’è¡¥æ··åˆç‰©å­—æ¯è¡¨è®¾è®¡ç®—æ³•ã€‚å¯¹äºå­˜åœ¨æ˜¾è‘—ISIçš„é«˜æ•°æ®é€Ÿç‡åœºæ™¯ï¼ŒAMLæ£€æµ‹å™¨å¯ä»¥è¿›è¡Œè°ƒæ•´ä»¥åˆ©ç”¨ç»Ÿè®¡ISIçŸ¥è¯†ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§ç»“åˆå¤šä¸ªç¬¦å·é—´éš”ä¿¡æ¯çš„åºåˆ—æ£€æµ‹å™¨ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡ä¸€ä¸ªè€ƒè™‘å‘å°„å™¨å™ªå£°ã€ISIä»¥åŠé€šç”¨éçº¿æ€§ã€äº¤å‰ååº”RXé˜µåˆ—çš„ç³»ç»Ÿæ¨¡å‹ï¼Œä¸ºä¸€å¤§ç±»MCç³»ç»Ÿå®ç°å¯é é€šä¿¡æä¾›äº†æ–¹æ¡ˆã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Air-based molecular communication (MC) has the potential to be one of the first MC systems to be deployed in real-world applications, enabled by commercially available sensors. However, these sensors usually exhibit non-linear and cross-reactive behavior, contrary to the idealizing assumption of linear and perfectly molecule type-specific sensing often made in the MC literature. To address this mismatch, we propose several detectors and transmission schemes for a molecule mixture communication system where the receiver (RX) employs non-linear, cross-reactive sensors. All proposed schemes are based on the first- and second-order moments of the symbol likelihoods that are fed through the non-linear RX using the Unscented Transform. In particular, we propose an approximate maximum likelihood (AML) symbol-by-symbol detector for inter-symbol-interference (ISI)-free transmission scenarios and a complementary mixture alphabet design algorithm which accounts for the RX characteristics. When significant ISI is present at high data rates, the AML detector can be adapted to exploit statistical ISI knowledge. Additionally, we propose a sequence detector which combines information from multiple symbol intervals. For settings where sequence detection is not possible due to extremely limited computational power at the RX, we propose an adaptive transmission scheme which can be combined with symbol-by-symbol detection. Using computer simulations, we validate all proposed detectors and algorithms based on the responses of commercially available sensors as well as artificially generated sensor data incorporating the characteristics of metal-oxide semiconductor sensors. By employing a general system model that accounts for transmitter noise, ISI, and general non-linear, cross-reactive RX arrays, this work enables reliable communication for a large class of MC systems.

</details>

---

### 19. [FlexMS is a flexible framework for benchmarking deep learning-based mass spectrum prediction tools in metabolomics](https://arxiv.org/abs/2602.22822)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22822`](https://arxiv.org/abs/2602.22822)
- ğŸ‘¥ ä½œè€…: Yunhua Zhong, Yixuan Tang, Yifan Li ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22822.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2å’Œæ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ˜¯æä¾›äº†ä¸€ä¸ªç”¨äºè¯„ä¼°è´¨è°±é¢„æµ‹æ¨¡å‹çš„åŸºå‡†æ¡†æ¶FlexMSï¼ˆæ ‡å‡†1ï¼šæ ¸å¿ƒä¸»é¢˜å›´ç»•è´¨è°±åˆ†æï¼‰ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå®ƒæ˜ç¡®æ—¨åœ¨æä¾›ç”¨äºè´¨è°±ç»“æ„æ¨ç†ï¼ˆå³ä»ç»“æ„é¢„æµ‹è°±å›¾ï¼‰çš„æ•°æ®é›†ã€å·¥å…·å’Œè¯„ä¼°åŸºå‡†ï¼ˆæ ‡å‡†2ï¼šæ•°æ®èµ„æºç›¸å…³ï¼‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†FlexMSï¼Œä¸€ä¸ªç”¨äºåœ¨ä»£è°¢ç»„å­¦ä¸­åŸºå‡†æµ‹è¯•æ·±åº¦å­¦ä¹ è´¨è°±é¢„æµ‹å·¥å…·çš„çµæ´»æ¡†æ¶ã€‚è´¨è°±æŠ€æœ¯ä»¥è´¨è·æ¯”å³°çš„å½¢å¼æä¾›æœ‰ä»·å€¼çš„ç¢ç‰‡åŒ–çº¿ç´¢ï¼Œå¯¹äºåŒ–å­¦åˆ†å­çš„é‰´å®šå’Œæ€§è´¨é¢„æµ‹è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå®éªŒè°±å›¾çš„ç¼ºä¹é˜»ç¢äº†åˆ†å­é‰´å®šï¼Œå› æ­¤è¿«åˆ‡éœ€è¦å»ºç«‹è®¡ç®—æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨é¢„æµ‹åˆ†å­ç»“æ„è°±å›¾æ–¹é¢å‰æ™¯å¹¿é˜”ï¼Œä½†ç”±äºæ–¹æ³•å¼‚è´¨æ€§å’Œç¼ºä¹æ˜ç¡®å®šä¹‰çš„åŸºå‡†ï¼Œæ•´ä½“è¯„ä¼°ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…åˆ›å»ºäº†åŸºå‡†æ¡†æ¶FlexMSï¼Œç”¨äºæ„å»ºå’Œè¯„ä¼°è´¨è°±é¢„æµ‹ä¸­çš„å¤šæ ·åŒ–æ¨¡å‹æ¶æ„ã€‚FlexMSæ”¯æŒåŠ¨æ€æ„å»ºä¼—å¤šä¸åŒçš„æ¨¡å‹æ¶æ„ç»„åˆï¼Œå¹¶ä½¿ç”¨ä¸åŒçš„æŒ‡æ ‡åœ¨é¢„å¤„ç†çš„å…¬å…±æ•°æ®é›†ä¸Šè¯„ä¼°å…¶æ€§èƒ½ã€‚è®ºæ–‡è¿˜æä¾›äº†å¯¹å½±å“æ€§èƒ½å› ç´ çš„è§è§£ï¼ŒåŒ…æ‹¬æ•°æ®é›†çš„ç»“æ„å¤šæ ·æ€§ã€å­¦ä¹ ç‡ç­‰è¶…å‚æ•°ã€æ•°æ®ç¨€ç–æ€§ã€é¢„è®­ç»ƒæ•ˆæœã€å…ƒæ•°æ®æ¶ˆèè®¾ç½®ä»¥åŠè·¨é¢†åŸŸè¿ç§»å­¦ä¹ åˆ†æã€‚æ­¤å¤–ï¼Œæ£€ç´¢åŸºå‡†æ¨¡æ‹Ÿäº†å®é™…çš„é‰´å®šåœºæ™¯ï¼Œæ ¹æ®é¢„æµ‹çš„è°±å›¾å¯¹æ½œåœ¨åŒ¹é…è¿›è¡Œè¯„åˆ†ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

The identification and property prediction of chemical molecules is of central importance in the advancement of drug discovery and material science, where the tandem mass spectrometry technology gives valuable fragmentation cues in the form of mass-to-charge ratio peaks. However, the lack of experimental spectra hinders the attachment of each molecular identification, and thus urges the establishment of prediction approaches for computational models. Deep learning models appear promising for predicting molecular structure spectra, but overall assessment remains challenging as a result of the heterogeneity in methods and the lack of well-defined benchmarks. To address this, our contribution is the creation of benchmark framework FlexMS for constructing and evaluating diverse model architectures in mass spectrum prediction. With its easy-to-use flexibility, FlexMS supports the dynamic construction of numerous distinct combinations of model architectures, while assessing their performance on preprocessed public datasets using different metrics. In this paper, we provide insights into factors influencing performance, including the structural diversity of datasets, hyperparameters like learning rate and data sparsity, pretraining effects, metadata ablation settings and cross-domain transfer learning analysis. This provides practical guidance in choosing suitable models. Moreover, retrieval benchmarks simulate practical identification scenarios and score potential matches based on predicted spectra.

</details>

---

### 20. [MEDNA-DFM: A Dual-View FiLM-MoE Model for Explainable DNA Methylation Prediction](https://arxiv.org/abs/2602.22850)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22850`](https://arxiv.org/abs/2602.22850)
- ğŸ‘¥ ä½œè€…: Yi He, Yina Cao, Jixiu Zhai ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22850.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ç”¨äºDNAåºåˆ—åŒ–å­¦ä¿®é¥°ï¼ˆç”²åŸºåŒ–ï¼‰é¢„æµ‹çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¿™å±äºåŒ–å­¦ä¿¡æ¯å­¦ä¸­åˆ©ç”¨è®¡ç®—æ¨¡å‹ï¼ˆå¯è§†ä¸ºä¸€ç§ç‰¹å®šé¢†åŸŸçš„åŒ–å­¦å¤§æ¨¡å‹ï¼‰é¢„æµ‹åˆ†å­æˆ–ç”Ÿç‰©å¤§åˆ†å­åŒ–å­¦å±æ€§çš„èŒƒç•´ï¼Œä¸â€˜åŒ–å­¦å¤§æ¨¡å‹â€™ä¸»é¢˜ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºMEDNA-DFMï¼Œä¸€ç§ç”¨äºDNAç”²åŸºåŒ–é¢„æµ‹çš„åŒè§†å›¾FiLM-MoEæ¨¡å‹ï¼Œå¹¶è¾…ä»¥æœºåˆ¶å¯å‘çš„ä¿¡å·çº¯åŒ–ç®—æ³•ä»¥å®ç°å¯è§£é‡Šæ€§ã€‚å‡†ç¡®çš„DNAç”²åŸºåŒ–è®¡ç®—è¯†åˆ«å¯¹äºç†è§£è¡¨è§‚é—ä¼ è°ƒæ§è‡³å…³é‡è¦ã€‚è™½ç„¶æ·±åº¦å­¦ä¹ åœ¨æ­¤äºŒå…ƒåˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶â€œé»‘ç›’â€æ€§è´¨é˜»ç¢äº†ç”Ÿç‰©å­¦æ´å¯Ÿã€‚ä½œè€…çš„ç ”ç©¶è¡¨æ˜ï¼ŒMEDNA-DFMèƒ½æœ‰æ•ˆæ•æ‰ä¿å®ˆçš„ç”²åŸºåŒ–æ¨¡å¼ï¼Œåœ¨ä¸åŒç‰©ç§é—´å®ç°ç¨³å¥åŒºåˆ†ã€‚åœ¨å¤–éƒ¨ç‹¬ç«‹æ•°æ®é›†ä¸Šçš„éªŒè¯è¯å®ï¼Œæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æ˜¯ç”±ä¿å®ˆçš„å†…åœ¨åŸºåºï¼ˆå¦‚GCå«é‡ï¼‰é©±åŠ¨çš„ï¼Œè€Œéç³»ç»Ÿå‘è‚²ä¸Šçš„æ¥è¿‘æ€§ã€‚æ­¤å¤–ï¼Œåº”ç”¨ä½œè€…å¼€å‘çš„ç®—æ³•æå–çš„åŸºåºæ¯”å…ˆå‰ç ”ç©¶å…·æœ‰æ˜¾è‘—æ›´é«˜çš„å¯é æ€§ã€‚æœ€åï¼Œæ¥è‡ªæœè‡6mAæ¡ˆä¾‹ç ”ç©¶çš„å®è¯è¯æ®ä¿ƒä½¿ä½œè€…æå‡ºäº†ä¸€ä¸ªâ€œåºåˆ—-ç»“æ„ååŒâ€å‡è¯´ã€‚è¿™é¡¹å·¥ä½œä¸ºç”²åŸºåŒ–é¢„æµ‹æä¾›äº†ä¸€ä¸ªå¼ºå¤§å·¥å…·ï¼Œå¹¶å±•ç¤ºäº†å¯è§£é‡Šæ·±åº¦å­¦ä¹ å¦‚ä½•æ¨åŠ¨æ–¹æ³•åˆ›æ–°å’Œç”Ÿç‰©å­¦å‡è¯´çš„ç”Ÿæˆã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Accurate computational identification of DNA methylation is essential for understanding epigenetic regulation. Although deep learning excels in this binary classification task, its "black-box" nature impedes biological insight. We address this by introducing a high-performance model MEDNA-DFM, alongside mechanism-inspired signal purification algorithms. Our investigation demonstrates that MEDNA-DFM effectively captures conserved methylation patterns, achieving robust distinction across diverse species. Validation on external independent datasets confirms that the model's generalization is driven by conserved intrinsic motifs (e.g., GC content) rather than phylogenetic proximity. Furthermore, applying our developed algorithms extracted motifs with significantly higher reliability than prior studies. Finally, empirical evidence from a Drosophila 6mA case study prompted us to propose a "sequence-structure synergy" hypothesis, suggesting that the GAGG core motif and an upstream A-tract element function cooperatively. We further validated this hypothesis via in silico mutagenesis, confirming that the ablation of either or both elements significantly degrades the model's recognition capabilities. This work provides a powerful tool for methylation prediction and demonstrates how explainable deep learning can drive both methodological innovation and the generation of biological hypotheses.

</details>

---

### 21. [MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis](https://arxiv.org/abs/2602.22955)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22955`](https://arxiv.org/abs/2602.22955)
- ğŸ‘¥ ä½œè€…: Feng Guo, Jiaxiang Liu, Yang Li ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22955.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯åˆ›å»ºå¹¶å‘å¸ƒäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šæ¨¡æ€çš„åŒ»å­¦å½±åƒè¯Šæ–­æ•°æ®é›†å’ŒåŸºå‡†ï¼ˆMM-NeuroOncoå’ŒMM-NeuroOnco-Benchï¼‰ã€‚è™½ç„¶å…¶åº”ç”¨é¢†åŸŸæ˜¯åŒ»å­¦å½±åƒï¼Œä½†å…¶æ„å»ºå¤šæ¨¡æ€æŒ‡ä»¤æ•°æ®ã€è¿›è¡Œæ¨¡å‹è¯„ä¼°çš„æ¡†æ¶å’Œæ–¹æ³•ï¼Œå¯¹äºæ„å»ºå’Œè¯„ä¼°æ›´é€šç”¨çš„åŒ–å­¦ä¿¡æ¯å­¦æˆ–è´¨è°±åˆ†æé¢†åŸŸçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œç»“åˆåˆ†å­ç»“æ„å›¾ã€è´¨è°±å›¾å’Œæ–‡æœ¬æè¿°ï¼‰å…·æœ‰é‡è¦çš„å‚è€ƒä»·å€¼å’Œèµ„æºæ„ä¹‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†MM-NeuroOncoï¼Œä¸€ä¸ªç”¨äºåŸºäºMRIçš„è„‘è‚¿ç˜¤è¯Šæ–­çš„å¤§è§„æ¨¡å¤šæ¨¡æ€åŸºå‡†å’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ã€‚å‡†ç¡®çš„è„‘è‚¿ç˜¤è¯Šæ–­è¦æ±‚æ¨¡å‹ä¸ä»…èƒ½æ£€æµ‹ç—…å˜ï¼Œè¿˜èƒ½ç”ŸæˆåŸºäºå½±åƒå­¦è¡¨ç°çš„ä¸´åºŠå¯è§£é‡Šæ¨ç†ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å…¬å…±æ•°æ®é›†åœ¨æ³¨é‡Šä¸°å¯Œåº¦å’Œè¯Šæ–­è¯­ä¹‰æ–¹é¢ä»ç„¶æœ‰é™ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼ŒMM-NeuroOncoåŒ…å«æ¥è‡ª20ä¸ªæ•°æ®æºçš„24,726ä¸ªMRIåˆ‡ç‰‡ï¼Œé…å¯¹äº†çº¦200,000ä¸ªæ¶µç›–ä¸åŒè‚¿ç˜¤äºšå‹å’Œæˆåƒæ¨¡å¼çš„è¯­ä¹‰ä¸°å¯Œçš„å¤šæ¨¡æ€æŒ‡ä»¤ã€‚ä¸ºäº†ç¼“è§£è¯Šæ–­è¯­ä¹‰æ³¨é‡Šçš„ç¨€ç¼ºæ€§å’Œé«˜æˆæœ¬ï¼Œä½œè€…å¼€å‘äº†ä¸€ä¸ªå¤šæ¨¡å‹åä½œæµç¨‹ï¼Œç”¨äºè‡ªåŠ¨å®ŒæˆåŒ»å­¦ä¿¡æ¯å¹¶è¿›è¡Œè´¨é‡æ§åˆ¶ï¼Œä»è€Œç”Ÿæˆè¶…è¶Šä»…æ©ç æ³¨é‡Šçš„è¯Šæ–­ç›¸å…³è¯­ä¹‰ã€‚åŸºäºæ­¤æ•°æ®é›†ï¼Œä½œè€…è¿›ä¸€æ­¥æ„å»ºäº†MM-NeuroOnco-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¦æœ‰æ‹’ç»æ„ŸçŸ¥è®¾ç½®çš„æ‰‹åŠ¨æ³¨é‡Šè¯„ä¼°åŸºå‡†ï¼Œä»¥å‡å°‘å°é—­å¼é—®é¢˜æ ¼å¼å›ºæœ‰çš„åè§ã€‚åœ¨åä¸ªä»£è¡¨æ€§æ¨¡å‹ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œå³ä½¿æ˜¯æœ€å¼ºçš„åŸºçº¿æ¨¡å‹Gemini 3 Flashï¼Œåœ¨è¯Šæ–­ç›¸å…³é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡ä¹Ÿä»…ä¸º41.88%ï¼Œçªæ˜¾äº†å¤šæ¨¡æ€è„‘è‚¿ç˜¤è¯Šæ–­ç†è§£çš„å·¨å¤§æŒ‘æˆ˜ã€‚åˆ©ç”¨MM-NeuroOncoï¼Œä½œè€…è¿›ä¸€æ­¥æå‡ºäº†NeuroOnco-GPTï¼Œè¯¥æ¨¡å‹åœ¨å¾®è°ƒåè¯Šæ–­é—®é¢˜çš„å‡†ç¡®ç‡ç»å¯¹æå‡äº†27%ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Accurate brain tumor diagnosis requires models to not only detect lesions but also generate clinically interpretable reasoning grounded in imaging manifestations, yet existing public datasets remain limited in annotation richness and diagnostic semantics. To bridge this gap, we introduce MM-NeuroOnco, a large-scale multimodal benchmark and instruction-tuning dataset for brain tumor MRI understanding, consisting of 24,726 MRI slices from 20 data sources paired with approximately 200,000 semantically enriched multimodal instructions spanning diverse tumor subtypes and imaging modalities. To mitigate the scarcity and high cost of diagnostic semantic annotations, we develop a multi-model collaborative pipeline for automated medical information completion and quality control, enabling the generation of diagnosis-related semantics beyond mask-only annotations. Building upon this dataset, we further construct MM-NeuroOnco-Bench, a manually annotated evaluation benchmark with a rejection-aware setting to reduce biases inherent in closed-ended question formats. Evaluation across ten representative models shows that even the strongest baseline, Gemini 3 Flash, achieves only 41.88% accuracy on diagnosis-related questions, highlighting the substantial challenges of multimodal brain tumor diagnostic understanding. Leveraging MM-NeuroOnco, we further propose NeuroOnco-GPT, which achieves a 27% absolute accuracy improvement on diagnostic questions following fine-tuning. This result demonstrates the effectiveness of our dataset and benchmark in advancing clinically grounded multimodal diagnostic reasoning. Code and dataset are publicly available at: this https URL

</details>

---

### 22. [SPM-Bench: Benchmarking Large Language Models for Scanning Probe Microscopy](https://arxiv.org/abs/2602.22971)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22971`](https://arxiv.org/abs/2602.22971)
- ğŸ‘¥ ä½œè€…: Peiyao Xiao, Xiaogang Li, Chengliang Xu ç­‰13äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22971.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºçš„è‡ªåŠ¨åŒ–æ•°æ®åˆæˆç®¡é“å’ŒåŸºå‡†æ„å»ºæ–¹æ³•ï¼Œä¸ºæ„å»ºç§‘å­¦é¢†åŸŸï¼ˆå¦‚åŒ–å­¦ï¼‰çš„å¤§æ¨¡å‹æä¾›äº†å¯å€Ÿé‰´çš„æ•°æ®é›†åˆ›å»ºå·¥å…·å’Œèµ„æºèŒƒå¼ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†SPM-Benchï¼Œä¸€ä¸ªä¸“é—¨ä¸ºæ‰«ææ¢é’ˆæ˜¾å¾®é•œï¼ˆSPMï¼‰è®¾è®¡çš„åšå£«çº§å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ã€‚è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºä¸€ä¸ªå…¨è‡ªåŠ¨çš„æ•°æ®åˆæˆæµç¨‹ï¼Œè¯¥æµç¨‹åˆ©ç”¨Anchor-Gated Sieveï¼ˆAGSï¼‰æŠ€æœ¯ä»arXivå’ŒæœŸåˆŠè®ºæ–‡ä¸­é«˜æ•ˆæå–é«˜è´¨é‡çš„å›¾åƒ-æ–‡æœ¬å¯¹ã€‚è™½ç„¶SPMæœ¬èº«æ˜¯ç‰©ç†è¡¨å¾æŠ€æœ¯ï¼Œä½†è¯¥è®ºæ–‡æå‡ºçš„è‡ªåŠ¨åŒ–æ•°æ®åˆæˆèŒƒå¼ã€ä»ç§‘å­¦æ–‡çŒ®ä¸­æå–ç»“æ„åŒ–æ•°æ®çš„æ–¹æ³•ï¼Œä»¥åŠæ„å»ºé¢†åŸŸç‰¹å®šåŸºå‡†æµ‹è¯•çš„æ¡†æ¶ï¼Œä¸ºæ„å»ºå’Œè¯„ä¼°ç§‘å­¦é¢†åŸŸï¼ˆåŒ…æ‹¬åŒ–å­¦ä¿¡æ¯å­¦å’Œè´¨è°±åˆ†æï¼‰çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºå‚è€ƒå’Œå·¥å…·æ€è·¯ã€‚å®ƒå±•ç¤ºäº†å¦‚ä½•è‡ªåŠ¨åŒ–åœ°åˆ›å»ºé«˜è´¨é‡ã€ä½æˆæœ¬çš„ç§‘å­¦æ•°æ®é›†ï¼Œè¿™å¯¹äºè®­ç»ƒéœ€è¦å¤§é‡é¢†åŸŸæ•°æ®çš„åŒ–å­¦å¤§æ¨¡å‹è‡³å…³é‡è¦ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

As LLMs achieved breakthroughs in general reasoning, their proficiency in specialized scientific domains reveals pronounced gaps in existing benchmarks due to data contamination, insufficient complexity, and prohibitive human labor costs. Here we present SPM-Bench, an original, PhD-level multimodal benchmark specifically designed for scanning probe microscopy (SPM). We propose a fully automated data synthesis pipeline that ensures both high authority and low-cost. By employing Anchor-Gated Sieve (AGS) technology, we efficiently extract high-value image-text pairs from arXiv and journal papers published between 2023 and 2025. Through a hybrid cloud-local architecture where VLMs return only spatial coordinates "llbox" for local high-fidelity cropping, our pipeline achieves extreme token savings while maintaining high dataset purity. To accurately and objectively evaluate the performance of the LLMs, we introduce the Strict Imperfection Penalty F1 (SIP-F1) score. This metric not only establishes a rigorous capability hierarchy but also, for the first time, quantifies model "personalities" (Conservative, Aggressive, Gambler, or Wise). By correlating these results with model-reported confidence and perceived difficulty, we expose the true reasoning boundaries of current AI in complex physical scenarios. These insights establish SPM-Bench as a generalizable paradigm for automated scientific data synthesis.

</details>

---

### 23. [RhythmBERT: A Self-Supervised Language Model Based on Latent Representations of ECG Waveforms for Heart Disease Detection](https://arxiv.org/abs/2602.23060)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.23060`](https://arxiv.org/abs/2602.23060)
- ğŸ‘¥ ä½œè€…: Xin Wang, Burcu Ozek, Aruna Mohan ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.23060.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹ï¼ˆå°†ç»“æ„åŒ–åºåˆ—æ•°æ®è§†ä¸ºè¯­è¨€è¿›è¡Œè‡ªç›‘ç£å»ºæ¨¡ï¼‰ä¸ºâ€œåŒ–å­¦å¤§æ¨¡å‹â€å’Œâ€œè´¨è°±ç»“æ„æ¨ç†â€æä¾›äº†ç›´æ¥çš„æ–¹æ³•è®ºå¯ç¤ºã€‚å°†è´¨è°±å›¾ç±»æ¯”ä¸ºè¯­è¨€ï¼Œå¹¶é‡‡ç”¨ç±»ä¼¼çš„tokenåŒ–å’Œé¢„è®­ç»ƒç­–ç•¥ï¼Œæ˜¯æ„å»ºè´¨è°±ä¸“ç”¨å¤§æ¨¡å‹ã€è¿›è¡Œç»“æ„æ¨ç†çš„ä¸€æ¡å¯è¡ŒæŠ€æœ¯è·¯å¾„ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†RhythmBERTï¼Œä¸€ç§åŸºäºå¿ƒç”µå›¾ï¼ˆECGï¼‰æ³¢å½¢æ½œåœ¨è¡¨ç¤ºçš„è‡ªç›‘ç£è¯­è¨€æ¨¡å‹ï¼Œç”¨äºå¿ƒè„ç–¾ç—…æ£€æµ‹ã€‚è¯¥æ¨¡å‹å°†ECGè§†ä¸ºä¸€ç§è¯­è¨€èŒƒå¼ï¼Œé€šè¿‡è‡ªç¼–ç å™¨å°†Pã€QRSã€Tæ³¢ç­‰ç‰‡æ®µç¼–ç ä¸ºç¬¦å·åŒ–tokenï¼ŒåŒæ—¶ä¿ç•™è¿ç»­çš„å½¢æ€å­¦åµŒå…¥ã€‚RhythmBERTåœ¨çº¦80ä¸‡ä»½æœªæ ‡è®°çš„ECGè®°å½•ä¸Šè¿›è¡Œæ©ç é¢„æµ‹ç›®æ ‡çš„é¢„è®­ç»ƒï¼Œä»¥å­¦ä¹ ä¸Šä¸‹æ–‡è¡¨å¾ã€‚å°½ç®¡è¯¥å·¥ä½œé’ˆå¯¹ç”Ÿç‰©åŒ»å­¦ä¿¡å·ï¼Œä½†å…¶æ ¸å¿ƒæ€æƒ³â€”â€”å°†å¤æ‚çš„ã€ç»“æ„åŒ–çš„åºåˆ—æ•°æ®ï¼ˆå¦‚ECGæ³¢å½¢ï¼‰åˆ†è§£ä¸ºç¦»æ•£çš„ã€æœ‰è¯­ä¹‰çš„tokenå’Œè¿ç»­çš„åµŒå…¥ï¼Œå¹¶åˆ©ç”¨è‡ªç›‘ç£è¯­è¨€æ¨¡å‹è¿›è¡Œå­¦ä¹ â€”â€”ä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€å’Œâ€œè´¨è°±ç»“æ„æ¨ç†â€çš„ç ”ç©¶ä¸»é¢˜é«˜åº¦ç›¸å…³ã€‚è´¨è°±å›¾åŒæ ·æ˜¯ä¸€ç§å¤æ‚çš„ç»“æ„åŒ–åºåˆ—/å›¾è°±æ•°æ®ï¼Œå¯ä»¥å€Ÿé‰´ç±»ä¼¼çš„â€œè°±å›¾ä½œä¸ºè¯­è¨€â€çš„èŒƒå¼ï¼Œå°†è´¨è°±å³°ã€ç¢ç‰‡ç¦»å­ç­‰ä¿¡æ¯tokenåŒ–ï¼Œå¹¶åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒå’Œä¸‹æ¸¸æ¨ç†ï¼ˆå¦‚ç»“æ„è§£æï¼‰ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Electrocardiogram (ECG) analysis is crucial for diagnosing heart disease, but most self-supervised learning methods treat ECG as a generic time series, overlooking physiologic semantics and rhythm-level structure. Existing contrastive methods utilize augmentations that distort morphology, whereas generative approaches employ fixed-window segmentation, which misaligns cardiac cycles. To address these limitations, we propose RhythmBERT, a generative ECG language model that considers ECG as a language paradigm by encoding P, QRS, and T segments into symbolic tokens via autoencoder-based latent representations. These discrete tokens capture rhythm semantics, while complementary continuous embeddings retain fine-grained morphology, enabling a unified view of waveform structure and rhythm. RhythmBERT is pretrained on approximately 800,000 unlabeled ECG recordings with a masked prediction objective, allowing it to learn contextual representations in a label-efficient manner. Evaluations show that despite using only a single lead, RhythmBERT achieves comparable or superior performance to strong 12-lead baselines. This generalization extends from prevalent conditions such as atrial fibrillation to clinically challenging cases such as subtle ST-T abnormalities and myocardial infarction. Our results suggest that considering ECG as structured language offers a scalable and physiologically aligned pathway for advancing cardiac analysis.

</details>

---

### 24. [Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent](https://arxiv.org/abs/2602.23079)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.23079`](https://arxiv.org/abs/2602.23079)
- ğŸ‘¥ ä½œè€…: Boyang Zhang, Yang Zhang
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.23079.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡æå‡ºçš„LLMæ™ºèƒ½ä½“åˆ†ææ¡†æ¶ï¼ˆç»“åˆé¢†åŸŸç‰¹å¾ä¸LLMæ¨ç†ï¼‰ä¸ºæ„å»ºç”¨äºâ€œè´¨è°±ç»“æ„æ¨ç†â€çš„æ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†å¯å‚è€ƒçš„æ¶æ„å’Œå®ç°æ€è·¯ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ–‡æœ¬ä½œè€…æ¨æ–­æ–¹é¢çš„èƒ½åŠ›åŠå…¶å¸¦æ¥çš„å»åŒ¿ååŒ–é£é™©ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªåä¸ºSALAï¼ˆStylometry-Assisted LLM Analysisï¼‰çš„LLMæ™ºèƒ½ä½“æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å®šé‡çš„æ–‡ä½“è®¡é‡å­¦ç‰¹å¾ä¸LLMæ¨ç†ç›¸ç»“åˆï¼Œç”¨äºé²æ£’ä¸”å¯è§£é‡Šçš„ä½œè€…å½’å±åˆ†æã€‚è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§å¼•å¯¼é‡å†™ç­–ç•¥ï¼Œåˆ©ç”¨æ™ºèƒ½ä½“çš„æ¨ç†è½¨è¿¹ç”Ÿæˆæ”¹å†™æç¤ºï¼Œä»¥é™ä½ä½œè€…çš„å¯è¯†åˆ«æ€§ã€‚è¿™é¡¹å·¥ä½œè™½ç„¶èšç„¦äºæ–‡æœ¬ä½œè€…åˆ†æï¼Œä½†å…¶æ ¸å¿ƒâ€”â€”åˆ©ç”¨LLMæ™ºèƒ½ä½“è¿›è¡Œç»†ç²’åº¦çš„ã€åŸºäºç‰¹å¾çš„åˆ†æå’Œç”Ÿæˆâ€”â€”ä¸åˆ©ç”¨AIè¿›è¡Œç§‘å­¦æ•°æ®åˆ†æï¼ˆå¦‚è´¨è°±è§£æï¼‰åœ¨èŒƒå¼ä¸Šç›¸é€šã€‚æ„å»ºä¸€ä¸ªç±»ä¼¼çš„â€œè´¨è°±è§£ææ™ºèƒ½ä½“â€ï¼Œç»“åˆåŒ–å­¦è§„åˆ™ï¼ˆç±»ä¼¼æ–‡ä½“ç‰¹å¾ï¼‰å’ŒLLMçš„æ¨ç†èƒ½åŠ›ï¼Œè¿›è¡Œè´¨è°±å›¾çš„ç»“æ„æ¨ç†ï¼Œæ˜¯ä¸€ä¸ªå€¼å¾—æ¢ç´¢çš„æ–¹å‘ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mitigate such risks through a structured, interpretable pipeline. Central to our framework is the proposed $\textit{SALA}$ (Stylometry-Assisted LLM Analysis) method, which integrates quantitative stylometric features with LLM reasoning for robust and transparent authorship attribution. Experiments on large-scale news datasets demonstrate that $\textit{SALA}$, particularly when augmented with a database module, achieves high inference accuracy in various scenarios. Finally, we propose a guided recomposition strategy that leverages the agent's reasoning trace to generate rewriting prompts, effectively reducing authorship identifiability while preserving textual meaning. Our findings highlight both the deanonymization potential of LLM agents and the importance of interpretable, proactive defenses for safeguarding author privacy.

</details>

---

### 25. [Induction Meets Biology: Mechanisms of Repeat Detection in Protein Language Models](https://arxiv.org/abs/2602.23179)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.23179`](https://arxiv.org/abs/2602.23179)
- ğŸ‘¥ ä½œè€…: Gal Kesten-Pomeranz, Yaniv Nikankin, Anja Reusch ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.23179.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡å¯¹è›‹ç™½è´¨è¯­è¨€æ¨¡å‹å†…éƒ¨æœºåˆ¶ï¼ˆç»“åˆé€šç”¨æ¨¡å¼åŒ¹é…ä¸é¢†åŸŸçŸ¥è¯†ï¼‰çš„æ·±å…¥ç ”ç©¶ï¼Œä¸ºç†è§£å’Œè®¾è®¡ç”¨äºâ€œè´¨è°±ç»“æ„æ¨ç†â€çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„å†…éƒ¨æ¶æ„å’Œå­¦ä¹ æœºåˆ¶æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œçµæ„Ÿã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æ·±å…¥ç ”ç©¶äº†è›‹ç™½è´¨è¯­è¨€æ¨¡å‹ï¼ˆPLMï¼‰å†…éƒ¨æ£€æµ‹è›‹ç™½è´¨åºåˆ—ä¸­é‡å¤ç‰‡æ®µï¼ˆåŒ…æ‹¬ç²¾ç¡®é‡å¤å’Œè¿‘ä¼¼é‡å¤ï¼‰çš„æœºåˆ¶ã€‚ç ”ç©¶å‘ç°ï¼ŒPLMé€šè¿‡ç»“åˆé€šç”¨çš„åŸºäºä½ç½®çš„æ³¨æ„åŠ›å¤´å’Œç”Ÿç‰©å­¦ç‰¹åŒ–çš„ç»„ä»¶ï¼ˆå¦‚ç¼–ç æ°¨åŸºé…¸ç›¸ä¼¼æ€§çš„ç¥ç»å…ƒï¼‰æ¥æ„å»ºç‰¹å¾è¡¨ç¤ºï¼Œç„¶åé€šè¿‡å½’çº³å¤´ï¼ˆinduction headsï¼‰å…³æ³¨é‡å¤ç‰‡æ®µé—´å¯¹é½çš„tokenï¼Œä»è€Œå®Œæˆæ£€æµ‹ä»»åŠ¡ã€‚è¿™é¡¹å·¥ä½œæ­ç¤ºäº†PLMå¦‚ä½•å°†åŸºäºè¯­è¨€çš„æ¨¡å¼åŒ¹é…ä¸ä¸“é—¨çš„ç”Ÿç‰©å­¦çŸ¥è¯†ç›¸ç»“åˆæ¥è§£å†³ç”Ÿç‰©ä»»åŠ¡ã€‚è¿™ä¸€æœºåˆ¶ç ”ç©¶å¯¹äºç†è§£â€œåŒ–å­¦å¤§æ¨¡å‹â€åœ¨åŒ–å­¦å’Œè´¨è°±é¢†åŸŸçš„æ½œåœ¨å·¥ä½œæ–¹å¼å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç”¨äºè´¨è°±ç»“æ„æ¨ç†çš„åŒ–å­¦å¤§æ¨¡å‹ï¼Œå¾ˆå¯èƒ½ä¹Ÿéœ€è¦ç±»ä¼¼çš„æœºåˆ¶ï¼šæ—¢éœ€è¦é€šç”¨çš„åºåˆ—/å›¾è°±æ¨¡å¼è¯†åˆ«èƒ½åŠ›ï¼Œä¹Ÿéœ€è¦å†…åŒ–åŒ–å­¦çŸ¥è¯†ï¼ˆå¦‚å®˜èƒ½å›¢ç‰¹æ€§ã€è£‚è§£è§„åˆ™ï¼‰çš„ç‰¹åŒ–ç»„ä»¶ï¼Œæ‰èƒ½æœ‰æ•ˆæ¨ç†å‡ºåˆ†å­ç»“æ„ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Protein sequences are abundant in repeating segments, both as exact copies and as approximate segments with mutations. These repeats are important for protein structure and function, motivating decades of algorithmic work on repeat identification. Recent work has shown that protein language models (PLMs) identify repeats, by examining their behavior in masked-token prediction. To elucidate their internal mechanisms, we investigate how PLMs detect both exact and approximate repeats. We find that the mechanism for approximate repeats functionally subsumes that of exact repeats. We then characterize this mechanism, revealing two main stages: PLMs first build feature representations using both general positional attention heads and biologically specialized components, such as neurons that encode amino-acid similarity. Then, induction heads attend to aligned tokens across repeated segments, promoting the correct answer. Our results reveal how PLMs solve this biological task by combining language-based pattern matching with specialized biological knowledge, thereby establishing a basis for studying more complex evolutionary processes in PLMs.

</details>

---

### 26. [ColoDiff: Integrating Dynamic Consistency With Content Awareness for Colonoscopy Video Generation](https://arxiv.org/abs/2602.23203)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.23203`](https://arxiv.org/abs/2602.23203)
- ğŸ‘¥ ä½œè€…: Junhu Fu, Shuyu Liang, Wutong Li ç­‰12äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.23203.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹ç›´æ¥å›´ç»•â€œåŒ–å­¦å¤§æ¨¡å‹â€è¿™ä¸€ä¸»é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªæ—¨åœ¨ç†è§£å’Œæ”¹è¿›åŒ–å­¦ç”Ÿç‰©å­¦ä¸­æœºå™¨å­¦ä¹ æ¨¡å‹å› æœæ¨ç†èƒ½åŠ›çš„ç»Ÿä¸€ç†è®ºæ¡†æ¶ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡é¢˜ä¸ºã€ŠInferential Mechanics Part 1: Causal Mechanistic Theories of Machine Learning in Chemical Biology with Implicationsã€‹ã€‚å®ƒæå‡ºäº†ä¸€ç§æ–°é¢–çš„ç†è®ºæ¡†æ¶ï¼Œæ—¨åœ¨å°†åŒ–å­¦ç†è®ºã€ç”Ÿç‰©å­¦ç†è®ºã€æ¦‚ç‡è®ºå’Œå› æœæ¨ç†ç»“åˆèµ·æ¥ï¼Œä»¥çº æ­£å½“å‰æœºå™¨å­¦ä¹ åœ¨è‡ªç„¶ç§‘å­¦ï¼ˆç‰¹åˆ«æ˜¯åŒ–å­¦ç”Ÿç‰©å­¦ï¼‰ä¸­å­˜åœ¨çš„å› æœç¼ºé™·ã€‚è®ºæ–‡çš„æ ¸å¿ƒæ˜¯æ¢ç´¢åŒ–å­¦å¤§æ¨¡å‹ï¼ˆMachine Learning in Chemical Biologyï¼‰çš„å› æœç»“æ„ï¼Œå¹¶å¼•å…¥äº†â€œç„¦ç‚¹â€ï¼ˆfocusï¼‰è¿™ä¸€æ–°æ¦‚å¿µï¼Œå³æœºå™¨å­¦ä¹ ç®—æ³•åœ¨å¤§å‹æ•°æ®é›†ä¸­èšç„¦äºéšè—åº•å±‚æœºåˆ¶çš„èƒ½åŠ›ã€‚è®ºæ–‡æä¾›äº†åœ¨AktæŠ‘åˆ¶å‰‚å®¶æ—ä¸Šçš„åˆæ­¥åŸç†è¯æ˜ã€‚è¯¥å·¥ä½œä¸ºåŒ–å­¦ç”Ÿç‰©å­¦å»ºç«‹äº†ä¸€ç§æ–°çš„æ•°å­¦æ¡†æ¶ï¼Œç”¨äºåœ¨ä¸ä½¿ç”¨è¿˜åŸè®ºå·¥å…·çš„æƒ…å†µä¸‹å¯¹è‡ªç„¶æœºåˆ¶è¿›è¡Œå»ºæ¨¡ï¼Œå³â€œæ¨ç†åŠ›å­¦â€ï¼ˆinferential mechanicsï¼‰ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Colonoscopy video generation delivers dynamic, information-rich data critical for diagnosing intestinal diseases, particularly in data-scarce scenarios. High-quality video generation demands temporal consistency and precise control over clinical attributes, but faces challenges from irregular intestinal structures, diverse disease representations, and various imaging modalities. To this end, we propose ColoDiff, a diffusion-based framework that generates dynamic-consistent and content-aware colonoscopy videos, aiming to alleviate data shortage and assist clinical analysis. At the inter-frame level, our TimeStream module decouples temporal dependency from video sequences through a cross-frame tokenization mechanism, enabling intricate dynamic modeling despite irregular intestinal structures. At the intra-frame level, our Content-Aware module incorporates noise-injected embeddings and learnable prototypes to realize precise control over clinical attributes, breaking through the coarse guidance of diffusion models. Additionally, ColoDiff employs a non-Markovian sampling strategy that cuts steps by over 90% for real-time generation. ColoDiff is evaluated across three public datasets and one hospital database, based on both generation metrics and downstream tasks including disease diagnosis, modality discrimination, bowel preparation scoring, and lesion segmentation. Extensive experiments show ColoDiff generates videos with smooth transitions and rich dynamics. ColoDiff presents an effort in controllable colonoscopy video generation, revealing the potential of synthetic videos in complementing authentic representation and mitigating data scarcity in clinical settings.

</details>

---

### 27. [Strengthening security and noise resistance in one-way quantum key distribution protocols through hypercube-based quantum walks](https://arxiv.org/abs/2602.23261)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.23261`](https://arxiv.org/abs/2602.23261)
- ğŸ‘¥ ä½œè€…: David Polzoni, Tommaso Bianchi, Mauro Conti
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.23261.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºå¹¶å‘å¸ƒäº†ä¸€ä¸ªç”¨äºåŸºäºé‡å­è¡Œèµ°çš„QKDåè®®çš„å¼€æºæ¨¡æ‹Ÿæ¡†æ¶ã€‚è¯¥å·¥å…·/èµ„æºå¯ç”¨äºç›¸å…³é¢†åŸŸï¼ˆå¦‚é‡å­ä¿¡æ¯å¤„ç†ï¼‰çš„ç ”ç©¶å’Œå¼€å‘ï¼Œè™½ç„¶ä¸ç›´æ¥é’ˆå¯¹è´¨è°±ç»“æ„æ¨ç†ï¼Œä½†ä½œä¸ºâ€œæ•°æ®èµ„æºç›¸å…³â€çš„å·¥å…·è¢«çº³å…¥ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡é¢˜ä¸ºã€ŠStrengthening security and noise resistance in one-way quantum key distribution protocols through hypercube-based quantum walksã€‹ã€‚å®ƒç ”ç©¶äº†ä¸€ç§åŸºäºç¦»æ•£æ—¶é—´é‡å­è¡Œèµ°ï¼ˆQWsï¼‰çš„å•å‘é‡å­å¯†é’¥åˆ†å‘åè®®ã€‚è®ºæ–‡çš„æ ¸å¿ƒæ˜¯å¼•å…¥äº†ä¸€ç§åŸºäºè¶…ç«‹æ–¹ä½“æ‹“æ‰‘çš„æ–°å‹QKDåè®®ï¼Œå¹¶è¯æ˜åœ¨ç›¸åŒå‚æ•°ä¸‹ï¼Œè¯¥åè®®æ¯”åŸºäºç¯å½¢æ‹“æ‰‘ï¼ˆå½“å‰æœ€å…ˆè¿›ï¼‰çš„åè®®æä¾›äº†æ˜¾è‘—å¢å¼ºçš„å®‰å…¨æ€§å’ŒæŠ—å™ªæ€§ã€‚è®ºæ–‡è¿˜ä»‹ç»äº†ä¸€ä¸ªé«˜æ•ˆçš„ã€å¯æ‰©å±•çš„æ¨¡æ‹Ÿæ¡†æ¶ï¼Œç”¨äºåˆ†æåŸºäºQWsçš„QKDåè®®ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Quantum Key Distribution (QKD) is a foundational cryptographic protocol that ensures information-theoretic security. However, classical protocols such as BB84, though favored for their simplicity, offer limited resistance to eavesdropping, and perform poorly under realistic noise conditions. Recent research has explored the use of discrete-time Quantum Walks (QWs) to enhance QKD schemes. In this work, we specifically focus on a one-way QKD protocol, where security depends exclusively on the underlying Quantum Walk (QW) topology, rather than the details of the protocol itself. Our paper introduces a novel protocol based on QWs over a hypercube topology and demonstrates that, under identical parameters, it provides significantly enhanced security and noise resistance compared to the circular topology (i.e., state-of-the-art), thereby strengthening protection against eavesdropping. Furthermore, we introduce an efficient and extensible simulation framework for one-way QKD protocols based on QWs, supporting both circular and hypercube topologies. Implemented with IBM's software development kit for quantum computing (i.e., Qiskit), our toolkit enables noise-aware analysis under realistic noise models. To support reproducibility and future developments, we release our entire simulation framework as open-source. This contribution establishes a foundation for the design of topology-aware QKD protocols that combine enhanced noise tolerance with topologically driven security.

</details>

---

### 28. [Quantum Key Distribution](https://arxiv.org/abs/2507.23192)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2507.23192`](https://arxiv.org/abs/2507.23192)
- ğŸ‘¥ ä½œè€…: Sebastian Kish, Josef Pieprzyk, Seyit Camtepe
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2507.23192.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†3ï¼šè®ºæ–‡æ˜¯ä¸€ç¯‡ä¸“é—¨é’ˆå¯¹é‡å­å¯†é’¥åˆ†å‘ï¼ˆQKDï¼‰æŠ€æœ¯çš„ç»¼è¿°ï¼Œæä¾›äº†è¯¥é¢†åŸŸçš„æˆç†Ÿåº¦ã€è¶‹åŠ¿ã€æŒ‘æˆ˜å’Œå‰æ™¯çš„å…¨é¢æ¦‚è¿°ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡é¢˜ä¸ºã€ŠQuantum Key Distributionã€‹ã€‚å®ƒæ˜¯ä¸€ç¯‡å…³äºé‡å­å¯†é’¥åˆ†å‘æŠ€æœ¯çš„ç»¼è¿°ç« èŠ‚ã€‚æ–‡ç« æ¦‚è¿°äº†QKDæŠ€æœ¯çš„æˆç†Ÿåº¦å’Œè¶‹åŠ¿ï¼Œå¼ºè°ƒäº†å•å…‰å­æºå’Œæ¢æµ‹æŠ€æœ¯æ–¹é¢çš„é‡å¤§è¿›å±•ï¼Œè¿™äº›è¿›å±•ä½¿QKDæ›´æ¥è¿‘å¹¿æ³›é‡‡ç”¨ã€‚æ–‡ç« è¿˜è®¨è®ºäº†æˆæœ¬ã€é›†æˆã€æ ‡å‡†åŒ–ä»¥åŠé‡å­ä¸­ç»§å™¨éœ€æ±‚ç­‰æŒ‘æˆ˜ï¼Œå¹¶å¼ºè°ƒäº†QKDåœ¨ä¿æŠ¤å…³é”®é€šä¿¡å…å—æœªæ¥é‡å­å¨èƒæ–¹é¢æ—¥ç›Šå¢é•¿çš„é‡è¦æ€§ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Quantum Key Distribution (QKD) is a technology that ensures secure communication by leveraging the principles of quantum mechanics, such as the no-cloning theorem and quantum uncertainty. This chapter provides an overview of this quantum technology's maturity and trends. It highlights significant advancements in single-photon sources and detection technologies that have brought QKD closer to widespread adoption, including real-world deployments by industry leaders. While addressing challenges such as cost, integration, standardization, and the need for quantum repeaters, the chapter emphasizes the growing importance of QKD in securing mission-critical communications against future quantum threats. Through its unique ability to achieve information-theoretic security, QKD is poised to play a vital role in quantum-safe cryptographic algorithms and protocols.

</details>

---

### 29. [CrossLLM-Mamba: Multimodal State Space Fusion of LLMs for RNA Interaction Prediction](https://arxiv.org/abs/2602.22236)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22236`](https://arxiv.org/abs/2602.22236)
- ğŸ‘¥ ä½œè€…: Rabeya Tus Sadia, Qiang Ye, Qiang Cheng
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22236.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯åˆ©ç”¨ç”Ÿç‰©å¤§è¯­è¨€æ¨¡å‹ï¼ˆBioLLMsï¼‰è¿›è¡Œå¤šæ¨¡æ€ç”Ÿç‰©åˆ†å­ç›¸äº’ä½œç”¨é¢„æµ‹ï¼Œç›´æ¥æ¶‰åŠâ€œåŒ–å­¦å¤§æ¨¡å‹â€åœ¨åŒ–å­¦ç”Ÿç‰©å­¦é¢†åŸŸçš„åº”ç”¨ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡é¢˜ä¸ºã€ŠCrossLLM-Mamba: Multimodal State Space Fusion of LLMs for RNA Interaction Predictionã€‹ã€‚å®ƒæå‡ºäº†ä¸€ç§åä¸ºCrossLLM-Mambaçš„æ–°é¢–æ¡†æ¶ï¼Œç”¨äºé¢„æµ‹RNAç›¸å…³çš„ç›¸äº’ä½œç”¨ï¼ˆå¦‚RNA-è›‹ç™½è´¨ã€RNA-å°åˆ†å­ã€RNA-RNAï¼‰ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç”Ÿç‰©å¤§è¯­è¨€æ¨¡å‹ï¼ˆBioLLMsï¼Œå¦‚ESM-2å’ŒRiNALMoï¼‰æä¾›å¼ºå¤§çš„åºåˆ—è¡¨ç¤ºï¼Œå¹¶é€šè¿‡åŒå‘Mambaç¼–ç å™¨å®ç°æ¨¡æ€ç‰¹å®šåµŒå…¥ä¹‹é—´çš„æ·±åº¦â€œä¸²æ‰°â€ã€‚å…¶æ ¸å¿ƒæ˜¯å°†ç›¸äº’ä½œç”¨é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºä¸€ä¸ªçŠ¶æ€ç©ºé—´å¯¹é½é—®é¢˜ï¼Œé€šè¿‡éšè—çŠ¶æ€ä¼ æ’­å¯¹ç›¸äº’ä½œç”¨è¿›è¡ŒåŠ¨æ€å»ºæ¨¡ã€‚è®ºæ–‡åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Accurate prediction of RNA-associated interactions is essential for understanding cellular regulation and advancing drug discovery. While Biological Large Language Models (BioLLMs) such as ESM-2 and RiNALMo provide powerful sequence representations, existing methods rely on static fusion strategies that fail to capture the dynamic, context-dependent nature of molecular binding. We introduce CrossLLM-Mamba, a novel framework that reformulates interaction prediction as a state-space alignment problem. By leveraging bidirectional Mamba encoders, our approach enables deep ``crosstalk'' between modality-specific embeddings through hidden state propagation, modeling interactions as dynamic sequence transitions rather than static feature overlaps. The framework maintains linear computational complexity, making it scalable to high-dimensional BioLLM embeddings. We further incorporate Gaussian noise injection and Focal Loss to enhance robustness against hard-negative samples. Comprehensive experiments across three interaction categories, RNA-protein, RNA-small molecule, and RNA-RNA demonstrate that CrossLLM-Mamba achieves state-of-the-art performance. On the RPI1460 benchmark, our model attains an MCC of 0.892, surpassing the previous best by 5.2\%. For binding affinity prediction, we achieve Pearson correlations exceeding 0.95 on riboswitch and repeat RNA subtypes. These results establish state-space modeling as a powerful paradigm for multi-modal biological interaction prediction.

</details>

---

### 30. [VAE-MS: An Asymmetric Variational Autoencoder for Mutational Signature Extraction](https://arxiv.org/abs/2602.22239)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22239`](https://arxiv.org/abs/2602.22239)
- ğŸ‘¥ ä½œè€…: Ida Egendal, Rasmus Froberg BrÃ¸ndum, Dan J Woodcock ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22239.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§åŸºäºå˜åˆ†è‡ªç¼–ç å™¨çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºä»ç™Œç—‡åŸºå› ç»„æ•°æ®ä¸­æå–çªå˜ç‰¹å¾ã€‚è¿™å±äºâ€œåŒ–å­¦å¤§æ¨¡å‹â€åœ¨è®¡ç®—ç”Ÿç‰©å­¦å’ŒåŒ–å­¦ä¿¡æ¯å­¦ä¸­çš„ä¸€ä¸ªå…·ä½“åº”ç”¨ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡é¢˜ä¸ºã€ŠVAE-MS: An Asymmetric Variational Autoencoder for Mutational Signature Extractionã€‹ã€‚å®ƒæå‡ºäº†ä¸€ç§ç”¨äºç™Œç—‡çªå˜ç‰¹å¾æå–çš„æ–°å‹å˜åˆ†è‡ªç¼–ç å™¨æ¨¡å‹ï¼ˆVAE-MSï¼‰ã€‚çªå˜ç‰¹å¾åˆ†ææ˜¯æ­ç¤ºç™Œç—‡å‘å±•èƒŒåç”Ÿç‰©å­¦è¿‡ç¨‹çš„é‡è¦æ–¹æ³•ã€‚VAE-MSç»“åˆäº†éå¯¹ç§°æ¶æ„å’Œæ¦‚ç‡æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜ç‰¹å¾æå–çš„å¯é æ€§å’Œä¸´åºŠé€‚ç”¨æ€§ã€‚è®ºæ–‡å°†VAE-MSä¸ç°æœ‰çš„é‡‘æ ‡å‡†æ–¹æ³•ï¼ˆå¦‚SigProfilerExtractorï¼‰ä»¥åŠå…¶ä»–å…ˆè¿›æ¨¡å‹ï¼ˆå¦‚MUSE-XAE, SigneRï¼‰è¿›è¡Œäº†æ¯”è¾ƒï¼Œå±•ç¤ºäº†å…¶åœ¨ç»“åˆéçº¿æ€§æå–ä¸æ¦‚ç‡å»ºæ¨¡æ–¹é¢çš„ä¼˜åŠ¿ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Mutational signature analysis has emerged as a powerful method for uncovering the underlying biological processes driving cancer development. However, the signature extraction process, typically performed using non-negative matrix factorization (NMF), often lacks reliability and clinical applicability. To address these limitations, several solutions have been introduced, including the use of neural networks to achieve more accurate estimates and probabilistic methods to better capture natural variation in the data. In this work, we introduce a Variational Autoencoder for Mutational Signatures (VAE-MS), a novel model that leverages both an asymmetric architecture and probabilistic methods for the extraction of mutational signatures. VAE-MS is compared to with three state-of-the-art models for mutational signature extraction: SigProfilerExtractor, the NMF-based gold standard; MUSE-XAE, an autoencoder that employs an asymmetric design without probabilistic components; and SigneR, a Bayesian NMF model, to illustrate the strength in combining a nonlinear extraction with a probabilistic model. In the ability to reconstruct input data and generalize to unseen data, models with probabilistic components (VAE-MS, SigneR) dramatically outperformed models without (SigProfilerExtractor, MUSE-XAE). The NMF-baed models (SigneR, SigProfilerExtractor) had the most accurate reconstructions in simulated data, while VAE-MS reconstructed more accurately on real cancer data. Upon evaluating the ability to extract signatures consistently, no model exhibited a clear advantage over the others. Software for VAE-MS is available at this https URL .

</details>

---

### 31. [Stochastic Neural Networks for Quantum Devices](https://arxiv.org/abs/2602.22241)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22241`](https://arxiv.org/abs/2602.22241)
- ğŸ‘¥ ä½œè€…: Bodo Rosenhahn, Tobias J. Osborne, Christoph Hirche
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22241.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å°†ï¼ˆéšæœºï¼‰ç¥ç»ç½‘ç»œå®ç°ä¸ºé‡å­ç”µè·¯ï¼Œå¹¶æ¢ç´¢å…¶åœ¨é‡å­è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚è¿™ç›´æ¥æ¶‰åŠâ€œåŒ–å­¦å¤§æ¨¡å‹â€åœ¨é‡å­è®¡ç®—è¿™ä¸€æ–°å…´äº¤å‰é¢†åŸŸçš„å½¢å¼å’Œå®ç°ï¼Œä¸åˆ©ç”¨å…ˆè¿›è®¡ç®—æ¨¡å‹è§£å†³åŒ–å­¦/ç§‘å­¦é—®é¢˜ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡é¢˜ä¸ºã€ŠStochastic Neural Networks for Quantum Devicesã€‹ã€‚å®ƒæå‡ºäº†ä¸€ç§åœ¨åŸºäºé—¨çš„é‡å­è®¡ç®—ä¸­ï¼Œå°†éšæœºç¥ç»ç½‘ç»œè¡¨è¾¾å’Œä¼˜åŒ–ä¸ºé‡å­ç”µè·¯çš„æ–¹æ¡ˆã€‚è®ºæ–‡å—ç»å…¸æ„ŸçŸ¥å™¨å¯å‘ï¼Œå¼•å…¥äº†éšæœºç¥ç»å…ƒå¹¶å°†å…¶ç»„åˆæˆé‡å­ç¥ç»ç½‘ç»œã€‚ä½¿ç”¨Kiefer-Wolfowitzç®—æ³•ç»“åˆæ¨¡æ‹Ÿé€€ç«æ¥è®­ç»ƒç½‘ç»œæƒé‡ã€‚å±•ç¤ºäº†å¤šç§æ‹“æ‰‘å’Œæ¨¡å‹ï¼ŒåŒ…æ‹¬æµ…å±‚å…¨è¿æ¥ç½‘ç»œã€Hopfieldç½‘ç»œã€å—é™ç»å°”å…¹æ›¼æœºã€è‡ªç¼–ç å™¨å’Œå·ç§¯ç¥ç»ç½‘ç»œã€‚æ­¤å¤–ï¼Œè¿˜æ¼”ç¤ºäº†å°†ä¼˜åŒ–åçš„ç¥ç»ç½‘ç»œä½œä¸ºGroverç®—æ³•çš„é¢„è¨€æœºï¼Œä»¥å®ç°é‡å­ç”Ÿæˆå¼AIæ¨¡å‹ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

This work presents a formulation to express and optimize stochastic neural networks as quantum circuits in gate-based quantum computing. Motivated by a classical perceptron, stochastic neurons are introduced and combined into a quantum neural network. The Kiefer-Wolfowitz algorithm in combination with simulated annealing is used for training the network weights. Several topologies and models are presented, including shallow fully connected networks, Hopfield Networks, Restricted Boltzmann Machines, Autoencoders and convolutional neural networks. We also demonstrate the combination of our optimized neural networks as an oracle for the Grover algorithm to realize a quantum generative AI model.

</details>

---

### 32. [Multi-Dimensional Spectral Geometry of Biological Knowledge in Single-Cell Transformer Representations](https://arxiv.org/abs/2602.22247)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22247`](https://arxiv.org/abs/2602.22247)
- ğŸ‘¥ ä½œè€…: Ihor Kendiukhov
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22247.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯åˆ†æå’Œè§£é‡Šå•ç»†èƒTransformeræ¨¡å‹ï¼ˆscGPTï¼‰çš„å†…éƒ¨è¡¨ç¤ºå’ŒçŸ¥è¯†ç¼–ç ï¼Œç›´æ¥å›´ç»•â€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆåœ¨ç”Ÿç‰©å­¦/åŒ–å­¦äº¤å‰é¢†åŸŸçš„åº”ç”¨ï¼‰è¿™ä¸€ä¸»é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡é¢˜ä¸ºã€ŠMulti-Dimensional Spectral Geometry of Biological Knowledge in Single-Cell Transformer Representationsã€‹ã€‚å®ƒç³»ç»Ÿåœ°è§£ç äº†å•ç»†èƒåŸºç¡€æ¨¡å‹scGPTå†…éƒ¨è¡¨ç¤ºï¼ˆå³å…¶å­¦ä¹ åˆ°çš„é«˜ç»´åŸºå› è¡¨å¾ï¼‰çš„å‡ ä½•ç»“æ„ã€‚é€šè¿‡è‡ªåŠ¨åŒ–å‡è®¾ç­›é€‰ï¼Œç ”ç©¶å‘ç°scGPTå°†åŸºå› ç»„ç»‡æˆä¸€ä¸ªç»“æ„åŒ–çš„ç”Ÿç‰©åæ ‡ç³»ï¼Œå…¶ä¸­ä¸»å¯¼çš„å…‰è°±è½´æ ¹æ®äºšç»†èƒå®šä½åˆ†ç¦»åŸºå› ï¼Œä¸­é—´å±‚ç¼–ç çº¿ç²’ä½“å’Œå†…è´¨ç½‘ç­‰ç»†èƒå™¨ï¼Œæ­£äº¤è½´ç¼–ç è›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨ç½‘ç»œã€‚è¯¥å·¥ä½œæ­ç¤ºäº†ç”Ÿç‰©Transformerï¼ˆå¦‚scGPTï¼‰å­¦ä¹ äº†ä¸€ä¸ªå¯è§£é‡Šçš„ç»†èƒç»„ç»‡å†…éƒ¨æ¨¡å‹ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Single-cell foundation models such as scGPT learn high-dimensional gene representations, but what biological knowledge these representations encode remains unclear. We systematically decode the geometric structure of scGPT internal representations through 63 iterations of automated hypothesis screening (183 hypotheses tested), revealing that the model organizes genes into a structured biological coordinate system rather than an opaque feature space. The dominant spectral axis separates genes by subcellular localization, with secreted proteins at one pole and cytosolic proteins at the other. Intermediate transformer layers transiently encode mitochondrial and ER compartments in a sequence that mirrors the cellular secretory pathway. Orthogonal axes encode protein-protein interaction networks with graded fidelity to experimentally measured interaction strength (Spearman rho = 1.000 across n = 5 STRING confidence quintiles, p = 0.017). In a compact six-dimensional spectral subspace, the model distinguishes transcription factors from their target genes (AUROC = 0.744, all 12 layers significant). Early layers preserve which specific genes regulate which targets, while deeper layers compress this into a coarser regulator versus regulated distinction. Repression edges are geometrically more prominent than activation edges, and B-cell master regulators BATF and BACH2 show convergence toward the B-cell identity anchor PAX5 across transformer depth. Cell-type marker genes cluster with high fidelity (AUROC = 0.851). Residual-stream geometry encodes biological structure complementary to attention patterns. These results indicate that biological transformers learn an interpretable internal model of cellular organization, with implications for regulatory network inference, drug target prioritization, and model auditing.

</details>

---

### 33. [Flow Matching is Adaptive to Manifold Structures](https://arxiv.org/abs/2602.22486)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22486`](https://arxiv.org/abs/2602.22486)
- ğŸ‘¥ ä½œè€…: Shivam Kumar, Yixin Wang, Lizhen Lin
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22486.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹ç›´æ¥å›´ç»•ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚æµåŒ¹é…ï¼‰åœ¨åˆ†å­ç»“æ„ç”Ÿæˆç­‰é¢†åŸŸçš„åº”ç”¨è¿›è¡Œç†è®ºåˆ†æï¼Œè¿™ä¸â€˜åŒ–å­¦å¤§æ¨¡å‹â€™ä¸»é¢˜ä¸­å…³äºç”Ÿæˆæ¨¡å‹çš„ç†è®ºåŸºç¡€é«˜åº¦ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»ç†è®ºè§’åº¦åˆ†æäº†æµåŒ¹é…ï¼ˆFlow Matchingï¼‰æ–¹æ³•åœ¨ç›®æ ‡åˆ†å¸ƒä½äºä½ç»´æµå½¢ä¸Šçš„æƒ…å†µã€‚æµåŒ¹é…æ˜¯ä¸€ç§å…æ¨¡æ‹Ÿçš„ç”Ÿæˆå»ºæ¨¡æ–¹æ³•ï¼Œé€šè¿‡å­¦ä¹ æºåˆ†å¸ƒï¼ˆå¦‚æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼‰ä¸ç›®æ ‡æ•°æ®åˆ†å¸ƒä¹‹é—´æ’å€¼çš„æ—¶å˜é€Ÿåº¦åœºæ¥ç”Ÿæˆæ ·æœ¬ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œå°½ç®¡æµåŒ¹é…æ–¹æ³•åœ¨æ–‡æœ¬åˆ°å›¾åƒåˆæˆã€è§†é¢‘ç”Ÿæˆå’Œåˆ†å­ç»“æ„ç”Ÿæˆç­‰é«˜ç»´æ•°æ®é›†ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç°æœ‰ç†è®ºåˆ†æå‡è®¾ç›®æ ‡åˆ†å¸ƒå…·æœ‰å¹³æ»‘çš„å…¨ç»´å¯†åº¦ï¼Œæœªèƒ½è§£é‡Šå…¶åœ¨æµå½¢æ”¯æ’‘æ•°æ®ä¸Šçš„æœ‰æ•ˆæ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…å»ºç«‹äº†å½“ç›®æ ‡åˆ†å¸ƒæ”¯æ’‘åœ¨å…‰æ»‘æµå½¢ä¸Šæ—¶ï¼ŒæµåŒ¹é…æ–¹æ³•ä¸­å­¦ä¹ åˆ°çš„é€Ÿåº¦åœºçš„éæ¸è¿‘æ”¶æ•›ä¿è¯ï¼Œå¹¶å°†æ­¤ä¼°è®¡è¯¯å·®é€šè¿‡å¸¸å¾®åˆ†æ–¹ç¨‹ä¼ æ’­ï¼Œå¾—åˆ°äº†ç”±æµåŒ¹é…ç›®æ ‡è¯±å¯¼çš„éšå¼å¯†åº¦ä¼°è®¡å™¨çš„ç»Ÿè®¡ä¸€è‡´æ€§ã€‚æœ€ç»ˆè¯æ˜å…¶æ”¶æ•›é€Ÿç‡æ¥è¿‘æå°æå¤§æœ€ä¼˜ï¼Œä¸”ä»…ä¾èµ–äºå†…åœ¨ç»´åº¦ï¼Œåæ˜ äº†æµå½¢å’Œç›®æ ‡åˆ†å¸ƒçš„å¹³æ»‘æ€§ã€‚è¿™äº›ç»“æœä¸ºæµåŒ¹é…å¦‚ä½•é€‚åº”å†…åœ¨æ•°æ®å‡ ä½•ç»“æ„å¹¶è§„é¿ç»´åº¦è¯…å’’æä¾›äº†åŸç†æ€§è§£é‡Šã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Flow matching has emerged as a simulation-free alternative to diffusion-based generative modeling, producing samples by solving an ODE whose time-dependent velocity field is learned along an interpolation between a simple source distribution (e.g., a standard normal) and a target data distribution. Flow-based methods often exhibit greater training stability and have achieved strong empirical performance in high-dimensional settings where data concentrate near a low-dimensional manifold, such as text-to-image synthesis, video generation, and molecular structure generation. Despite this success, existing theoretical analyses of flow matching assume target distributions with smooth, full-dimensional densities, leaving its effectiveness in manifold-supported settings largely unexplained. To this end, we theoretically analyze flow matching with linear interpolation when the target distribution is supported on a smooth manifold. We establish a non-asymptotic convergence guarantee for the learned velocity field, and then propagate this estimation error through the ODE to obtain statistical consistency of the implicit density estimator induced by the flow-matching objective. The resulting convergence rate is near minimax-optimal, depends only on the intrinsic dimension, and reflects the smoothness of both the manifold and the target distribution. Together, these results provide a principled explanation for how flow matching adapts to intrinsic data geometry and circumvents the curse of dimensionality.

</details>

---

### 34. [Discovery of Interpretable Physical Laws in Materials via Language-Model-Guided Symbolic Regression](https://arxiv.org/abs/2602.22967)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22967`](https://arxiv.org/abs/2602.22967)
- ğŸ‘¥ ä½œè€…: Yifeng Guan, Chuyi Liu, Dongzhan Zhou ç­‰7äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22967.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼•å¯¼ç¬¦å·å›å½’ä»¥å‘ç°ææ–™ç§‘å­¦ä¸­ç‰©ç†å®šå¾‹çš„æ¡†æ¶ã€‚è¿™ç›´æ¥æ¶‰åŠâ€˜åŒ–å­¦å¤§æ¨¡å‹â€™ä¸»é¢˜ä¸­åˆ©ç”¨AI/LLMè¿›è¡Œç§‘å­¦å‘ç°å’Œå»ºæ¨¡çš„ç ”ç©¶æ–¹å‘ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼•å¯¼ç¬¦å·å›å½’ï¼ˆSymbolic Regressionï¼‰æ¥ä»é«˜ç»´æ•°æ®ä¸­å‘ç°å¯è§£é‡Šç‰©ç†å®šå¾‹çš„æ¡†æ¶ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³ä¼ ç»Ÿç¬¦å·å›å½’åœ¨æœç´¢å·¨å¤§å¯èƒ½å½¢å¼ç©ºé—´æ—¶äº§ç”Ÿå¤æ‚ã€éç‰©ç†è§£æå¼çš„éš¾é¢˜ã€‚é€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­åµŒå…¥çš„ç§‘å­¦çŸ¥è¯†æ¥å¼•å¯¼æœç´¢è¿‡ç¨‹ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆåœ°ä»æ•°æ®ä¸­è¯†åˆ«ç‰©ç†å®šå¾‹ã€‚ä½œè€…ä»¥é’™é’›çŸ¿ææ–™çš„å…³é”®æ€§è´¨å»ºæ¨¡ä¸ºä¾‹éªŒè¯äº†è¯¥æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç¼“è§£äº†ä¼ ç»Ÿç¬¦å·å›å½’ä¸­å¸¸è§çš„ç»„åˆçˆ†ç‚¸é—®é¢˜ï¼Œå°†æœ‰æ•ˆæœç´¢ç©ºé—´å‡å°‘äº†çº¦10^5å€ã€‚ç ”ç©¶è¯†åˆ«å‡ºäº†ä¸€ç»„å…³äºä½“æ¨¡é‡ã€å¸¦éš™å’Œææ°§ååº”æ´»æ€§çš„æ–°å…¬å¼ï¼Œè¿™äº›å…¬å¼ä¸ä»…æä¾›äº†æœ‰æ„ä¹‰çš„ç‰©ç†è§è§£ï¼Œè€Œä¸”åœ¨å‡†ç¡®æ€§å’Œç®€æ´æ€§ä¸Šè¶…è¶Šäº†å…ˆå‰çš„å…¬å¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Discovering interpretable physical laws from high-dimensional data is a fundamental challenge in scientific research. Traditional methods, such as symbolic regression, often produce complex, unphysical formulas when searching a vast space of possible forms. We introduce a framework that guides the search process by leveraging the embedded scientific knowledge of large language models, enabling efficient identification of physical laws in the data. We validate our approach by modeling key properties of perovskite materials. Our method mitigates the combinatorial explosion commonly encountered in traditional symbolic regression, reducing the effective search space by a factor of approximately $10^5$. A set of novel formulas for bulk modulus, band gap, and oxygen evolution reaction activity are identified, which not only provide meaningful physical insights but also outperform previous formulas in accuracy and simplicity.

</details>

---

### 35. [Not All Attention is Needed: Parameter and Computation Efficient Transfer Learning for Multi-modal Large Language Models](https://arxiv.org/abs/2403.15226)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2403.15226`](https://arxiv.org/abs/2403.15226)
- ğŸ‘¥ ä½œè€…: Qiong Wu, Weihao Ye, Yiyi Zhou ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2403.15226.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹å›´ç»•å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„é«˜æ•ˆè°ƒä¼˜æ–¹æ³•ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯è§†è§‰è¯­è¨€ï¼Œä½†å…¶æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°ï¼ˆæ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–ã€å‚æ•°é«˜æ•ˆè°ƒä¼˜ï¼‰æ˜¯æ„å»ºå’Œä¼˜åŒ–â€˜åŒ–å­¦å¤§æ¨¡å‹â€™è¿™ç±»å¤æ‚AIæ¨¡å‹æ—¶å¯èƒ½å€Ÿé‰´çš„å…³é”®æŠ€æœ¯ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ–°å‹å‚æ•°å’Œè®¡ç®—é«˜æ•ˆè°ƒä¼˜æ–¹æ³•ï¼Œç§°ä¸ºé«˜æ•ˆæ³¨æ„åŠ›è·³è¿‡ï¼ˆEfficient Attention Skipping, EASï¼‰ã€‚è¯¥æ–¹æ³•é¦–å…ˆæ­ç¤ºäº†å¤šå¤´æ³¨æ„åŠ›ï¼ˆMHAï¼‰â€”â€”MLLMsçš„ä¸»è¦è®¡ç®—å¼€é”€â€”â€”å¯¹äºä¸‹æ¸¸ä»»åŠ¡é€šå¸¸æ˜¯å†—ä½™çš„ã€‚åŸºäºè¿™ä¸€è§‚å¯Ÿï¼ŒEASè¯„ä¼°æ³¨æ„åŠ›å†—ä½™æ€§å¹¶è·³è¿‡è¾ƒä¸é‡è¦çš„MHAä»¥åŠ é€Ÿæ¨ç†ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¿¡æ¯ä¼ æ’­é€‚é…å™¨ï¼ˆpropagation-of-information adapter, PIAï¼‰æ¥æœåŠ¡äºEASçš„æ³¨æ„åŠ›è·³è¿‡å¹¶ä¿æŒå‚æ•°æ•ˆç‡ï¼Œè¯¥é€‚é…å™¨å¯ä»¥è¿›ä¸€æ­¥é‡æ–°å‚æ•°åŒ–åˆ°å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰ä¸­ï¼Œå®ç°é›¶é¢å¤–å»¶è¿Ÿã€‚ä½œè€…å°†EASåº”ç”¨äºæœ€è¿‘æå‡ºçš„MLLMæ¨¡å‹LaVINå’Œä¸€ä¸ªç»å…¸çš„è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹METERï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒã€‚å®éªŒè¡¨æ˜ï¼ŒEASä¸ä»…ä¿æŒäº†é«˜æ€§èƒ½å’Œå‚æ•°æ•ˆç‡ï¼Œè€Œä¸”å¤§å¤§åŠ å¿«äº†æ¨ç†é€Ÿåº¦ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

In this paper, we propose a novel parameter and computation efficient tuning method for Multi-modal Large Language Models (MLLMs), termed Efficient Attention Skipping (EAS). Concretely, we first reveal that multi-head attentions (MHAs), the main computational overhead of MLLMs, are often redundant to downstream tasks. Based on this observation, EAS evaluates the attention redundancy and skips the less important MHAs to speed up inference. Besides, we also propose a novel propagation-of-information adapter (PIA) to serve the attention skipping of EAS and keep parameter efficiency, which can be further re-parameterized into feed-forward networks (FFNs) for zero-extra latency. To validate EAS, we apply it to a recently proposed MLLM called LaVIN and a classic VL pre-trained model called METER, and conduct extensive experiments on a set of benchmarks. The experiments show that EAS not only retains high performance and parameter efficiency, but also greatly speeds up inference speed. For instance, LaVIN-EAS can obtain 89.98\% accuracy on ScineceQA while speeding up inference by 2.2 times to LaVIN

</details>

---

### 36. [StableMaterials: Enhancing Diversity in Material Generation via Semi-Supervised Learning](https://arxiv.org/abs/2406.09293)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2406.09293`](https://arxiv.org/abs/2406.09293)
- ğŸ‘¥ ä½œè€…: Giuseppe Vecchio
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2406.09293.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ç”¨äºç”Ÿæˆç‰©ç†æ¸²æŸ“ï¼ˆPBRï¼‰ææ–™çš„ç”Ÿæˆæ¨¡å‹ï¼ˆStableMaterialsï¼‰ï¼Œè¯¥æ–¹æ³•åŸºäºéšæ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ã€‚ç”Ÿæˆæ¨¡å‹æ˜¯â€˜åŒ–å­¦å¤§æ¨¡å‹â€™çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ï¼Œç‰¹åˆ«æ˜¯åœ¨ææ–™å‘ç°å’Œåˆ†å­ç”Ÿæˆé¢†åŸŸã€‚è™½ç„¶æœ¬æ–‡èšç„¦äºå›¾å½¢å­¦ææ–™ï¼Œä½†å…¶åº•å±‚ç”Ÿæˆæ¨¡å‹æŠ€æœ¯å…·æœ‰é€šç”¨æ€§ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†StableMaterialsï¼Œä¸€ç§é€šè¿‡å°†åŠç›‘ç£å­¦ä¹ ä¸éšæ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ç›¸ç»“åˆæ¥ç”Ÿæˆé€¼çœŸç‰©ç†æ¸²æŸ“ï¼ˆPBRï¼‰ææ–™çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¯¹æŠ—è®­ç»ƒä»ç°æœ‰çš„å¤§è§„æ¨¡å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­æå–çŸ¥è¯†ï¼Œæœ€å°åŒ–å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå¹¶å¢å¼ºç”Ÿæˆçš„å¤šæ ·æ€§ã€‚è¿™ç§è’¸é¦æ–¹æ³•å°†ç”Ÿæˆææ–™çš„åˆ†å¸ƒä¸SDXLæ¨¡å‹çš„å›¾åƒçº¹ç†åˆ†å¸ƒå¯¹é½ï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆåˆå§‹è®­ç»ƒæ•°æ®é›†ä¸­ä¸å­˜åœ¨çš„æ–°ææ–™ã€‚æ­¤å¤–ï¼Œä½œè€…é‡‡ç”¨äº†ä¸€ä¸ªåŸºäºæ‰©æ•£çš„ç»†åŒ–æ¨¡å‹æ¥æé«˜æ ·æœ¬çš„è§†è§‰è´¨é‡å¹¶å®ç°é«˜åˆ†è¾¨ç‡ç”Ÿæˆã€‚æœ€åï¼Œä½œè€…è’¸é¦äº†ä¸€ä¸ªæ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ç”¨äºä»…éœ€å››æ­¥çš„å¿«é€Ÿç”Ÿæˆï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„å¯å¹³é“ºæŠ€æœ¯ï¼Œä»¥å‡å°‘é€šå¸¸ä¸è¾ƒå°‘æ‰©æ•£æ­¥éª¤ç›¸å…³çš„è§†è§‰ä¼ªå½±ã€‚è®ºæ–‡è¯¦ç»†ä»‹ç»äº†StableMaterialsçš„æ¶æ„å’Œè®­ç»ƒè¿‡ç¨‹ï¼Œç°æœ‰LDMæ¡†æ¶å†…åŠç›‘ç£è®­ç»ƒçš„é›†æˆï¼Œå¹¶å±•ç¤ºäº†è¯¥æ–¹æ³•çš„ä¼˜åŠ¿ã€‚ä¸æœ€å…ˆè¿›æ–¹æ³•çš„æ¯”è¾ƒè¯„ä¼°æ˜¾ç¤ºäº†StableMaterialsçš„æœ‰æ•ˆæ€§ï¼Œçªå‡ºäº†å…¶åœ¨è®¡ç®—æœºå›¾å½¢å­¦åŠå…¶ä»–é¢†åŸŸçš„æ½œåœ¨åº”ç”¨ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

We introduce StableMaterials, a novel approach for generating photorealistic physical-based rendering (PBR) materials that integrate semi-supervised learning with Latent Diffusion Models (LDMs). Our method employs adversarial training to distill knowledge from existing large-scale image generation models, minimizing the reliance on annotated data and enhancing the diversity in generation. This distillation approach aligns the distribution of the generated materials with that of image textures from an SDXL model, enabling the generation of novel materials that are not present in the initial training dataset. Furthermore, we employ a diffusion-based refiner model to improve the visual quality of the samples and achieve high-resolution generation. Finally, we distill a latent consistency model for fast generation in just four steps and propose a new tileability technique that removes visual artifacts typically associated with fewer diffusion steps. We detail the architecture and training process of StableMaterials, the integration of semi-supervised training within existing LDM frameworks and show the advantages of our approach. Comparative evaluations with state-of-the-art methods show the effectiveness of StableMaterials, highlighting its potential applications in computer graphics and beyond. StableMaterials is publicly available at this https URL .

</details>

---

### 37. [Efficient Graph Coloring with Neural Networks: A Physics-Inspired Approach for Large Graphs](https://arxiv.org/abs/2408.01503)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2408.01503`](https://arxiv.org/abs/2408.01503)
- ğŸ‘¥ ä½œè€…: Lorenzo Colantonio, Andrea Cacioppo, Federico Scarpati ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2408.01503.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ç”¨äºè§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜ï¼ˆå¦‚å›¾ç€è‰²ï¼‰çš„ç¥ç»æ±‚è§£å™¨æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†å›¾ç¥ç»ç½‘ç»œå’Œç‰©ç†åŸç†ã€‚å›¾ç¥ç»ç½‘ç»œæ˜¯æ„å»ºâ€˜åŒ–å­¦å¤§æ¨¡å‹â€™ï¼ˆç”¨äºåˆ†å­è¡¨ç¤ºã€æ€§è´¨é¢„æµ‹ã€ååº”æ¨ç†ï¼‰çš„æ ¸å¿ƒæ¶æ„ä¹‹ä¸€ã€‚æœ¬æ–‡å¯¹GNNåœ¨å¤æ‚ä¼˜åŒ–é—®é¢˜ä¸­çš„åº”ç”¨è¿›è¡Œäº†æ·±å…¥æ¢ç´¢ï¼Œç›¸å…³æ–¹æ³•å’ŒæŠ€æœ¯å¯èƒ½è¿ç§»è‡³åŒ–å­¦ä¿¡æ¯å­¦ä»»åŠ¡ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªå—ç‰©ç†å­¦å¯å‘çš„ç¥ç»æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç»“åˆå›¾ç¥ç»ç½‘ç»œå’Œç»Ÿè®¡åŠ›å­¦åŸç†ï¼Œå­¦ä¹ è§£å†³å¤§è§„æ¨¡å›¾ç€è‰²å®ä¾‹ã€‚è¯¥æ–¹æ³•æ•´åˆäº†åŸºäºç§æ¤çš„ç›‘ç£ä¿¡å·ã€å¯¹ç§°æ€§ç ´ç¼ºæ­£åˆ™åŒ–å’Œè¿­ä»£å™ªå£°é€€ç«ç¥ç»åŠ¨åŠ›å­¦ï¼Œä»¥å¯¼èˆªèšé›†çš„è§£ç©ºé—´ã€‚å½“è¿­ä»£æ¬¡æ•°ä¸å›¾å¤§å°æˆäºŒæ¬¡æ–¹æ¯”ä¾‹æ—¶ï¼Œå­¦ä¹ åˆ°çš„æ±‚è§£å™¨åœ¨éšæœºå›¾ä¸­è¾¾åˆ°æ¥è¿‘ç†è®ºåŠ¨æ€è½¬å˜çš„ç®—æ³•é˜ˆå€¼ï¼Œå¹¶åœ¨ç§æ¤æ¨æ–­æœºåˆ¶ä¸­å®ç°æ¥è¿‘æœ€ä¼˜çš„æ£€æµ‹æ€§èƒ½ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿä»å°å‹è®­ç»ƒå›¾æ¨å¹¿åˆ°è§„æ¨¡å¤§å‡ ä¸ªæ•°é‡çº§çš„å®ä¾‹ï¼Œè¡¨æ˜ç¥ç»æ¶æ„å¯ä»¥å­¦ä¹ åˆ°åœ¨ç»„åˆä¼˜åŒ–å’Œæ¨æ–­çš„åŸºæœ¬ç›¸è¾¹ç•Œé™„è¿‘ä»ç„¶æœ‰æ•ˆçš„å¯æ‰©å±•ç®—æ³•ç­–ç•¥ã€‚è¿™äº›ç»“æœä¸ºå­¦ä¹ åœ¨ç»„åˆä¼˜åŒ–å’Œæ¨æ–­çš„åŸºæœ¬ç›¸è¾¹ç•Œé™„è¿‘æ“ä½œçš„ç¥ç»æ±‚è§£å™¨å»ºç«‹äº†ä¸€ä¸ªé€šç”¨èŒƒå¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Combinatorial optimization problems near algorithmic phase transitions represent a fundamental challenge for both classical algorithms and machine learning approaches. Among them, graph coloring stands as a prototypical constraint satisfaction problem exhibiting sharp dynamical and satisfiability thresholds. Here we introduce a physics-inspired neural framework that learns to solve large-scale graph coloring instances by combining graph neural networks with statistical-mechanics principles. Our approach integrates a planting-based supervised signal, symmetry-breaking regularization, and iterative noise-annealed neural dynamics to navigate clustered solution landscapes. When the number of iterations scales quadratically with graph size, the learned solver reaches algorithmic thresholds close to the theoretical dynamical transition in random graphs and achieves near-optimal detection performance in the planted inference regime. The model generalizes from small training graphs to instances orders of magnitude larger, demonstrating that neural architectures can learn scalable algorithmic strategies that remain effective in hard connectivity regions. These results establish a general paradigm for learning neural solvers that operate near fundamental phase boundaries in combinatorial optimization and inference.

</details>

---

### 38. [Open-Set Deepfake Detection: A Parameter-Efficient Adaptation Method with Forgery Style Mixture](https://arxiv.org/abs/2408.12791)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2408.12791`](https://arxiv.org/abs/2408.12791)
- ğŸ‘¥ ä½œè€…: Chenqi Kong, Anwei Luo, Peijun Bao ç­‰8äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2408.12791.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ç”¨äºå¼€æ”¾é›†æ£€æµ‹ä»»åŠ¡çš„å‚æ•°é«˜æ•ˆè§†è§‰Transformeræ¨¡å‹ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯Deepfakeæ£€æµ‹ï¼Œä½†å…¶æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°ï¼ˆå‚æ•°é«˜æ•ˆè°ƒä¼˜ã€æ¨¡å‹æ³›åŒ–ï¼‰æ˜¯æ„å»ºå’Œä¼˜åŒ–â€˜åŒ–å­¦å¤§æ¨¡å‹â€™ï¼ˆå¦‚ç”¨äºå…‰è°±åˆ†ææˆ–åˆ†å­å±æ€§é¢„æµ‹çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼‰æ—¶å¯èƒ½é¢ä¸´å’Œéœ€è¦è§£å†³çš„å…±æ€§é—®é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡é’ˆå¯¹å¼€æ”¾é›†äººè„¸ä¼ªé€ æ£€æµ‹çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é€šç”¨ä¸”å‚æ•°é«˜æ•ˆçš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŸºäºä¸€ä¸ªå‡è®¾ï¼šä¸åŒçš„ä¼ªé€ æºåŸŸè¡¨ç°å‡ºä¸åŒçš„é£æ ¼ç»Ÿè®¡ç‰¹å¾ã€‚å…ˆå‰çš„æ–¹æ³•é€šå¸¸éœ€è¦å¯¹é¢„è®­ç»ƒç½‘ç»œè¿›è¡Œå®Œå…¨å¾®è°ƒï¼Œæ¶ˆè€—å¤§é‡æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚ä¸ºæ­¤ï¼Œä½œè€…è®¾è®¡äº†ä¸€ç§ä¼ªé€ é£æ ¼æ··åˆå…¬å¼ï¼Œä»¥å¢å¼ºä¼ªé€ æºåŸŸçš„å¤šæ ·æ€§ï¼Œä»è€Œæé«˜æ¨¡å‹å¯¹æœªè§åŸŸçš„æ³›åŒ–èƒ½åŠ›ã€‚å€Ÿé‰´è§†è§‰Transformerï¼ˆViTï¼‰åœ¨äººè„¸ä¼ªé€ æ£€æµ‹ä¸­çš„æœ€æ–°è¿›å±•ï¼Œä½œè€…å¼€å‘äº†ä¸€ä¸ªå‚æ•°é«˜æ•ˆçš„åŸºäºViTçš„æ£€æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åŒ…å«è½»é‡çº§çš„ä¼ªé€ ç‰¹å¾æå–æ¨¡å—ï¼Œå¹¶ä½¿æ¨¡å‹èƒ½å¤ŸåŒæ—¶æå–å…¨å±€å’Œå±€éƒ¨ä¼ªé€ çº¿ç´¢ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œä»…ä¼˜åŒ–æ’å…¥çš„è½»é‡çº§æ¨¡å—ï¼Œä¿æŒåŸå§‹ViTç»“æ„åŠå…¶é¢„è®­ç»ƒçš„ImageNetæƒé‡ä¸å˜ã€‚è¿™ç§è®­ç»ƒç­–ç•¥æœ‰æ•ˆåœ°ä¿ç•™äº†ä¿¡æ¯ä¸°å¯Œçš„é¢„è®­ç»ƒçŸ¥è¯†ï¼ŒåŒæ—¶çµæ´»åœ°å°†æ¨¡å‹é€‚åº”äºDeepfakeæ£€æµ‹ä»»åŠ¡ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€è®¾è®¡çš„æ¨¡å‹ä»¥æ˜¾è‘—å‡å°‘çš„å¯è®­ç»ƒå‚æ•°å®ç°äº†æœ€å…ˆè¿›çš„æ³›åŒ–èƒ½åŠ›ï¼Œä»£è¡¨äº†å‘å¼€æ”¾é›†Deepfakeæ£€æµ‹è¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Open-set face forgery detection poses significant security threats and presents substantial challenges for existing detection models. These detectors primarily have two limitations: they cannot generalize across unknown forgery domains and inefficiently adapt to new data. To address these issues, we introduce an approach that is both general and parameter-efficient for face forgery detection. It builds on the assumption that different forgery source domains exhibit distinct style statistics. Previous methods typically require fully fine-tuning pre-trained networks, consuming substantial time and computational resources. In turn, we design a forgery-style mixture formulation that augments the diversity of forgery source domains, enhancing the model's generalizability across unseen domains. Drawing on recent advancements in vision transformers (ViT) for face forgery detection, we develop a parameter-efficient ViT-based detection model that includes lightweight forgery feature extraction modules and enables the model to extract global and local forgery clues simultaneously. We only optimize the inserted lightweight modules during training, maintaining the original ViT structure with its pre-trained ImageNet weights. This training strategy effectively preserves the informative pre-trained knowledge while flexibly adapting the model to the task of Deepfake detection. Extensive experimental results demonstrate that the designed model achieves state-of-the-art generalizability with significantly reduced trainable parameters, representing an important step toward open-set Deepfake detection in the wild.

</details>

---

### 39. [Beyond Attribution: Unified Concept-Level Explanations](https://arxiv.org/abs/2410.12439)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2410.12439`](https://arxiv.org/abs/2410.12439)
- ğŸ‘¥ ä½œè€…: Junhao Liu, Haonan Yu, Xin Zhang
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2410.12439.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªä¸ºAIæ¨¡å‹ï¼ˆåŒ…æ‹¬å¤šæ¨¡æ€æ¨¡å‹ï¼‰æä¾›åŸºäºæ¦‚å¿µçš„è§£é‡Šçš„é€šç”¨æ¡†æ¶ï¼ˆUnCLEï¼‰ã€‚æ¨¡å‹å¯è§£é‡Šæ€§æ˜¯â€˜åŒ–å­¦å¤§æ¨¡å‹â€™å’Œâ€˜è´¨è°±ç»“æ„æ¨ç†â€™æ¨¡å‹åœ¨å®é™…ç§‘å­¦åº”ç”¨ä¸­å–å¾—ä¿¡ä»»å’ŒéªŒè¯å…¶é¢„æµ‹çš„å…³é”®éœ€æ±‚ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•ä¸ºå¤æ‚æ¨¡å‹çš„è§£é‡Šæä¾›äº†æ–°æ€è·¯ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé€šç”¨æ¡†æ¶UnCLEï¼Œæ—¨åœ¨å°†ç°æœ‰çš„å±€éƒ¨æ¨¡å‹æ— å…³è§£é‡ŠæŠ€æœ¯æå‡åˆ°æä¾›åŸºäºæ¦‚å¿µçš„è§£é‡Šã€‚ç°æœ‰çš„åŸºäºæ¦‚å¿µçš„æ¨¡å‹æ— å…³è§£é‡Šæ–¹æ³•èŒƒå›´æœ‰é™ï¼Œä¸»è¦å…³æ³¨å½’å› è§£é‡Šï¼Œè€Œå¿½ç•¥äº†å……åˆ†æ¡ä»¶å’Œåäº‹å®ç­‰å¤šç§å½¢å¼ï¼Œä»è€Œç¼©å°äº†å…¶å®ç”¨æ€§ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼ŒUnCLEé€šè¿‡åˆ©ç”¨å¤§å‹é¢„è®­ç»ƒæ¨¡å‹æ‰°åŠ¨ï¼Œç»Ÿä¸€æ‰©å±•äº†ç°æœ‰çš„å±€éƒ¨æ¨¡å‹æ— å…³æ–¹æ³•ï¼Œä»¥æä¾›ç»Ÿä¸€çš„åŸºäºæ¦‚å¿µçš„è§£é‡Šã€‚ä½œè€…å°†UnCLEå®ä¾‹åŒ–ï¼Œä»¥ä¸‰ç§å½¢å¼æä¾›åŸºäºæ¦‚å¿µçš„è§£é‡Šï¼šå½’å› ã€å……åˆ†æ¡ä»¶å’Œåäº‹å®ï¼Œå¹¶å°†å…¶åº”ç”¨äºæµè¡Œçš„æ–‡æœ¬ã€å›¾åƒå’Œå¤šæ¨¡æ€æ¨¡å‹ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒUnCLEæä¾›çš„è§£é‡Šæ¯”æœ€å…ˆè¿›çš„åŸºäºæ¦‚å¿µçš„è§£é‡Šæ–¹æ³•æ›´å¿ å®ï¼Œå¹¶ä¸”æä¾›äº†æ»¡è¶³å„ç§ç”¨æˆ·éœ€æ±‚çš„æ›´ä¸°å¯Œçš„è§£é‡Šå½¢å¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

There is an increasing need to integrate model-agnostic explanation techniques with concept-based approaches, as the former can explain models across different architectures while the latter makes explanations more faithful and understandable to end-users. However, existing concept-based model-agnostic explanation methods are limited in scope, mainly focusing on attribution-based explanations while neglecting diverse forms like sufficient conditions and counterfactuals, thus narrowing their utility. To bridge this gap, we propose a general framework UnCLE to elevate existing local model-agnostic techniques to provide concept-based explanations. Our key insight is that we can uniformly extend existing local model-agnostic methods to provide unified concept-based explanations with large pre-trained model perturbation. We have instantiated UnCLE to provide concept-based explanations in three forms: attributions, sufficient conditions, and counterfactuals, and applied it to popular text, image, and multimodal models. Our evaluation results demonstrate that UnCLE provides explanations more faithful than state-of-the-art concept-based explanation methods, and provides richer explanation forms that satisfy various user needs.

</details>

---

### 40. [LLM4AD: A Platform for Algorithm Design with Large Language Model](https://arxiv.org/abs/2412.17287)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2412.17287`](https://arxiv.org/abs/2412.17287)
- ğŸ‘¥ ä½œè€…: Fei Liu, Rui Zhang, Zhuoliang Xie ç­‰13äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2412.17287.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å¹³å°ï¼ˆLLM4ADï¼‰ï¼Œä¸“é—¨ç”¨äºLLMè¾…åŠ©çš„ç®—æ³•è®¾è®¡ã€‚è¯¥å¹³å°æä¾›äº†å·¥å…·ã€æ¥å£å’Œè¯„ä¼°ç¯å¢ƒï¼Œå¯ä½œä¸ºâ€˜åŒ–å­¦å¤§æ¨¡å‹â€™å’Œâ€˜è´¨è°±ç»“æ„æ¨ç†â€™é¢†åŸŸç ”ç©¶äººå‘˜å¼€å‘å’Œæµ‹è¯•æ–°ç®—æ³•ï¼ˆå¦‚ç”¨äºåˆ†å­ä¼˜åŒ–ã€å…‰è°±è§£æçš„æ–°æ–¹æ³•ï¼‰çš„æ½œåœ¨èµ„æºæˆ–å·¥å…·ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†LLM4ADï¼Œä¸€ä¸ªç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¾…åŠ©ç®—æ³•è®¾è®¡çš„ç»Ÿä¸€Pythonå¹³å°ã€‚LLM4ADæ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå…·æœ‰æ¨¡å—åŒ–å—ï¼Œç”¨äºæœç´¢æ–¹æ³•ã€ç®—æ³•è®¾è®¡ä»»åŠ¡å’ŒLLMæ¥å£ã€‚è¯¥å¹³å°é›†æˆäº†è®¸å¤šå…³é”®æ–¹æ³•ï¼Œå¹¶æ”¯æŒè·¨å¤šä¸ªé¢†åŸŸï¼ˆåŒ…æ‹¬ä¼˜åŒ–ã€æœºå™¨å­¦ä¹ å’Œç§‘å­¦å‘ç°ï¼‰çš„å„ç§ç®—æ³•è®¾è®¡ä»»åŠ¡ã€‚ä½œè€…è¿˜è®¾è®¡äº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ²™ç›’ï¼Œä»¥ç¡®ä¿å¯¹ç®—æ³•è¿›è¡Œå®‰å…¨ç¨³å¥çš„è¯„ä¼°ã€‚æ­¤å¤–ï¼Œä½œè€…ç¼–åˆ¶äº†ä¸€å¥—å…¨é¢çš„æ”¯æŒèµ„æºï¼ŒåŒ…æ‹¬æ•™ç¨‹ã€ç¤ºä¾‹ã€ç”¨æˆ·æ‰‹å†Œã€åœ¨çº¿èµ„æºå’Œä¸“ç”¨çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ï¼Œä»¥å¢å¼ºLLM4ADçš„ä½¿ç”¨ä½“éªŒã€‚ä½œè€…ç›¸ä¿¡è¯¥å¹³å°å°†æˆä¸ºä¿ƒè¿›LLMè¾…åŠ©ç®—æ³•è®¾è®¡è¿™ä¸€æ–°å…´ç ”ç©¶æ–¹å‘æœªæ¥å‘å±•çš„å®è´µå·¥å…·ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

We introduce LLM4AD, a unified Python platform for algorithm design (AD) with large language models (LLMs). LLM4AD is a generic framework with modularized blocks for search methods, algorithm design tasks, and LLM interface. The platform integrates numerous key methods and supports a wide range of algorithm design tasks across various domains including optimization, machine learning, and scientific discovery. We have also designed a unified evaluation sandbox to ensure a secure and robust assessment of algorithms. Additionally, we have compiled a comprehensive suite of support resources, including tutorials, examples, a user manual, online resources, and a dedicated graphical user interface (GUI) to enhance the usage of LLM4AD. We believe this platform will serve as a valuable tool for fostering future development in the merging research direction of LLM-assisted algorithm design.

</details>

---

### 41. [Neuro-Symbolic AI for Analytical Solutions of Differential Equations](https://arxiv.org/abs/2502.01476)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2502.01476`](https://arxiv.org/abs/2502.01476)
- ğŸ‘¥ ä½œè€…: Orestis Oikonomou, Levi Lingsch, Dana Grund ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2502.01476.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªç¥ç»ç¬¦å·æ¡†æ¶ï¼ˆSIGSï¼‰ï¼Œç”¨äºè‡ªåŠ¨å‘ç°å¾®åˆ†æ–¹ç¨‹çš„è§£æè§£ã€‚è™½ç„¶ä¸ç›´æ¥é’ˆå¯¹åŒ–å­¦ï¼Œä½†è¯¥æ–¹æ³•è®ºï¼ˆç»“åˆç¬¦å·æ¨ç†ä¸ç¥ç»æœç´¢ï¼‰æ˜¯æ¨è¿›â€˜åŒ–å­¦å¤§æ¨¡å‹â€™ç§‘å­¦å‘ç°èƒ½åŠ›ï¼ˆå¦‚ä»æ•°æ®ä¸­å‘ç°ç‰©ç†å®šå¾‹ã€æ¨å¯¼ååº”åŠ¨åŠ›å­¦æ–¹ç¨‹ï¼‰çš„å‰æ²¿æ–¹å‘ï¼Œå…·æœ‰é«˜åº¦çš„ç›¸å…³æ€§ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†SIGSï¼Œä¸€ä¸ªç”¨äºè‡ªåŠ¨å‘ç°å¾®åˆ†æ–¹ç¨‹è§£æè§£çš„ç¥ç»ç¬¦å·æ¡†æ¶ã€‚SIGSä½¿ç”¨å½¢å¼è¯­æ³•ä»…ç”Ÿæˆè¯­æ³•æœ‰æ•ˆçš„æ„å»ºå—ï¼Œå°†è¿™äº›è¡¨è¾¾å¼åµŒå…¥è¿ç»­ç©ºé—´ï¼Œç„¶åæœç´¢è¯¥ç©ºé—´ä»¥é€šè¿‡æœ€å°åŒ–åŸºäºç‰©ç†çš„æ®‹å·®æ¥ç»„è£…ã€è¯„åˆ†å’Œç»†åŒ–å€™é€‰é—­å¼è§£ã€‚è¯¥è®¾è®¡å°†ç¬¦å·æ¨ç†ä¸æ•°å€¼ä¼˜åŒ–ç›¸ç»Ÿä¸€ï¼›è¯­æ³•çº¦æŸå€™é€‰è§£å—åœ¨æ„é€ ä¸Šæ˜¯æ­£ç¡®çš„ï¼Œè€Œæ½œåœ¨æœç´¢ä½¿æ¢ç´¢æ˜“äºå¤„ç†ä¸”æ— éœ€æ•°æ®ã€‚SIGSæ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿï¼ˆiï¼‰è§£ææ±‚è§£éçº¿æ€§åå¾®åˆ†æ–¹ç¨‹è€¦åˆç³»ç»Ÿï¼Œï¼ˆiiï¼‰åœ¨è¯­æ³•æœªæŒ‡å®šæƒ…å†µä¸‹å‘ç°è§£ï¼Œä»¥åŠï¼ˆiiiï¼‰ä¸ºç¼ºä¹å·²çŸ¥é—­å¼è§£çš„åå¾®åˆ†æ–¹ç¨‹äº§ç”Ÿç²¾ç¡®ç¬¦å·è¿‘ä¼¼çš„ç¥ç»ç¬¦å·æ–¹æ³•ã€‚æ€»ä½“è€Œè¨€ï¼ŒSIGSåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šæ¯”ç°æœ‰ç¬¦å·æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¸Šå®ç°äº†æ•°é‡çº§çš„æ”¹è¿›ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Analytical solutions to differential equations offer exact, interpretable insight but are rarely available because discovering them requires expert intuition or exhaustive search in combinatorial spaces. We introduce SIGS, a neuro-symbolic framework that automates this process. SIGS uses a formal grammar to generate only syntactically valid building blocks, embeds these expressions into a continuous space, and then searches this space to assemble, score, and refine candidate closed-form solutions by minimizing a physics-based residual. This design unifies symbolic reasoning with numerical optimization; the grammar constrains candidate solution blocks to be proper by construction, while the latent search makes exploration tractable and data-free. SIGS is the first neuro-symbolic method to (i) analytically solve coupled systems of nonlinear PDEs, (ii) discover solutions under grammar misspecification, and (iii) produce accurate symbolic approximations for PDEs lacking known closed-form solutions. Overall, SIGS achieves orders-of-magnitude improvements in accuracy and efficiency over existing symbolic methods on standard benchmarks.

</details>

---

### 42. [CLIP-Free, Label Free, Unsupervised Concept Bottleneck Models](https://arxiv.org/abs/2503.10981)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2503.10981`](https://arxiv.org/abs/2503.10981)
- ğŸ‘¥ ä½œè€…: Fawaz Sammani, Jonas Fischer, Nikos Deligiannis
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2503.10981.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘æ— éœ€CLIPå’Œäººå·¥æ ‡æ³¨çš„æ¦‚å¿µç“¶é¢ˆæ¨¡å‹ï¼ˆCBMï¼‰æ„å»ºæ–¹æ³•ã€‚æ¦‚å¿µç“¶é¢ˆæ¨¡å‹æ˜¯ä¸€ç§å¯è§£é‡Šçš„AIæ¨¡å‹ï¼Œå…¶æ€æƒ³å¯ä»¥è¿ç§»åˆ°â€˜åŒ–å­¦å¤§æ¨¡å‹â€™å’Œâ€˜è´¨è°±ç»“æ„æ¨ç†â€™ä¸­ï¼Œç”¨äºæ„å»ºå…·æœ‰äººç±»å¯ç†è§£ä¸­é—´æ¦‚å¿µï¼ˆå¦‚å®˜èƒ½å›¢ã€ç¢ç‰‡ç¦»å­ï¼‰çš„é¢„æµ‹æ¨¡å‹ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„å¯ä¿¡åº¦å’Œå¯è§£é‡Šæ€§ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œå¯ä»¥å°†ä»»ä½•å†»ç»“çš„è§†è§‰åˆ†ç±»å™¨è½¬æ¢ä¸ºæ¦‚å¿µç“¶é¢ˆæ¨¡å‹ï¼ˆCBMï¼‰ï¼Œè€Œæ— éœ€å›¾åƒ-æ¦‚å¿µæ ‡ç­¾ï¼ˆæ— æ ‡ç­¾ï¼‰ã€ä¸ä¾èµ–CLIPæ¨¡å‹ï¼ˆæ— CLIPï¼‰ï¼Œå¹¶ä»¥æ— ç›‘ç£æ–¹å¼æ¨å¯¼çº¿æ€§åˆ†ç±»å™¨ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†åŸå§‹åˆ†ç±»å™¨çš„åˆ†å¸ƒï¼ˆåœ¨ç¦»æ•£ç±»åˆ«ç´¢å¼•ä¸Šï¼‰ä¸å…¶ä»æ–‡æœ¬ç±»åˆ«åç§°æ´¾ç”Ÿçš„ç›¸åº”è§†è§‰-è¯­è¨€å¯¹åº”åˆ†å¸ƒå¯¹é½ï¼ŒåŒæ—¶ä¿ç•™åˆ†ç±»å™¨çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•ä¸éœ€è¦çœŸå®å›¾åƒ-ç±»åˆ«æ ‡æ³¨ï¼Œå…·æœ‰é«˜åº¦æ•°æ®æ•ˆç‡ï¼Œå¹¶ä¿ç•™äº†åˆ†ç±»å™¨çš„æ¨ç†è¿‡ç¨‹ã€‚åœ¨è¶…è¿‡40ä¸ªè§†è§‰åˆ†ç±»å™¨ä¸Šåº”ç”¨å’Œæµ‹è¯•ï¼Œæ‰€å¾—å‡ºçš„æ— ç›‘ç£ã€æ— æ ‡ç­¾å’Œæ— CLIPçš„CBMï¼ˆU-F^2-CBMï¼‰è®¾ç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼Œç”šè‡³è¶…è¿‡äº†æœ‰ç›‘ç£çš„åŸºäºCLIPçš„CBMã€‚ä½œè€…è¿˜è¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ç”¨äºé›¶æ ·æœ¬å›¾åƒæè¿°ï¼Œä¼˜äºåŸºäºCLIPçš„ç°æœ‰æ–¹æ³•ï¼Œå¹¶è¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Concept Bottleneck Models (CBMs) map dense feature representations into human-interpretable concepts which are then combined linearly to make a prediction. However, modern CBMs rely on the CLIP model to obtain image-concept annotations, and it remains unclear how to design CBMs without the CLIP bottleneck. Methods that do not use CLIP instead require manual, labor intensive annotation to associate feature representations with concepts. Furthermore, all CBMs necessitate training a linear classifier to map the extracted concepts to class labels. In this work, we lift all three limitations simultaneously by proposing a method that converts any frozen visual classifier into a CBM without requiring image-concept labels (label-free), without relying on the CLIP model (CLIP-free), and by deriving the linear classifier in an unsupervised manner. Our method is formulated by aligning the original classifier's distribution (over discrete class indices) with its corresponding vision-language counterpart distribution derived from textual class names, while preserving the classifier's performance. The approach requires no ground-truth image-class annotations, and is highly data-efficient and preserves the classifier's reasoning process. Applied and tested on over 40 visual classifiers, our resulting unsupervised, label-free and CLIP-free CBM (U-F$^2$-CBM) sets a new state of the art, surpassing even supervised CLIP-based CBMs. We also show that our method can be used for zero-shot image captioning, outperforming existing methods based on CLIP, and achieving state-of-art.

</details>

---

### 43. [Compositional-ARC: Assessing Systematic Generalization in Abstract Spatial Reasoning](https://arxiv.org/abs/2504.01445)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2504.01445`](https://arxiv.org/abs/2504.01445)
- ğŸ‘¥ ä½œè€…: Philipp Mondorf, Shijia Zhou, Monica Riedler ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2504.01445.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯è¯„ä¼°å’Œæå‡AIæ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯Transformeræ¶æ„ï¼‰çš„ç³»ç»Ÿæ€§ç»„åˆæ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§èƒ½åŠ›å¯¹äºâ€˜åŒ–å­¦å¤§æ¨¡å‹â€™è‡³å…³é‡è¦ï¼Œä¾‹å¦‚éœ€è¦æ¨¡å‹ç†è§£å·²çŸ¥åŒ–å­¦ååº”æˆ–åˆ†å­ç‰‡æ®µçš„æ–°ç»„åˆï¼Œæˆ–ä»æœ‰é™çš„è´¨è°±ç¢ç‰‡æ¨¡å¼æ¨ç†å‡ºæ–°çš„åˆ†å­ç»“æ„ã€‚æœ¬æ–‡çš„ç ”ç©¶èŒƒå¼ï¼ˆå…ƒå­¦ä¹ ã€ç»„åˆæ€§è¯„ä¼°ï¼‰å¯¹è¯¥ä¸»é¢˜æœ‰ç›´æ¥å€Ÿé‰´æ„ä¹‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡å¼•å…¥äº†Compositional-ARCæ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹ä»å·²çŸ¥å‡ ä½•å˜æ¢ï¼ˆå¦‚å¹³ç§»ã€æ—‹è½¬ï¼‰ç³»ç»Ÿæ³›åŒ–åˆ°è¿™äº›å˜æ¢çš„æ–°ç»„åˆï¼ˆå¦‚å¹³ç§»+æ—‹è½¬ï¼‰çš„èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸€ä¸ªåŸºäºTransformerçš„å°å‹ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œé€šè¿‡ä¸ºç»„åˆæ€§è®¾è®¡çš„å…ƒå­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥ç³»ç»Ÿæ€§åœ°æ³›åŒ–åˆ°å…ˆå‰æœªè§è¿‡çš„å˜æ¢ç»„åˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡è¯¥æ¨¡å‹åªæœ‰570ä¸‡ä¸ªå‚æ•°ï¼Œä½†å…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆåŒ…æ‹¬o3-miniã€GPT-4oå’ŒGemini 2.0 Flashï¼Œè¿™äº›æ¨¡å‹æœªèƒ½è¡¨ç°å‡ºç±»ä¼¼çš„ç³»ç»Ÿè¡Œä¸ºï¼‰ï¼Œå¹¶ä¸ARC prize 2024çš„è·èƒœæ¨¡å‹ï¼ˆä¸€ä¸ªé€šè¿‡æµ‹è¯•æ—¶è®­ç»ƒçš„80äº¿å‚æ•°LLMï¼‰è¡¨ç°ç›¸å½“ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†å…ƒå­¦ä¹ åœ¨ä¿ƒè¿›è¯­è¨€ä»»åŠ¡ä¹‹å¤–çš„ç³»ç»Ÿæ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¼€å‘æ›´ç¨³å¥å’Œå¯æ³›åŒ–çš„æ¨¡å‹æŒ‡æ˜äº†æœ‰å¸Œæœ›çš„æ–¹å‘ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Systematic generalization refers to the capacity to understand and generate novel combinations from known components. Despite recent progress by large language models (LLMs) across various domains, these models often fail to extend their knowledge to novel compositional scenarios, revealing notable limitations in systematic generalization. There has been an ongoing debate about whether neural networks possess the capacity for systematic generalization, with recent studies suggesting that meta-learning approaches designed for compositionality can significantly enhance this ability. However, these insights have largely been confined to linguistic problems, leaving their applicability to other tasks an open question. In this study, we extend meta-learning for compositionality to the domain of abstract spatial reasoning. To this end, we introduce $\textit{Compositional-ARC}\unicode{x2014}$a dataset designed to evaluate the capacity of models to systematically generalize from known geometric transformations (e.g., translation, rotation) of abstract two-dimensional objects to novel combinations of these transformations (e.g., translation+rotation). Our results show that a small transformer-based encoder-decoder model, trained via meta-learning for compositionality, can systematically generalize to previously unseen transformation compositions. Notably, despite having only 5.7M parameters, this model significantly outperforms state-of-the-art LLMs$\unicode{x2014}$including o3-mini, GPT-4o, and Gemini 2.0 Flash, which fail to exhibit similar systematic behavior$\unicode{x2014}$and performs on par with the winning model of the ARC prize 2024, an 8B-parameter LLM trained via test-time training. Our findings highlight the effectiveness of meta-learning in promoting systematicity beyond linguistic tasks, suggesting a promising direction toward more robust and generalizable models.

</details>

---

### 44. [The Spacetime of Diffusion Models: An Information Geometry Perspective](https://arxiv.org/abs/2505.17517)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2505.17517`](https://arxiv.org/abs/2505.17517)
- ğŸ‘¥ ä½œè€…: RafaÅ‚ Karczewski, Markus Heinonen, Alison Pouplin ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2505.17517.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹å›´ç»•åŒ–å­¦ä¿¡æ¯å­¦ä¸­çš„ä¸€ä¸ªå…³é”®ä¸»é¢˜â€”â€”åˆ†å­ç³»ç»Ÿçš„è¡¨ç¤ºä¸ç”Ÿæˆæ¨¡å‹ï¼ˆæ‰©æ•£æ¨¡å‹ï¼‰ã€‚è®ºæ–‡æå‡ºçš„å‡ ä½•æ¡†æ¶å’Œç¼–è¾‘è·ç¦»ç›´æ¥ä¸åˆ†å­ç»“æ„çš„æ¨ç†ã€ç¼–è¾‘å’Œé‡‡æ ·ç›¸å…³ï¼Œè¿™æ˜¯è´¨è°±ç»“æ„æ¨ç†å’ŒåŒ–å­¦å¤§æ¨¡å‹ï¼ˆç”¨äºåˆ†å­ç”Ÿæˆä¸è¡¨ç¤ºï¼‰çš„æ ¸å¿ƒé—®é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»ä¿¡æ¯å‡ ä½•çš„è§’åº¦æå‡ºäº†æ‰©æ•£æ¨¡å‹æ½œåœ¨ç©ºé—´çš„ä¸€ç§æ–°é¢–å‡ ä½•è§†è§’ã€‚ä½œè€…æŒ‡å‡ºï¼Œæ ‡å‡†çš„åŸºäºç¡®å®šæ€§æ¦‚ç‡æµODEè§£ç å™¨çš„å›æ‹‰æ–¹æ³•å­˜åœ¨æ ¹æœ¬æ€§ç¼ºé™·ï¼Œå› ä¸ºå®ƒè¿«ä½¿æµ‹åœ°çº¿åœ¨æ•°æ®ç©ºé—´ä¸­è§£ç ä¸ºç›´çº¿æ®µï¼Œä»è€Œå¿½ç•¥äº†æ•°æ®çš„å†…åœ¨å‡ ä½•ç»“æ„ã€‚ä½œä¸ºè¡¥å……ï¼Œæ‰©æ•£æ¨¡å‹ä¹Ÿå…è®¸é€šè¿‡åå‘SDEè¿›è¡Œéšæœºè§£ç ï¼Œè¿™ä½¿å¾—å¯ä»¥ä½¿ç”¨Fisher-Raoåº¦é‡è¿›è¡Œä¿¡æ¯å‡ ä½•å¤„ç†ã€‚ç„¶è€Œï¼Œé€‰æ‹©x_Tä½œä¸ºæ½œåœ¨è¡¨ç¤ºä¼šç”±äºæ— è®°å¿†æ€§å¯¼è‡´è¯¥åº¦é‡åç¼©ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…å¼•å…¥äº†ä¸€ä¸ªæ½œåœ¨æ—¶ç©ºz=(x_t, t)ï¼Œè¯¥æ—¶ç©ºç´¢å¼•äº†æ‰€æœ‰å™ªå£°å°ºåº¦ä¸‹çš„å»å™ªåˆ†å¸ƒæ—p(x_0 | x_t)ï¼Œä»è€Œäº§ç”Ÿäº†ä¸€ä¸ªéå¹³å‡¡çš„å‡ ä½•ç»“æ„ã€‚ä½œè€…è¯æ˜äº†è¿™äº›åˆ†å¸ƒå½¢æˆäº†ä¸€ä¸ªæŒ‡æ•°æ—ï¼Œå¹¶æ¨å¯¼äº†æ›²çº¿é•¿åº¦çš„æ— æ¨¡æ‹Ÿä¼°è®¡å™¨ï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„æµ‹åœ°çº¿è®¡ç®—ã€‚ç”±æ­¤äº§ç”Ÿçš„ç»“æ„å¼•å…¥äº†ä¸€ç§åŸåˆ™æ€§çš„æ‰©æ•£ç¼–è¾‘è·ç¦»ï¼Œå…¶ä¸­æµ‹åœ°çº¿è¿½è¸ªæ•°æ®ä¹‹é—´å™ªå£°å’Œå»å™ªç¼–è¾‘çš„æœ€å°åºåˆ—ã€‚è¿™é¡¹å·¥ä½œè¿˜å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨åˆ†å­ç³»ç»Ÿï¼ˆåŒ…æ‹¬çº¦æŸå˜ä½“ï¼Œå¦‚ä½æ–¹å·®è·ƒè¿å’ŒåŒºåŸŸè§„é¿ï¼‰ä¸­è¿‡æ¸¡è·¯å¾„é‡‡æ ·çš„å¥½å¤„ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

We present a novel geometric perspective on the latent space of diffusion models. We first show that the standard pullback approach, utilizing the deterministic probability flow ODE decoder, is fundamentally flawed. It provably forces geodesics to decode as straight segments in data space, effectively ignoring any intrinsic data geometry beyond the ambient Euclidean space. Complementing this view, diffusion also admits a stochastic decoder via the reverse SDE, which enables an information geometric treatment with the Fisher-Rao metric. However, a choice of $x_T$ as the latent representation collapses this metric due to memorylessness. We address this by introducing a latent spacetime $z=(x_t,t)$ that indexes the family of denoising distributions $p(x_0 | x_t)$ across all noise scales, yielding a nontrivial geometric structure. We prove these distributions form an exponential family and derive simulation-free estimators for curve lengths, enabling efficient geodesic computation. The resulting structure induces a principled Diffusion Edit Distance, where geodesics trace minimal sequences of noise and denoise edits between data. We also demonstrate benefits for transition path sampling in molecular systems, including constrained variants such as low-variance transitions and region avoidance. Code is available at: this https URL .

</details>

---

### 45. [Random Matrix Theory-guided sparse PCA for single-cell RNA-seq data](https://arxiv.org/abs/2509.15429)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2509.15429`](https://arxiv.org/abs/2509.15429)
- ğŸ‘¥ ä½œè€…: Victor ChardÃ¨s
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2509.15429.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ•°æ®å¤„ç†å’Œåˆ†ææ–¹æ³•ï¼ˆåŸºäºRMTçš„ç¨€ç–PCAï¼‰ï¼Œå¹¶åº”ç”¨äºå•ç»†èƒRNA-seqæ•°æ®ã€‚è™½ç„¶ä¸»é¢˜æ›´åå‘ç”Ÿç‰©ä¿¡æ¯å­¦ï¼Œä½†å…¶æ ¸å¿ƒæ˜¯å¼€å‘ç”¨äºé«˜ç»´ã€å™ªå£°ç”Ÿç‰©åˆ†å­æ•°æ®ï¼ˆè½¬å½•ç»„ï¼‰çš„åˆ†æå·¥å…·å’Œç®—æ³•ã€‚è¿™ç§æ•°æ®å¤„ç†å’Œç‰¹å¾æå–æ–¹æ³•åœ¨åŒ–å­¦ä¿¡æ¯å­¦ä¸­å…·æœ‰ç›´æ¥çš„ç±»æ¯”å’Œåº”ç”¨æ½œåŠ›ï¼Œä¾‹å¦‚ç”¨äºå¤„ç†è´¨è°±æ•°æ®æˆ–æ„å»ºåŒ–å­¦æ•°æ®çš„è¡¨ç¤ºï¼Œå› æ­¤æä¾›äº†å¯ç”¨äºç›¸å…³ä¸»é¢˜çš„æ•°æ®åˆ†æèµ„æºå’Œæ–¹æ³•è®ºã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºéšæœºçŸ©é˜µç†è®ºï¼ˆRMTï¼‰çš„ç¨€ç–ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰æ–¹æ³•ï¼Œç”¨äºå¤„ç†å•ç»†èƒRNAæµ‹åºï¼ˆscRNA-seqï¼‰æ•°æ®ã€‚å•ç»†èƒRNA-seqæ•°æ®å™ªå£°é«˜ï¼Œå˜å¼‚æ€§æ¥æºäºç”Ÿç‰©å­¦å·®å¼‚å’ŒæŠ€æœ¯å› ç´ ï¼ˆå¦‚æ‰©å¢åå·®å’Œæœ‰é™çš„RNAæ•è·æ•ˆç‡ï¼‰ï¼Œè¿™ä½¿å¾—å°†è®¡ç®—æµç¨‹é€‚åº”å¼‚æ„æ•°æ®é›†æˆ–ä¸æ–­å‘å±•çš„æŠ€æœ¯å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å¤§å¤šæ•°ç ”ç©¶ä»ç„¶ä¾èµ–ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰è¿›è¡Œé™ç»´ï¼Œå°½ç®¡å·²çŸ¥å…¶åœ¨ç»´æ•°è¾ƒé«˜æ—¶å­˜åœ¨åå·®ã€‚æœ¬æ–‡æ”¹è¿›äº†PCAï¼Œæå‡ºäº†ä¸€ç§åŸºäºéšæœºçŸ©é˜µç†è®ºï¼ˆRMTï¼‰çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç°æœ‰çš„ç¨€ç–PCAç®—æ³•æ¥æŒ‡å¯¼ç¨€ç–ä¸»æˆåˆ†çš„æ¨æ–­ã€‚ä½œè€…é¦–å…ˆå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åŒç™½åŒ–ç®—æ³•ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿè‡ªä¸€è‡´åœ°ä¼°è®¡æ¯ä¸ªåŸºå› åœ¨æ¯ä¸ªç»†èƒä¸­å—è½¬å½•ç»„å™ªå£°å½±å“çš„å¤§å°ï¼Œè€Œæ— éœ€å‡è®¾ç‰¹å®šçš„å™ªå£°åˆ†å¸ƒã€‚è¿™ä½¿å¾—èƒ½å¤Ÿä½¿ç”¨åŸºäºRMTçš„æ ‡å‡†è‡ªåŠ¨é€‰æ‹©ç¨€ç–åº¦æ°´å¹³ï¼Œä»è€Œä½¿ç¨€ç–PCAå‡ ä¹æ— éœ€å‚æ•°ã€‚è¿™ç§åŸºäºæ•°å­¦çš„æ–¹æ³•ä¿ç•™äº†PCAçš„å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶èƒ½å¤Ÿç¨³å¥ã€æ— éœ€äººå·¥å¹²é¢„åœ°æ¨æ–­ç¨€ç–ä¸»æˆåˆ†ã€‚åœ¨ä¸ƒç§å•ç»†èƒRNA-seqæŠ€æœ¯å’Œå››ç§ç¨€ç–PCAç®—æ³•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç³»ç»Ÿåœ°æ”¹å–„äº†ä¸»æˆåˆ†å­ç©ºé—´çš„é‡å»ºï¼Œå¹¶åœ¨ç»†èƒç±»å‹åˆ†ç±»ä»»åŠ¡ä¸­æŒç»­ä¼˜äºåŸºäºPCAã€è‡ªç¼–ç å™¨å’Œæ‰©æ•£çš„æ–¹æ³•ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Single-cell RNA-seq provides detailed molecular snapshots of individual cells but is notoriously noisy. Variability stems from biological differences and technical factors, such as amplification bias and limited RNA capture efficiency, making it challenging to adapt computational pipelines to heterogeneous datasets or evolving technologies. As a result, most studies still rely on principal component analysis (PCA) for dimensionality reduction, valued for its interpretability and robustness, in spite of its known bias in high dimensions. Here, we improve upon PCA with a Random Matrix Theory (RMT)-based approach that guides the inference of sparse principal components using existing sparse PCA algorithms. We first introduce a novel biwhitening algorithm which self-consistently estimates the magnitude of transcriptomic noise affecting each gene in individual cells, without assuming a specific noise distribution. This enables the use of an RMT-based criterion to automatically select the sparsity level, rendering sparse PCA nearly parameter-free. Our mathematically grounded approach retains the interpretability of PCA while enabling robust, hands-off inference of sparse principal components. Across seven single-cell RNA-seq technologies and four sparse PCA algorithms, we show that this method systematically improves the reconstruction of the principal subspace and consistently outperforms PCA-, autoencoder-, and diffusion-based methods in cell-type classification tasks.

</details>

---

### 46. [G-reasoner: Foundation Models for Unified Reasoning over Graph-structured Knowledge](https://arxiv.org/abs/2509.24276)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2509.24276`](https://arxiv.org/abs/2509.24276)
- ğŸ‘¥ ä½œè€…: Linhao Luo, Zicheng Zhao, Junnan Liu ç­‰12äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2509.24276.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªç”¨äºåœ¨ç»“æ„åŒ–çŸ¥è¯†ï¼ˆå¦‚å›¾ï¼‰ä¸Šè¿›è¡Œæ¨ç†çš„ç»Ÿä¸€åŸºç¡€æ¨¡å‹æ¡†æ¶ã€‚è¿™ç›´æ¥ä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€ä¸»é¢˜ç›¸å…³ï¼Œå› ä¸ºåŒ–å­¦é¢†åŸŸçŸ¥è¯†ï¼ˆå¦‚åˆ†å­ç»“æ„ã€ååº”è·¯å¾„ã€æ€§è´¨å…³ç³»ï¼‰å¤©ç„¶é€‚åˆç”¨å›¾æ¥è¡¨ç¤ºã€‚G-reasoneræ¡†æ¶ä¸ºæ„å»ºèƒ½å¤Ÿç†è§£å’Œæ¨ç†åŒ–å­¦å›¾ç»“æ„ï¼ˆå¦‚åˆ†å­å›¾ï¼‰çš„å¤§æ¨¡å‹æä¾›äº†æ–¹æ³•è®ºå’Œæ¶æ„ä¸Šçš„å‚è€ƒï¼Œæ˜¯åŒ–å­¦ä¿¡æ¯å­¦ä¸­æ„å»ºå…·æœ‰æ·±åº¦æ¨ç†èƒ½åŠ›çš„å¤§æ¨¡å‹çš„é‡è¦ç›¸å…³ç ”ç©¶ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†G-reasonerï¼Œä¸€ä¸ªå°†å›¾ä¸è¯­è¨€åŸºç¡€æ¨¡å‹ç›¸é›†æˆçš„ç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºå¯¹å¤šæ ·åŒ–å›¾ç»“æ„çŸ¥è¯†è¿›è¡Œå¯æ‰©å±•æ¨ç†ã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ“…é•¿å¤æ‚æ¨ç†ï¼Œä½†å—é™äºé™æ€å’Œä¸å®Œæ•´çš„å‚æ•°åŒ–çŸ¥è¯†ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡æ•´åˆå¤–éƒ¨çŸ¥è¯†æ¥ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œä½†ç°æœ‰çš„RAGç”±äºä¿¡æ¯ç¢ç‰‡åŒ–å’ŒçŸ¥è¯†ç»“æ„å»ºæ¨¡è–„å¼±ï¼Œåœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­ä»ç„¶å­˜åœ¨å›°éš¾ã€‚å›¾æä¾›äº†ä¸€ç§å¯¹çŸ¥è¯†å†…éƒ¨å…³ç³»è¿›è¡Œå»ºæ¨¡çš„è‡ªç„¶æ–¹å¼ï¼Œä½†LLMsæœ¬è´¨ä¸Šæ˜¯éç»“æ„åŒ–çš„ï¼Œæ— æ³•æœ‰æ•ˆåœ°å¯¹å›¾ç»“æ„æ•°æ®è¿›è¡Œæ¨ç†ã€‚æœ€è¿‘çš„å›¾å¢å¼ºRAGï¼ˆGraphRAGï¼‰è¯•å›¾é€šè¿‡æ„å»ºå®šåˆ¶åŒ–çš„å›¾å¹¶è®©LLMsåœ¨å…¶ä¸Šè¿›è¡Œæ¨ç†æ¥å¼¥åˆè¿™ä¸€å·®è·ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–äºä¸´æ—¶æ€§çš„å›¾è®¾è®¡ã€å¯å‘å¼æœç´¢æˆ–æˆæœ¬é«˜æ˜‚çš„æ™ºèƒ½ä½“æµç¨‹ï¼Œè¿™é˜»ç¢äº†å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†G-reasonerã€‚å…¶æ ¸å¿ƒæ˜¯QuadGraphï¼Œä¸€ä¸ªæ ‡å‡†åŒ–çš„å››å±‚æŠ½è±¡ï¼Œå°†å¼‚æ„çŸ¥è¯†æºç»Ÿä¸€ä¸ºé€šç”¨çš„å›¾è¡¨ç¤ºã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä½œè€…å¼•å…¥äº†ä¸€ä¸ª3400ä¸‡å‚æ•°çš„å›¾åŸºç¡€æ¨¡å‹ï¼ˆGFMï¼‰ï¼Œè¯¥æ¨¡å‹è”åˆæ•è·å›¾æ‹“æ‰‘å’Œæ–‡æœ¬è¯­ä¹‰ï¼Œå¹¶ä¸LLMsé›†æˆä»¥å¢å¼ºä¸‹æ¸¸åº”ç”¨ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚åœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒG-reasoneræŒç»­ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œæ˜¾è‘—å¢å¼ºäº†LLMçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶å®ç°äº†å¼ºå¤§çš„æ•ˆç‡å’Œè·¨å›¾æ³›åŒ–èƒ½åŠ›ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Large language models (LLMs) excel at complex reasoning but remain limited by static and incomplete parametric knowledge. Retrieval-augmented generation (RAG) mitigates this by incorporating external knowledge, yet existing RAGs struggle with knowledge-intensive tasks due to fragmented information and weak modeling of knowledge structure. Graphs offer a natural way to model relationships within knowledge, but LLMs are inherently unstructured and cannot effectively reason over graph-structured data. Recent graph-enhanced RAG (GraphRAG) attempts to bridge this gap by constructing tailored graphs and enabling LLMs to reason on them. However, these methods often depend on ad-hoc graph designs, heuristic search, or costly agent pipelines, which hinder scalability and generalization. To address these challenges, we present G-reasoner, a unified framework that integrates graph and language foundation models for scalable reasoning over diverse graph-structured knowledge. Central to our approach is QuadGraph, a standardized four-layer abstraction that unifies heterogeneous knowledge sources into a common graph representation. Building on this, we introduce a 34M-parameter graph foundation model (GFM) that jointly captures graph topology and textual semantics, and is integrated with LLMs to enhance reasoning in downstream applications. To ensure scalability and efficiency, mixed-precision training and distributed message-passing are implemented to scale GFM with more GPUs. Extensive experiments on six benchmarks show that G-reasoner consistently outperforms state-of-the-art baselines, significantly enhances LLM reasoning, and achieves strong efficiency and cross-graph generalization.

</details>

---

### 47. [Object-Centric Representation Learning for Enhanced 3D Semantic Scene Graph Prediction](https://arxiv.org/abs/2510.04714)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2510.04714`](https://arxiv.org/abs/2510.04714)
- ğŸ‘¥ ä½œè€…: KunHo Heo, GiHyun Kim, SuYeon Kim ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2510.04714.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ä¹‹ä¸€æ˜¯æå‡ºäº†ä¸€ç§ç”¨äºå­¦ä¹ å¯¹è±¡ä¸­å¿ƒè¡¨ç¤ºçš„æ–°é¢–å¯¹æ¯”é¢„è®­ç»ƒç­–ç•¥å’Œç‰¹å¾ç¼–ç å™¨ã€‚è™½ç„¶åº”ç”¨åœºæ™¯æ˜¯3Dåœºæ™¯ç†è§£ï¼Œä½†å…¶æ–¹æ³•è®ºâ€”â€”å³é€šè¿‡è§£è€¦è¡¨ç¤ºå­¦ä¹ å’Œä¸‹æ¸¸ä»»åŠ¡æ¥å­¦ä¹ é«˜åº¦åˆ¤åˆ«æ€§çš„å¯¹è±¡ç‰¹å¾â€”â€”åœ¨åŒ–å­¦ä¿¡æ¯å­¦å’Œè´¨è°±åˆ†æä¸­å…·æœ‰æ½œåœ¨çš„åº”ç”¨ä»·å€¼ã€‚ä¾‹å¦‚ï¼Œåœ¨è´¨è°±ç»“æ„æ¨ç†ä¸­ï¼Œå¯ä»¥å°†è´¨è°±å³°æˆ–åˆ†å­ç‰‡æ®µè§†ä¸ºâ€œå¯¹è±¡â€ï¼Œå­¦ä¹ å…¶åˆ¤åˆ«æ€§è¡¨ç¤ºå¯¹äºæ¨æ–­åˆ†å­ç»“æ„è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œè¯¥è®ºæ–‡æä¾›äº†ä¸€ç§å¯ç”¨äºç›¸å…³ä¸»é¢˜çš„ç‰¹å¾å­¦ä¹ æ–¹æ³•å’Œå·¥å…·ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä¸“æ³¨äº3Dè¯­ä¹‰åœºæ™¯å›¾é¢„æµ‹ä»»åŠ¡ï¼Œæ—¨åœ¨æ£€æµ‹3Dåœºæ™¯ä¸­çš„å¯¹è±¡åŠå…¶è¯­ä¹‰å…³ç³»ã€‚ä½œè€…æŒ‡å‡ºï¼Œå…ˆå‰çš„ç ”ç©¶è™½ç„¶è§£å†³äº†æ•°æ®é›†é™åˆ¶å¹¶æ¢ç´¢äº†åŒ…æ‹¬å¼€æ”¾è¯æ±‡è®¾ç½®åœ¨å†…çš„å„ç§æ–¹æ³•ï¼Œä½†æœªèƒ½ä¼˜åŒ–å¯¹è±¡å’Œå…³ç³»ç‰¹å¾çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œè¡¨ç°å‡ºå¯¹å›¾ç¥ç»ç½‘ç»œçš„è¿‡åº¦ä¾èµ–ï¼Œå°½ç®¡å…¶åˆ¤åˆ«èƒ½åŠ›ä¸è¶³ã€‚æœ¬æ–‡é€šè¿‡å¹¿æ³›åˆ†æè¯æ˜ï¼Œå¯¹è±¡ç‰¹å¾çš„è´¨é‡åœ¨å†³å®šæ•´ä½“åœºæ™¯å›¾å‡†ç¡®æ€§æ–¹é¢èµ·ç€å…³é”®ä½œç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…è®¾è®¡äº†ä¸€ä¸ªé«˜åº¦åˆ¤åˆ«æ€§çš„å¯¹è±¡ç‰¹å¾ç¼–ç å™¨ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§å¯¹æ¯”é¢„è®­ç»ƒç­–ç•¥ï¼Œå°†å¯¹è±¡è¡¨ç¤ºå­¦ä¹ ä¸åœºæ™¯å›¾é¢„æµ‹è§£è€¦ã€‚è¿™ç§è®¾è®¡ä¸ä»…æé«˜äº†å¯¹è±¡åˆ†ç±»çš„å‡†ç¡®æ€§ï¼Œè¿˜ç›´æ¥æ”¹å–„äº†å…³ç³»é¢„æµ‹ã€‚å½“å°†é¢„è®­ç»ƒçš„ç¼–ç å™¨æ’å…¥ç°æœ‰æ¡†æ¶æ—¶ï¼Œåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šéƒ½è§‚å¯Ÿåˆ°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œä½œè€…æœ‰æ•ˆåœ°ç»“åˆäº†å‡ ä½•å’Œè¯­ä¹‰ç‰¹å¾æ¥å®ç°æ›´ä¼˜çš„å…³ç³»é¢„æµ‹ã€‚åœ¨3DSSGæ•°æ®é›†ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºå…ˆå‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

3D Semantic Scene Graph Prediction aims to detect objects and their semantic relationships in 3D scenes, and has emerged as a crucial technology for robotics and AR/VR applications. While previous research has addressed dataset limitations and explored various approaches including Open-Vocabulary settings, they frequently fail to optimize the representational capacity of object and relationship features, showing excessive reliance on Graph Neural Networks despite insufficient discriminative capability. In this work, we demonstrate through extensive analysis that the quality of object features plays a critical role in determining overall scene graph accuracy. To address this challenge, we design a highly discriminative object feature encoder and employ a contrastive pretraining strategy that decouples object representation learning from the scene graph prediction. This design not only enhances object classification accuracy but also yields direct improvements in relationship prediction. Notably, when plugging in our pretrained encoder into existing frameworks, we observe substantial performance improvements across all evaluation metrics. Additionally, whereas existing approaches have not fully exploited the integration of relationship information, we effectively combine both geometric and semantic features to achieve superior relationship prediction. Comprehensive experiments on the 3DSSG dataset demonstrate that our approach significantly outperforms previous state-of-the-art methods. Our code is publicly available at this https URL .

</details>

---

### 48. [Learning Hamiltonian Flow Maps: Mean Flow Consistency for Large-Timestep Molecular Dynamics](https://arxiv.org/abs/2601.22123)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2601.22123`](https://arxiv.org/abs/2601.22123)
- ğŸ‘¥ ä½œè€…: Winfried Ripken, Michael Plainer, Gregor Lied ç­‰8äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2601.22123.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªç”¨äºåˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿçš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œè¿™ç›´æ¥å±äºåŒ–å­¦ä¿¡æ¯å­¦ä¸­åˆ©ç”¨å¤§æ¨¡å‹ï¼ˆå¦‚æœºå™¨å­¦ä¹ åŠ›åœºï¼‰è¿›è¡Œåˆ†å­ç³»ç»Ÿæ¨¡æ‹Ÿå’Œæ€§è´¨é¢„æµ‹çš„æ ¸å¿ƒä¸»é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§å­¦ä¹ å“ˆå¯†é¡¿æµæ˜ å°„çš„æ¡†æ¶ï¼Œç”¨äºæ¨¡æ‹Ÿå“ˆå¯†é¡¿ç³»ç»Ÿçš„é•¿æ—¶é—´æ¼”åŒ–ã€‚è¯¥æ–¹æ³•é€šè¿‡é¢„æµ‹é€‰å®šæ—¶é—´è·¨åº¦å†…çš„å¹³å‡ç›¸ç©ºé—´æ¼”åŒ–ï¼Œå®ç°äº†è¿œè¶…ç»å…¸ç§¯åˆ†å™¨ç¨³å®šæ€§é™åˆ¶çš„å¤§æ—¶é—´æ­¥é•¿æ›´æ–°ã€‚å…¶æ ¸å¿ƒæ˜¯æ–½åŠ äº†ä¸€ä¸ªå…³äºæ—¶é—´å¹³å‡å“ˆå¯†é¡¿åŠ¨åŠ›å­¦çš„â€œå¹³å‡æµä¸€è‡´æ€§â€æ¡ä»¶ã€‚ä¸å…ˆå‰æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶å…è®¸åœ¨æ— éœ€è®¿é—®æœªæ¥çŠ¶æ€çš„æƒ…å†µä¸‹ï¼Œåœ¨ç‹¬ç«‹çš„ç›¸ç©ºé—´æ ·æœ¬ä¸Šè¿›è¡Œè®­ç»ƒï¼Œé¿å…äº†æ˜‚è´µçš„è½¨è¿¹ç”Ÿæˆã€‚è¯¥æ–¹æ³•åœ¨åŒ…æ‹¬ä½¿ç”¨æœºå™¨å­¦ä¹ åŠ›åœºï¼ˆMLFFï¼‰çš„åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿåœ¨å†…çš„å¤šç§å“ˆå¯†é¡¿ç³»ç»Ÿä¸­å¾—åˆ°éªŒè¯ã€‚è¯¥å·¥ä½œä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€ä¸»é¢˜ç›¸å…³ï¼Œå› ä¸ºå®ƒæå‡ºäº†ä¸€ç§ç”¨äºåˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿçš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œè¿™æ˜¯åŒ–å­¦ä¿¡æ¯å­¦å’Œè®¡ç®—åŒ–å­¦ä¸­åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†å­æ¨¡æ‹Ÿå’Œæ€§è´¨é¢„æµ‹çš„æ ¸å¿ƒåº”ç”¨åœºæ™¯ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Simulating the long-time evolution of Hamiltonian systems is limited by the small timesteps required for stable numerical integration. To overcome this constraint, we introduce a framework to learn Hamiltonian Flow Maps by predicting the mean phase-space evolution over a chosen time span, enabling stable large-timestep updates far beyond the stability limits of classical integrators. To this end, we impose a Mean Flow consistency condition for time-averaged Hamiltonian dynamics. Unlike prior approaches, this allows training on independent phase-space samples without access to future states, avoiding expensive trajectory generation. Validated across diverse Hamiltonian systems, our method in particular improves upon molecular dynamics simulations using machine-learned force fields (MLFF). Our models maintain comparable training and inference cost, but support significantly larger integration timesteps while trained directly on widely-available trajectory-free MLFF datasets.

</details>

---

### 49. [A Minimum Variance Path Principle for Accurate and Stable Score-Based Density Ratio Estimation](https://arxiv.org/abs/2602.00834)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.00834`](https://arxiv.org/abs/2602.00834)
- ğŸ‘¥ ä½œè€…: Wei Chen, Jiacheng Li, Shigui Li ç­‰7äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.00834.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å…³äºæ¦‚ç‡åˆ†å¸ƒå»ºæ¨¡ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹åˆ†ç±»/ç¦»æ•£æ•°æ®åœ¨å•çº¯å½¢ä¸Šçš„è¡¨ç¤ºå’Œå­¦ä¹ ã€‚è¿™ç§æ–¹æ³•æ˜¯åŒ–å­¦ä¿¡æ¯å­¦ä¸­åˆ†å­è¡¨ç¤ºå­¦ä¹ ï¼ˆåŒ–å­¦å¤§æ¨¡å‹ï¼‰å’Œè´¨è°±æ•°æ®æ¦‚ç‡å»ºæ¨¡ï¼ˆè´¨è°±ç»“æ„æ¨ç†ï¼‰çš„åŸºç¡€å·¥å…·ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºåœ¨å•çº¯å½¢ä¸Šå­¦ä¹ å’Œé‡‡æ ·æ¦‚ç‡åˆ†å¸ƒçš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å…‰æ»‘åŒå°„å°†å¼€æ”¾å•çº¯å½¢æ˜ å°„åˆ°æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼Œåˆ©ç”¨Aitchisonå‡ ä½•æ¥å®šä¹‰æ˜ å°„ï¼Œå¹¶é€šè¿‡ç‹„åˆ©å…‹é›·æ’å€¼å°†ç¦»æ•£è§‚æµ‹å»é‡åŒ–æˆè¿ç»­è§‚æµ‹ï¼Œä»è€Œæ”¯æŒå¯¹åˆ†ç±»æ•°æ®çš„å»ºæ¨¡ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿé€šè¿‡åŒå°„åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­è¿›è¡Œå¯†åº¦å»ºæ¨¡ï¼ŒåŒæ—¶ä»èƒ½ç²¾ç¡®æ¢å¤åŸå§‹ç¦»æ•£åˆ†å¸ƒã€‚ä¸å…ˆå‰åœ¨å•çº¯å½¢ä¸Šä½¿ç”¨é»æ›¼å‡ ä½•æˆ–è‡ªå®šä¹‰å™ªå£°è¿‡ç¨‹çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­å·¥ä½œï¼ŒåŒæ—¶å°Šé‡Aitchisonå‡ ä½•ï¼Œå¹¶åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå®ç°äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚è¯¥å·¥ä½œä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€å’Œâ€œè´¨è°±ç»“æ„æ¨ç†â€å‡ç›¸å…³ï¼Œå› ä¸ºå®ƒæå‡ºäº†ä¸€ç§å¤„ç†åˆ†ç±»/ç¦»æ•£æ•°æ®ï¼ˆå¦‚åˆ†å­æŒ‡çº¹ã€è´¨è°±å³°çš„å­˜åœ¨/ç¼ºå¤±æˆ–åŒ–åˆç‰©ç±»åˆ«ï¼‰çš„æ¦‚ç‡å»ºæ¨¡æ–¹æ³•ï¼Œè¿™æ˜¯åŒ–å­¦ä¿¡æ¯å­¦ä¸­åˆ†å­è¡¨ç¤ºå’Œè´¨è°±æ•°æ®åˆ†æçš„åŸºç¡€ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Score-based methods are powerful across machine learning, but they face a paradox: theoretically path-independent, yet practically path-dependent. We resolve this by proving that practical training objectives differ from the ideal, ground-truth objective by a crucial, overlooked term: the path variance of the score function. We propose the MVP (**M**imum **V**ariance **P**ath) Principle to minimize this path variance. Our key contribution is deriving a closed-form expression for the variance, making optimization tractable. By parameterizing the path with a flexible Kumaraswamy Mixture Model, our method learns data-adaptive, low-variance paths without heuristic manual selection. This principled optimization of the complete objective yields more accurate and stable estimators, establishing new state-of-the-art results on challenging benchmarks and providing a general framework for optimizing score-based interpolation.

</details>

---

### 50. [Composable and adaptive design of machine learning interatomic potentials guided by Fisher-information analysis](https://arxiv.org/abs/2504.19372)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2504.19372`](https://arxiv.org/abs/2504.19372)
- ğŸ‘¥ ä½œè€…: Weishi Wang, Mark K. Transtrum, Vincenzo Lordi ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2504.19372.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§ç”¨äºæœºå™¨å­¦ä¹ åŸå­é—´åŠ¿ï¼ˆMLIPsï¼‰çš„è‡ªé€‚åº”è®¾è®¡ç­–ç•¥å’Œè¯„ä¼°æ¡†æ¶ã€‚MLIPsæ˜¯åŒ–å­¦ä¿¡æ¯å­¦å’Œè®¡ç®—åŒ–å­¦ä¸­ç”¨äºé¢„æµ‹åˆ†å­å’Œææ–™æ€§è´¨çš„æ ¸å¿ƒæ¨¡å‹ç±»å‹ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡è¿­ä»£æ¨¡å‹é‡æ„å’ŒåŸºäºè´¹èˆå°”ä¿¡æ¯çš„è¯„ä¼°ï¼Œæ—¨åœ¨åˆ›å»ºæ›´ä¼˜ã€æ›´å¯è§£é‡Šçš„åŒ–å­¦æ¨¡å‹ï¼Œè¿™ç›´æ¥å›´ç»•â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„ä¸»é¢˜ï¼Œå³å¼€å‘æ›´å…ˆè¿›ã€æ›´æ™ºèƒ½çš„åŒ–å­¦é¢†åŸŸæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºæœºå™¨å­¦ä¹ åŸå­é—´åŠ¿ï¼ˆMLIPsï¼‰çš„è‡ªé€‚åº”ã€ç‰©ç†å¯å‘çš„æ¨¡å‹è®¾è®¡ç­–ç•¥ã€‚è¯¥ç­–ç•¥ä¾èµ–äºä»å•æœ¯è¯­æ¨¡å‹è¿­ä»£é‡æ„å¤åˆæ¨¡å‹ï¼Œå¹¶è¾…ä»¥ç»Ÿä¸€çš„è®­ç»ƒç¨‹åºã€‚ä¸ºäº†æŒ‡å¯¼æ¨¡å‹é‡æ„å’Œè¶…å‚æ•°ä¼˜åŒ–ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºè´¹èˆå°”ä¿¡æ¯çŸ©é˜µï¼ˆFIMï¼‰å’Œå¤šå±æ€§è¯¯å·®åº¦é‡çš„æ¨¡å‹è¯„ä¼°æ–¹æ³•ã€‚é€šè¿‡ç»“åˆé‡æ„å’Œè¯„ä¼°å­ç¨‹åºï¼Œè¯¥æ¡†æ¶åœ¨çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚åœ¨ä¸€ä¸ªé’ˆå¯¹ç»“æ„å¤šæ ·çš„é“Œæ•°æ®é›†çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œè¯¥æ¡†æ¶ç”Ÿæˆçš„åŒ…å«75ä¸ªå‚æ•°çš„æœ€ä¼˜æ¨¡å‹é…ç½®å®ç°äº†0.172 eV/Ã…çš„åŠ›RMSEå’Œ0.013 eV/åŸå­çš„èƒ½é‡RMSEã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡ç³»ç»Ÿæ€§çš„ã€ä¿¡æ¯é©±åŠ¨çš„æ¡†æ¶æ¥è®¾è®¡å’Œä¼˜åŒ–ç”¨äºåŒ–å­¦å’Œææ–™ç§‘å­¦çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä¸å¼€å‘æ›´æ™ºèƒ½ã€æ›´å¯è§£é‡Šçš„â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„ç ”ç©¶æ–¹å‘é«˜åº¦ç›¸å…³ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

An adaptive physics-inspired model design strategy for machine-learning interatomic potentials (MLIPs) is proposed. This strategy relies on iterative reconfigurations of composite models from single-term models, followed by a unified training procedure. A model evaluation method based on the Fisher information matrix (FIM) and multiple-property error metrics is also proposed to guide the model reconfiguration and hyperparameter optimization. By combining the reconfiguration and the evaluation subroutines, we provide an adaptive MLIP design strategy that balances flexibility and extensibility. In a case study of designing models against a structurally diverse niobium dataset, we managed to obtain an optimal model configuration with 75 parameters generated by our framework that achieved a force RMSE of 0.172 eV/Ã… and an energy RMSE of 0.013 eV/atom.

</details>

---

### 51. [Understanding protein function with a multimodal retrieval-augmented foundation model](https://arxiv.org/abs/2508.04724)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2508.04724`](https://arxiv.org/abs/2508.04724)
- ğŸ‘¥ ä½œè€…: Timothy Fei Truong Jr, Tristan Bepler
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2508.04724.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªåä¸ºPoET-2çš„å¤šæ¨¡æ€ã€æ£€ç´¢å¢å¼ºçš„è›‹ç™½è´¨åŸºç¡€æ¨¡å‹ã€‚è›‹ç™½è´¨æ˜¯å¤æ‚çš„ç”Ÿç‰©å¤§åˆ†å­ï¼Œå…¶åºåˆ—-ç»“æ„-åŠŸèƒ½å…³ç³»çš„å»ºæ¨¡æ˜¯åŒ–å­¦ä¿¡æ¯å­¦å’Œè®¡ç®—ç”Ÿç‰©å­¦çš„å‰æ²¿ã€‚PoET-2ä½œä¸ºä¸€ä¸ªå…ˆè¿›çš„è›‹ç™½è´¨è¯­è¨€æ¨¡å‹ï¼Œç›´æ¥å±äºâ€œåŒ–å­¦å¤§æ¨¡å‹â€çš„ç ”ç©¶èŒƒç•´ï¼Œæ—¨åœ¨æå‡å¯¹è›‹ç™½è´¨åŠŸèƒ½çš„ç†è§£å’Œé¢„æµ‹èƒ½åŠ›ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†PoET-2ï¼Œä¸€ä¸ªå¤šæ¨¡æ€ã€æ£€ç´¢å¢å¼ºçš„è›‹ç™½è´¨åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆå®¶æ—ç‰¹å¼‚æ€§è¿›åŒ–çº¦æŸçš„ä¸Šä¸‹æ–‡å­¦ä¹ ä»¥åŠå¯é€‰çš„ç»“æ„æ¡ä»¶ï¼Œæ¥å­¦ä¹ è›‹ç™½è´¨åºåˆ—çš„ç”Ÿæˆåˆ†å¸ƒã€‚PoET-2é‡‡ç”¨åˆ†å±‚Transformerç¼–ç å™¨å’Œå…·æœ‰å› æœä¸æ©ç è¯­è¨€å»ºæ¨¡ç›®æ ‡çš„åŒè§£ç å™¨æ¶æ„ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å®Œå…¨ç”Ÿæˆå’ŒåŒå‘è¡¨ç¤ºå­¦ä¹ ä¸¤ç§æ¨¡å¼ä¸‹è¿è¡Œã€‚PoET-2åœ¨é›¶æ ·æœ¬å˜ä½“æ•ˆåº”é¢„æµ‹ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨è¯„åˆ†å¤šé‡çªå˜å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„æ’å…¥ç¼ºå¤±çªå˜æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚åœ¨ç›‘ç£è®¾ç½®ä¸‹ï¼ŒPoET-2çš„åµŒå…¥åœ¨å­¦ä¹ å’Œé¢„æµ‹è›‹ç™½è´¨åºåˆ—-åŠŸèƒ½å…³ç³»æ–¹é¢ä¼˜äºå…ˆå‰çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨å°æ•°æ®é›†ä¸Šã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†å°†æ£€ç´¢å¢å¼ºä¸å¤šæ¨¡æ€ã€ä»¥å®¶æ—ä¸ºä¸­å¿ƒçš„å»ºæ¨¡ç›¸ç»“åˆï¼Œå¯¹äºæ¨è¿›è›‹ç™½è´¨åŸºç¡€æ¨¡å‹çš„ç›Šå¤„ã€‚è›‹ç™½è´¨åºåˆ—å’ŒåŠŸèƒ½çš„å»ºæ¨¡æ˜¯åŒ–å­¦ä¿¡æ¯å­¦å’Œç”Ÿç‰©ä¿¡æ¯å­¦çš„æ ¸å¿ƒï¼Œå±äºå¹¿ä¹‰çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€èŒƒç•´ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Protein language models (PLMs) learn probability distributions over natural protein sequences. By learning from hundreds of millions of natural protein sequences, protein understanding and design capabilities emerge. Recent works have shown that scaling these models improves structure prediction, but does not seem to improve mutation understanding and representation quality for protein function prediction. We introduce PoET-2, a multimodal, retrieval-augmented protein foundation model that incorporates in-context learning of family-specific evolutionary constraints with optional structure conditioning to learn generative distributions over protein sequences. PoET-2 uses a hierarchical transformer encoder that is equivariant to sequence context ordering and a dual decoder architecture with both causal and masked language modeling objectives, allowing PoET-2 to operate in both fully generative and bidirectional representation learning modes. PoET-2 achieves state-of-the-art performance on zero-shot variant effect prediction, excelling at scoring variants with multiple mutations and challenging indel mutations. In supervised settings, PoET-2 embeddings outperform previous methods for learning sequence-function relationships, especially with small datasets. This work highlights the benefits of combining retrieval augmentation with multimodal, family-centric modeling for advancing protein foundation models.

</details>

---

### 52. [TokEye: Fast Signal Extraction for Fluctuating Time Series via Offline Self-Supervised Learning From Fusion Diagnostics to Bioacoustics](https://arxiv.org/abs/2602.20317)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.20317`](https://arxiv.org/abs/2602.20317)
- ğŸ‘¥ ä½œè€…: Nathaniel Chen, Kouroche Bouchiat, Peter Steiner ç­‰9äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.20317.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªä»é«˜å™ªå£°ã€å¤šé€šé“æ—¶åºä¿¡å·ä¸­è‡ªåŠ¨æå–ç›¸å¹²å’Œç¬æ€æ¨¡å¼çš„é€šç”¨æ¡†æ¶ã€‚å°½ç®¡åº”ç”¨åœºæ™¯æ˜¯èšå˜ç­‰ç¦»å­ä½“è¯Šæ–­ï¼Œä½†å…¶æ ¸å¿ƒæŠ€æœ¯â€”â€”é’ˆå¯¹æ³¢åŠ¨æµ‹é‡è¿›è¡Œä¿¡å·å¤„ç†ã€ç‰¹å¾æå–å’Œæ¨¡å¼è¯†åˆ«â€”â€”ä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­å¤„ç†å¤æ‚çš„è´¨è°±/è‰²è°±-è´¨è°±æ•°æ®ä»¥è¯†åˆ«åˆ†å­ç‰¹å¾å’Œç¢ç‰‡çš„æŒ‘æˆ˜åœ¨æœ¬è´¨ä¸Šæ˜¯ä¸€è‡´çš„ã€‚è®ºæ–‡æå‡ºçš„è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶å’Œå¿«é€Ÿç¥ç»ç½‘ç»œä»£ç†æ–¹æ³•ï¼Œä¸ºè§£å†³è´¨è°±æ•°æ®ä¸­ç±»ä¼¼çš„ä¿¡æ¯æå–å’Œæ¨ç†é—®é¢˜æä¾›äº†æ½œåœ¨çš„æŠ€æœ¯è·¯å¾„ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªâ€œä¿¡å·ä¼˜å…ˆâ€çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºä»å„ç§ä¼ æ„Ÿå™¨çš„é«˜å™ªå£°æ—¶é¢‘æ•°æ®ä¸­è‡ªåŠ¨æå–ç›¸å¹²å’Œç¬æ€æ¨¡å¼ã€‚ä½œè€…å¼€å‘äº†ä¸€ç§é€šç”¨æ–¹æ³•å’Œå·¥å…·ï¼Œé€šè¿‡åœ¨å¤šé€šé“ä¿¡å·å¤„ç†ä¸­åº”ç”¨éçº¿æ€§ä¼˜åŒ–æŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨å¿«é€Ÿç¥ç»ç½‘ç»œä»£ç†ï¼Œä»æ‰˜å¡é©¬å…‹è£…ç½®ï¼ˆå¦‚DIII-Dï¼‰çš„å¿«é€Ÿç£å­¦ã€ç”µå­å›æ—‹è¾å°„ã€CO2å¹²æ¶‰ä»ªå’ŒæŸå‘å°„å…‰è°±æµ‹é‡ä¸­æå–ç›¸å¹²ã€å‡†ç›¸å¹²å’Œç¬æ€æ¨¡å¼ã€‚è¯¥æ¡†æ¶åœ¨DIII-Dã€TJ-IIå’Œéèåˆè¯­è°±å›¾çš„æ•°æ®ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚æ¨ç†å»¶è¿Ÿä¸º0.5ç§’ï¼Œä½¿å¾—è¯¥æ¡†æ¶èƒ½å¤Ÿå®ç°å®æ—¶æ¨¡å¼è¯†åˆ«å’Œå¤§è§„æ¨¡è‡ªåŠ¨åŒ–æ•°æ®åº“ç”Ÿæˆï¼Œç”¨äºå…ˆè¿›çš„ç­‰ç¦»å­ä½“æ§åˆ¶ã€‚è¿™é¡¹å·¥ä½œè™½ç„¶ä¸»è¦åº”ç”¨äºèšå˜è¯Šæ–­ï¼Œä½†å…¶æ ¸å¿ƒæ˜¯å¼€å‘ä¸€ç§ä»å¤æ‚ã€é«˜å™ªå£°çš„æ—¶åºä¿¡å·ï¼ˆç±»ä¼¼äºè´¨è°±ä¸­çš„è‰²è°±-è´¨è°±è”ç”¨æ•°æ®ï¼‰ä¸­æå–ç‰¹å¾å’Œæ¨¡å¼çš„é€šç”¨æ–¹æ³•ã€‚è¿™ç§ä¿¡å·å¤„ç†å’Œæ¨¡å¼è¯†åˆ«æŠ€æœ¯ä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­ä»è´¨è°±æ•°æ®ä¸­æå–åˆ†å­ç‰¹å¾å’Œæ¨æ–­ç»“æ„æ‰€é¢ä¸´çš„æŒ‘æˆ˜åœ¨æ–¹æ³•è®ºä¸Šé«˜åº¦ç›¸ä¼¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Next-generation fusion facilities like ITER face a "data deluge," generating petabytes of multi-diagnostic signals daily that challenge manual analysis. We present a "signals-first" self-supervised framework for the automated extraction of coherent and transient modes from high-noise time-frequency data across a variety of sensors. We also develop a general-purpose method and tool for extracting coherent, quasi-coherent, and transient modes for fluctuation measurements in tokamaks by employing non-linear optimal techniques in multichannel signal processing with a fast neural network surrogate on fast magnetics, electron cyclotron emission, CO2 interferometers, and beam emission spectroscopy measurements from DIII-D. Results are tested on data from DIII-D, TJ-II, and non-fusion spectrograms. With an inference latency of 0.5 seconds, this framework enables real-time mode identification and large-scale automated database generation for advanced plasma control. Repository is in this https URL .

</details>

---

## ğŸ“Š æ•°æ®ç»Ÿè®¡
- ç´¯è®¡è¿è¡Œå¤©æ•°ï¼š2
- ç´¯è®¡è®ºæ–‡æ•°é‡ï¼š89

## ğŸ“ å†å²è®°å½•

> æš‚æ— å†å²æ•°æ®

