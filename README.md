# ğŸ“š ArXiv è®ºæ–‡æ—¥æŠ¥

> æ¯å¤©è‡ªåŠ¨æ›´æ–°ï¼Œå…³æ³¨ **åŒ–å­¦å¤§æ¨¡å‹, è´¨è°±ç»“æ„æ¨ç†** ç›¸å…³çš„æœ€æ–°è®ºæ–‡

## æ›´æ–°æ—¶é—´
â° 2026-02-28 18:16:08

## ğŸ“… 2026-02-28 (ä»Šæ—¥æœ€æ–°)

**ç›¸å…³è®ºæ–‡æ•°ï¼š37**

### 1. [Zatom-1: A Multimodal Flow Foundation Model for 3D Molecules and Materials](https://arxiv.org/abs/2602.22251)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22251`](https://arxiv.org/abs/2602.22251)
- ğŸ‘¥ ä½œè€…: Alex Morehead, Miruna Cretu, Antonia Panescu ç­‰17äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22251.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªç”¨äº3Dåˆ†å­å’Œææ–™çš„ç»Ÿä¸€ç”Ÿæˆä¸é¢„æµ‹åŸºç¡€æ¨¡å‹ï¼Œè¿™ç›´æ¥å±äºâ€˜åŒ–å­¦å¤§æ¨¡å‹â€™çš„ç ”ç©¶èŒƒç•´ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†Zatom-1ï¼Œè¿™æ˜¯é¦–ä¸ªç»Ÿä¸€3Dåˆ†å­å’Œææ–™ç”Ÿæˆä¸é¢„æµ‹å­¦ä¹ çš„åŸºç¡€æ¨¡å‹ã€‚å®ƒæ˜¯ä¸€ä¸ªåŸºäºTransformerçš„æ¨¡å‹ï¼Œé€šè¿‡å¤šæ¨¡æ€æµåŒ¹é…ç›®æ ‡è”åˆå»ºæ¨¡ç¦»æ•£åŸå­ç±»å‹å’Œè¿ç»­3Då‡ ä½•ç»“æ„ã€‚è¯¥æ¨¡å‹æ”¯æŒå¯æ‰©å±•çš„é¢„è®­ç»ƒï¼Œå¹¶èƒ½å¤Ÿè¿›è¡Œå¿«é€Ÿç¨³å®šçš„é‡‡æ ·ã€‚é€šè¿‡è”åˆç”Ÿæˆå¼é¢„è®­ç»ƒä½œä¸ºä¸‹æ¸¸å¤šä»»åŠ¡ï¼ˆå¦‚æ€§è´¨ã€èƒ½é‡å’ŒåŠ›é¢„æµ‹ï¼‰çš„é€šç”¨åˆå§‹åŒ–ï¼ŒZatom-1åœ¨ç”Ÿæˆå’Œé¢„æµ‹åŸºå‡†æµ‹è¯•ä¸­åŒ¹é…æˆ–è¶…è¶Šäº†ä¸“é—¨çš„åŸºçº¿æ¨¡å‹ï¼ŒåŒæ—¶å°†ç”Ÿæˆæ¨ç†æ—¶é—´å‡å°‘äº†ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚å®éªŒè¡¨æ˜ï¼Œè”åˆç”Ÿæˆå¼é¢„è®­ç»ƒåœ¨åŒ–å­¦é¢†åŸŸä¹‹é—´äº§ç”Ÿäº†æ­£å‘çš„é¢„æµ‹è¿ç§»ï¼šåœ¨é¢„è®­ç»ƒä¸­å»ºæ¨¡ææ–™å¯ä»¥æé«˜åˆ†å­æ€§è´¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

General-purpose 3D chemical modeling encompasses molecules and materials, requiring both generative and predictive capabilities. However, most existing AI approaches are optimized for a single domain (molecules or materials) and a single task (generation or prediction), which limits representation sharing and transfer. We introduce Zatom-1, the first foundation model that unifies generative and predictive learning of 3D molecules and materials. Zatom-1 is a Transformer trained with a multimodal flow matching objective that jointly models discrete atom types and continuous 3D geometries. This approach supports scalable pretraining with predictable gains as model capacity increases, while enabling fast and stable sampling. We use joint generative pretraining as a universal initialization for downstream multi-task prediction of properties, energies, and forces. Empirically, Zatom-1 matches or outperforms specialized baselines on both generative and predictive benchmarks, while reducing the generative inference time by more than an order of magnitude. Our experiments demonstrate positive predictive transfer between chemical domains from joint generative pretraining: modeling materials during pretraining improves molecular property prediction accuracy.

</details>

---

### 2. [Energy Efficient Federated Learning with Hyperdimensional Computing (HDC)](https://arxiv.org/abs/2602.22290)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22290`](https://arxiv.org/abs/2602.22290)
- ğŸ‘¥ ä½œè€…: Yahao Ding, Yinchao Yang, Jiaxiang Wang ç­‰7äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22290.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»“åˆè¶…ç»´è®¡ç®—ï¼ˆHDCï¼‰çš„è”é‚¦å­¦ä¹ æ¡†æ¶ï¼ŒHDCæ˜¯ä¸€ç§ç”¨äºé«˜æ•ˆå¤„ç†åŒ–å­¦ä¿¡æ¯ï¼ˆå¦‚åˆ†å­æŒ‡çº¹ï¼‰çš„æ½œåœ¨æ–¹æ³•ï¼Œå› æ­¤è¯¥æ¡†æ¶å¯è¢«è§†ä¸ºä¸€ç§å¯ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦é¢†åŸŸï¼ˆå¦‚åˆ†å­è¡¨ç¤ºå­¦ä¹ ï¼‰çš„å·¥å…·æˆ–æ–¹æ³•ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶äº†æ— çº¿è¾¹ç¼˜ç½‘ç»œä¸­å®‰å…¨è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰çš„æ€»èƒ½è€—æœ€å°åŒ–é—®é¢˜ã€‚ä¸ºäº†åº”å¯¹ä¼ ç»Ÿç¥ç»ç½‘ç»œå¤„ç†å¤§è§„æ¨¡åˆ†å¸ƒå¼æ•°æ®æ—¶çš„é«˜è®¡ç®—æˆæœ¬å’Œéšç§æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªç»“åˆè¶…ç»´è®¡ç®—ï¼ˆHDCï¼‰å’Œå·®åˆ†éšç§ï¼ˆDPï¼‰çš„è”é‚¦å­¦ä¹ æ¡†æ¶ï¼ˆFL-HDC-DPï¼‰ã€‚æ¯ä¸ªè¾¹ç¼˜è®¾å¤‡ä½¿ç”¨HDCè¿›è¡Œè½»é‡çº§æœ¬åœ°è®­ç»ƒï¼Œå¹¶åº”ç”¨DPå™ªå£°æ¥ä¿æŠ¤ä¼ è¾“çš„æ¨¡å‹æ›´æ–°ã€‚é€šè¿‡è”åˆä¼˜åŒ–HDCç»´åº¦ã€å‘å°„åŠŸç‡å’ŒCPUé¢‘ç‡æ¥æœ€å°åŒ–æ€»èƒ½è€—ã€‚ç ”ç©¶å¼€å‘äº†ä¸€ç§é«˜æ•ˆçš„æ··åˆç®—æ³•ï¼Œç»“åˆäº†ç”¨äºHDCç»´åº¦çš„å¤–éƒ¨æšä¸¾æœç´¢å’Œç”¨äºèµ„æºåˆ†é…çš„å†…éƒ¨ä¸€ç»´æœç´¢ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œä¸åŸºçº¿æ–¹æ¡ˆç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ¡†æ¶èƒ½è€—é™ä½äº†é«˜è¾¾83.3%ï¼ŒåŒæ—¶ä¿æŒäº†é«˜ç²¾åº¦å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

This paper investigates the problem of minimizing total energy consumption for secure federated learning (FL) in wireless edge networks, a key paradigm for decentralized big data analytics. To tackle the high computational cost and privacy challenges of processing large-scale distributed data with conventional neural networks, we propose an FL with hyperdimensional computing and differential privacy (FL-HDC-DP) framework. Each edge device employs hyperdimensional computing (HDC) for lightweight local training and applies differential privacy (DP) noise to protect transmitted model updates. The total energy consumption is minimized through a joint optimization of the HDC dimension, transmit power, and CPU frequency. An efficient hybrid algorithm is developed, combining an outer enumeration search for HDC dimensions with an inner one-dimensional search for resource allocation. Simulation results show that the proposed framework achieves up to 83.3% energy reduction compared with baseline schemes, while maintaining high accuracy and faster convergence.

</details>

---

### 3. [Learning Rewards, Not Labels: Adversarial Inverse Reinforcement Learning for Machinery Fault Detection](https://arxiv.org/abs/2602.22297)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22297`](https://arxiv.org/abs/2602.22297)
- ğŸ‘¥ ä½œè€…: Dhiraj Neupane, Richard Dazeley, Mohamed Reda Bouadjenek ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22297.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºçš„åŸºäºé€†å¼ºåŒ–å­¦ä¹ çš„å¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ä»æ­£å¸¸æ•°æ®åºåˆ—ä¸­å­¦ä¹ åŠ¨æ€æ¨¡å¼å¹¶æ£€æµ‹åå·®ã€‚è¿™ç§æ—¶åºæ¨¡å¼å­¦ä¹ å’Œå¼‚å¸¸æ£€æµ‹çš„æ–¹æ³•è®ºï¼Œå¯ä»¥è¿ç§»åº”ç”¨äºè´¨è°±åˆ†æé¢†åŸŸï¼Œä¾‹å¦‚ä»æ­£å¸¸çš„è´¨è°±æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œå¹¶ç”¨äºæ£€æµ‹å¼‚å¸¸æˆ–æ¨æ–­æœªçŸ¥åŒ–åˆç‰©çš„ç»“æ„ï¼Œå› æ­¤ä¸â€˜è´¨è°±ç»“æ„æ¨ç†â€™ä¸»é¢˜åœ¨æ–¹æ³•è®ºä¸Šç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºå°†æœºæ¢°æ•…éšœæ£€æµ‹ï¼ˆMFDï¼‰è¡¨è¿°ä¸ºä¸€ä¸ªç¦»çº¿é€†å¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œå…¶ä¸­æ™ºèƒ½ä½“ç›´æ¥ä»å¥åº·æ“ä½œåºåˆ—ä¸­å­¦ä¹ å¥–åŠ±åŠ¨æ€ï¼Œä»è€Œç»•è¿‡äº†æ‰‹åŠ¨å¥–åŠ±å·¥ç¨‹å’Œæ•…éšœæ ‡ç­¾çš„éœ€æ±‚ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¯¹æŠ—æ€§é€†å¼ºåŒ–å­¦ä¹ æ¥è®­ç»ƒä¸€ä¸ªåˆ¤åˆ«å™¨ï¼Œä»¥åŒºåˆ†æ­£å¸¸ï¼ˆä¸“å®¶ï¼‰å’Œç­–ç•¥ç”Ÿæˆçš„è½¬æ¢ã€‚åˆ¤åˆ«å™¨å­¦ä¹ åˆ°çš„å¥–åŠ±ä½œä¸ºå¼‚å¸¸åˆ†æ•°ï¼ŒæŒ‡ç¤ºä¸æ­£å¸¸æ“ä½œè¡Œä¸ºçš„åå·®ã€‚é€šè¿‡åœ¨ä¸‰ä¸ªè¿è¡Œè‡³æ•…éšœåŸºå‡†æ•°æ®é›†ï¼ˆHUMS2023ï¼Œ IMSï¼Œ å’Œ XJTU-SYï¼‰ä¸Šçš„è¯„ä¼°ï¼Œè¯¥æ¨¡å‹å§‹ç»ˆä¸ºæ­£å¸¸æ ·æœ¬åˆ†é…ä½å¼‚å¸¸åˆ†æ•°ï¼Œä¸ºæ•…éšœæ ·æœ¬åˆ†é…é«˜åˆ†æ•°ï¼Œä»è€Œå®ç°æ—©æœŸä¸”ç¨³å¥çš„æ•…éšœæ£€æµ‹ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Reinforcement learning (RL) offers significant promise for machinery fault detection (MFD). However, most existing RL-based MFD approaches do not fully exploit RL's sequential decision-making strengths, often treating MFD as a simple guessing game (Contextual Bandits). To bridge this gap, we formulate MFD as an offline inverse reinforcement learning problem, where the agent learns the reward dynamics directly from healthy operational sequences, thereby bypassing the need for manual reward engineering and fault labels. Our framework employs Adversarial Inverse Reinforcement Learning to train a discriminator that distinguishes between normal (expert) and policy-generated transitions. The discriminator's learned reward serves as an anomaly score, indicating deviations from normal operating behaviour. When evaluated on three run-to-failure benchmark datasets (HUMS2023, IMS, and XJTU-SY), the model consistently assigns low anomaly scores to normal samples and high scores to faulty ones, enabling early and robust fault detection. By aligning RL's sequential reasoning with MFD's temporal structure, this work opens a path toward RL-based diagnostics in data-driven industrial settings.

</details>

---

### 4. [Disentangling Shared and Target-Enriched Topics via Background-Contrastive Non-negative Matrix Factorization](https://arxiv.org/abs/2602.22387)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22387`](https://arxiv.org/abs/2602.22387)
- ğŸ‘¥ ä½œè€…: Yixuan Li, Archer Y. Yang, Yue Li
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22387.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºçš„èƒŒæ™¯å¯¹æ¯”éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆBC-NMFï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„é™ç»´å’Œç‰¹å¾æå–æ–¹æ³•ï¼Œä¸“é—¨è®¾è®¡ç”¨äºä»é«˜ç»´æ•°æ®ï¼ˆå¦‚ç»„å­¦æ•°æ®ï¼‰ä¸­åˆ†ç¦»ç›®æ ‡ç‰¹å¼‚æ€§ä¿¡å·ã€‚è¿™ç§æ•°æ®åˆ†æå’Œæ¨¡å¼è¯†åˆ«æ–¹æ³•å¯ä»¥ç›´æ¥åº”ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦å’Œè´¨è°±åˆ†æé¢†åŸŸï¼Œç”¨äºä»å¤æ‚çš„è´¨è°±æˆ–å…‰è°±æ•°æ®ä¸­æå–ä¸ç‰¹å®šåŒ–åˆç‰©æˆ–ç»“æ„ç›¸å…³çš„ç‰¹å¾ï¼Œå› æ­¤æä¾›äº†å¯ç”¨äºè¿™äº›ä¸»é¢˜çš„æ•°æ®åˆ†æå·¥å…·ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†èƒŒæ™¯å¯¹æ¯”éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆBC-NMFï¼‰ï¼Œè¯¥æ–¹æ³•é€šè¿‡è”åˆåˆ†è§£ç›®æ ‡æ•°æ®é›†å’ŒåŒ¹é…çš„èƒŒæ™¯æ•°æ®é›†ï¼Œä½¿ç”¨å…±äº«çš„éè´ŸåŸºï¼Œåœ¨å¯¹æ¯”æ€§ç›®æ ‡ä¸‹æŠ‘åˆ¶èƒŒæ™¯è¡¨è¾¾çš„ç»“æ„ï¼Œä»è€Œæå–ç›®æ ‡å¯Œé›†çš„æ½œåœ¨ä¸»é¢˜ã€‚è¿™ç§æ–¹æ³•äº§ç”Ÿå¯ç›´æ¥åœ¨ç‰¹å¾å±‚é¢è§£é‡Šçš„éè´Ÿæˆåˆ†ï¼Œå¹¶æ˜ç¡®éš”ç¦»ç›®æ ‡ç‰¹å¼‚æ€§å˜å¼‚ã€‚BC-NMFé€šè¿‡é«˜æ•ˆçš„ä¹˜æ³•æ›´æ–°ç®—æ³•å­¦ä¹ ï¼Œè¯¥ç®—æ³•é€šè¿‡çŸ©é˜µä¹˜æ³•å®ç°ï¼Œä½¿å…¶åœ¨GPUç¡¬ä»¶ä¸Šé«˜åº¦é«˜æ•ˆï¼Œå¹¶ä¸”é€šè¿‡ç±»ä¼¼äºæ·±åº¦å­¦ä¹ çš„å°æ‰¹é‡è®­ç»ƒå¯æ‰©å±•åˆ°å¤§æ•°æ®ã€‚åœ¨æ¨¡æ‹Ÿå’Œå¤šæ ·åŒ–çš„ç”Ÿç‰©æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBC-NMFæ­ç¤ºäº†ä¼ ç»Ÿæ–¹æ³•æ‰€æ©ç›–çš„ä¿¡å·ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Biological signals of interest in high-dimensional data are often masked by dominant variation shared across conditions. This variation, arising from baseline biological structure or technical effects, can prevent standard dimensionality reduction methods from resolving condition-specific structure. The challenge is that these confounding topics are often unknown and mixed with biological signals. Existing background correction methods are either unscalable to high dimensions or not interpretable. We introduce background contrastive Non-negative Matrix Factorization (\model), which extracts target-enriched latent topics by jointly factorizing a target dataset and a matched background using shared non-negative bases under a contrastive objective that suppresses background-expressed structure. This approach yields non-negative components that are directly interpretable at the feature level, and explicitly isolates target-specific variation. \model is learned by an efficient multiplicative update algorithm via matrix multiplication such that it is highly efficient on GPU hardware and scalable to big data via minibatch training akin to deep learning approach. Across simulations and diverse biological datasets, \model reveals signals obscured by conventional methods, including disease-associated programs in postmortem depressive brain single-cell RNA-seq, genotype-linked protein expression patterns in mice, treatment-specific transcriptional changes in leukemia, and TP53-dependent drug responses in cancer cell lines.

</details>

---

### 5. [MolFM-Lite: Multi-Modal Molecular Property Prediction with Conformer Ensemble Attention and Cross-Modal Fusion](https://arxiv.org/abs/2602.22405)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22405`](https://arxiv.org/abs/2602.22405)
- ğŸ‘¥ ä½œè€…: Syed Omer Shah, Mohammed Maqsood Ahmed, Danish Mohiuddin Mohammed ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22405.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹å›´ç»•å¤šæ¨¡æ€åˆ†å­è¡¨ç¤ºå­¦ä¹ ï¼Œè¿™æ˜¯æ„å»ºåŒ–å­¦å¤§æ¨¡å‹ï¼ˆç”¨äºæ€§è´¨é¢„æµ‹ã€ç»“æ„æ¨ç†ç­‰ï¼‰çš„å…³é”®åŸºç¡€æŠ€æœ¯ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†MolFM-Liteï¼Œä¸€ä¸ªç”¨äºåˆ†å­æ€§è´¨é¢„æµ‹çš„å¤šæ¨¡æ€æ¨¡å‹ã€‚å®ƒè”åˆç¼–ç SELFIESåºåˆ—ï¼ˆ1Dï¼‰ã€åˆ†å­å›¾ï¼ˆ2Dï¼‰å’Œæ„è±¡ä½“é›†åˆï¼ˆ3Dï¼‰ï¼Œå¹¶é€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›èåˆè¿›è¡Œä¿¡æ¯å…±äº«ã€‚æ¨¡å‹çš„æ ¸å¿ƒè´¡çŒ®åŒ…æ‹¬æ„è±¡ä½“é›†åˆæ³¨æ„åŠ›æœºåˆ¶å’Œè·¨æ¨¡æ€èåˆå±‚ã€‚è¯¥ç ”ç©¶åœ¨åŒ–å­¦ä¿¡æ¯å­¦é¢†åŸŸç›´æ¥æ¶‰åŠåˆ†å­è¡¨ç¤ºå­¦ä¹ ï¼Œè¿™æ˜¯æ„å»ºåŒ–å­¦å¤§æ¨¡å‹ï¼ˆå¦‚ç”¨äºæ€§è´¨é¢„æµ‹æˆ–ç»“æ„æ¨ç†çš„æ¨¡å‹ï¼‰çš„åŸºç¡€ã€‚è®ºæ–‡è¿˜æåˆ°åœ¨ZINC250Kæ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶å‘å¸ƒäº†æ‰€æœ‰ä»£ç ã€è®­ç»ƒæ¨¡å‹å’Œæ•°æ®åˆ†å‰²ä»¥æ”¯æŒå¯é‡å¤æ€§ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Most machine learning models for molecular property prediction rely on a single molecular representation (either a sequence, a graph, or a 3D structure) and treat molecular geometry as static. We present MolFM-Lite, a multi-modal model that jointly encodes SELFIES sequences (1D), molecular graphs (2D), and conformer ensembles (3D) through cross-attention fusion, while conditioning predictions on experimental context via Feature-wise Linear Modulation (FiLM). Our main methodological contributions are: (1) a conformer ensemble attention mechanism that combines learnable attention with Boltzmann-weighted priors over multiple RDKit-generated conformers, capturing the thermodynamic distribution of molecular shapes; and (2) a cross-modal fusion layer where each modality can attend to others, enabling complementary information sharing. We evaluate on four MoleculeNet scaffold-split benchmarks using our model's own splits, and report all baselines re-evaluated under the same protocol. Comprehensive ablation studies across all four datasets confirm that each architectural component contributes independently, with tri-modal fusion providing 7-11% AUC improvement over single-modality baselines and conformer ensembles adding approximately 2% over single-conformer variants. Pre-training on ZINC250K (~250K molecules) using cross-modal contrastive and masked-atom objectives enables effective weight initialization at modest compute cost. We release all code, trained models, and data splits to support reproducibility.

</details>

---

### 6. [Mapping the Landscape of Artificial Intelligence in Life Cycle Assessment Using Large Language Models](https://arxiv.org/abs/2602.22500)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22500`](https://arxiv.org/abs/2602.22500)
- ğŸ‘¥ ä½œè€…: Anastasija Mensikova, Donna M. Rizzo, Kathryn Hinkelman
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22500.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†3ï¼šè®ºæ–‡æ˜¯å…³äºAIï¼ˆç‰¹åˆ«æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼‰åœ¨ç§‘å­¦é¢†åŸŸï¼ˆç”Ÿå‘½å‘¨æœŸè¯„ä¼°ï¼‰åº”ç”¨çš„ç»¼è¿°ï¼Œå¹¶åŒ…å«å¯¹ç›¸å…³æŠ€æœ¯è¶‹åŠ¿çš„é‡è¦è®¨è®ºã€‚è™½ç„¶ä¸ç›´æ¥é’ˆå¯¹åŒ–å­¦å¤§æ¨¡å‹æˆ–è´¨è°±ï¼Œä½†å…¶å¯¹AIåœ¨ç§‘å­¦è®¡ç®—ä¸­åº”ç”¨çš„å®è§‚ç»¼è¿°ä¸æ„å»ºç§‘å­¦é¢†åŸŸå¤§æ¨¡å‹ï¼ˆåŒ…æ‹¬åŒ–å­¦ä¿¡æ¯å­¦ï¼‰çš„èƒŒæ™¯é«˜åº¦ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç»¼è¿°äº†äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åœ¨ç”Ÿå‘½å‘¨æœŸè¯„ä¼°ï¼ˆLCAï¼‰ä¸­çš„æ•´åˆåº”ç”¨ã€‚ç ”ç©¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹AI-LCAäº¤å‰é¢†åŸŸçš„å·²å‘è¡¨å·¥ä½œè¿›è¡Œè¯¦ç»†å›é¡¾ï¼Œä»¥è¯†åˆ«å½“å‰è¶‹åŠ¿ã€æ–°å…´ä¸»é¢˜å’Œæœªæ¥æ–¹å‘ã€‚åˆ†æè¡¨æ˜ï¼Œéšç€LCAç ”ç©¶çš„æ‰©å±•ï¼ŒAIæŠ€æœ¯çš„é‡‡ç”¨æ€¥å‰§å¢é•¿ï¼Œå¹¶æ˜æ˜¾è½¬å‘LLMé©±åŠ¨çš„æ–¹æ³•ã€‚è¯¥ç ”ç©¶é€šè¿‡å°†åŸºäºLLMçš„æ–‡æœ¬æŒ–æ˜æ–¹æ³•ä¸ä¼ ç»Ÿçš„æ–‡çŒ®ç»¼è¿°æŠ€æœ¯ç›¸ç»“åˆï¼Œå¼•å…¥äº†ä¸€ä¸ªåŠ¨æ€æœ‰æ•ˆçš„æ¡†æ¶ï¼Œèƒ½å¤Ÿæ•æ‰è¯¥é¢†åŸŸçš„é«˜å±‚ç ”ç©¶è¶‹åŠ¿å’Œç»†ç²’åº¦çš„æ¦‚å¿µæ¨¡å¼ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†LLMè¾…åŠ©æ–¹æ³•åœ¨æ”¯æŒå¤§è§„æ¨¡ã€å¯é‡å¤çš„è·¨é¢†åŸŸæ–‡çŒ®ç»¼è¿°æ–¹é¢çš„æ½œåŠ›ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Integration of artificial intelligence (AI) into life cycle assessment (LCA) has accelerated in recent years, with numerous studies successfully adapting machine learning algorithms to support various stages of LCA. Despite this rapid development, comprehensive and broad synthesis of AI-LCA research remains limited. To address this gap, this study presents a detailed review of published work at the intersection of AI and LCA, leveraging large language models (LLMs) to identify current trends, emerging themes, and future directions. Our analyses reveal that as LCA research continues to expand, the adoption of AI technologies has grown dramatically, with a noticeable shift toward LLM-driven approaches, continued increases in ML applications, and statistically significant correlations between AI approaches and corresponding LCA stages. By integrating LLM-based text-mining methods with traditional literature review techniques, this study introduces a dynamic and effective framework capable of capturing both high-level research trends and nuanced conceptual patterns (themes) across the field. Collectively, these findings demonstrate the potential of LLM-assisted methodologies to support large-scale, reproducible reviews across broad research domains, while also evaluating pathways for computationally-efficient LCA in the context of rapidly developing AI technologies. In doing so, this work helps LCA practitioners incorporate state-of-the-art tools and timely insights into environmental assessments that can enhance the rigor and quality of sustainability-driven decisions and decision-making processes.

</details>

---

### 7. [LUMOS: Democratizing SciML Workflows with L0-Regularized Learning for Unified Feature and Parameter Adaptation](https://arxiv.org/abs/2602.22537)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22537`](https://arxiv.org/abs/2602.22537)
- ğŸ‘¥ ä½œè€…: Shouwei Gao, Xu Zheng, Dongsheng Luo ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22537.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯ç§‘å­¦æœºå™¨å­¦ä¹ ï¼ˆSciMLï¼‰æ¨¡å‹çš„è‡ªåŠ¨åŒ–è®¾è®¡æ¡†æ¶ï¼Œå¹¶æ˜ç¡®åœ¨åˆ†å­ç§‘å­¦ç­‰é¢†åŸŸè¿›è¡Œè¯„ä¼°ã€‚è¿™ç›´æ¥å…³ç³»åˆ°å¦‚ä½•é«˜æ•ˆæ„å»ºå’Œä¼˜åŒ–ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦ä»»åŠ¡çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¯è§†ä¸ºåŒ–å­¦å¤§æ¨¡å‹çš„åŸºç¡€è®¾æ–½æˆ–æ–¹æ³•è®ºï¼‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†LUMOSï¼Œä¸€ä¸ªåŸºäºL0æ­£åˆ™åŒ–å­¦ä¹ çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œæ—¨åœ¨æ°‘ä¸»åŒ–ç§‘å­¦æœºå™¨å­¦ä¹ ï¼ˆSciMLï¼‰æ¨¡å‹çš„è®¾è®¡ã€‚å®ƒé€šè¿‡åŠéšæœºé—¨æ§å’Œé‡å‚æ•°åŒ–æŠ€æœ¯ï¼Œç»Ÿä¸€äº†ç‰¹å¾é€‰æ‹©å’Œæ¨¡å‹å‰ªæï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€é€‰æ‹©ä¿¡æ¯ç‰¹å¾å¹¶å‰ªæå†—ä½™å‚æ•°ï¼Œå‡å°‘äº†å¯¹äººå·¥è°ƒä¼˜çš„ä¾èµ–ã€‚ç ”ç©¶åœ¨åŒ…æ‹¬åˆ†å­ç§‘å­¦åœ¨å†…çš„13ä¸ªä¸åŒçš„SciMLå·¥ä½œè´Ÿè½½ä¸Šè¯„ä¼°äº†LUMOSï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚è¯¥æ¡†æ¶ç›´æ¥åº”ç”¨äºåˆ†å­ç§‘å­¦ç­‰é¢†åŸŸçš„SciMLæ¨¡å‹æ„å»ºï¼Œä¸å¼€å‘ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦ä»»åŠ¡çš„ä¸“ç”¨ã€é«˜æ•ˆæ¨¡å‹ï¼ˆå¯è§†ä¸ºåŒ–å­¦å¤§æ¨¡å‹çš„ä¸€ç§å½¢å¼ï¼‰é«˜åº¦ç›¸å…³ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

The rapid growth of scientific machine learning (SciML) has accelerated discovery across diverse domains, yet designing effective SciML models remains a challenging task. In practice, building such models often requires substantial prior knowledge and manual expertise, particularly in determining which input features to use and how large the model should be. We introduce LUMOS, an end-to-end framework based on L0-regularized learning that unifies feature selection and model pruning to democratize SciML model design. By employing semi-stochastic gating and reparameterization techniques, LUMOS dynamically selects informative features and prunes redundant parameters during training, reducing the reliance on manual tuning while maintaining predictive accuracy. We evaluate LUMOS across 13 diverse SciML workloads, including cosmology and molecular sciences, and demonstrate its effectiveness and generalizability. Experiments on 13 SciML models show that LUMOS achieves 71.45% parameter reduction and a 6.4x inference speedup on average. Furthermore, Distributed Data Parallel (DDP) training on up to eight GPUs confirms the scalability of

</details>

---

### 8. [DisQ-HNet: A Disentangled Quantized Half-UNet for Interpretable Multimodal Image Synthesis Applications to Tau-PET Synthesis from T1 and FLAIR MRI](https://arxiv.org/abs/2602.22545)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22545`](https://arxiv.org/abs/2602.22545)
- ğŸ‘¥ ä½œè€…: Agamdeep S. Chopra, Caitlin Neher, Tianyi Ren ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22545.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¤šæ¨¡æ€æ•°æ®èåˆä¸å¯è§£é‡Šçš„ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºä»ä¸€ç§æ•°æ®æ¨¡æ€ï¼ˆMRIï¼‰æ¨ç†/åˆæˆå¦ä¸€ç§å¤æ‚æ•°æ®æ¨¡æ€ï¼ˆPETå›¾åƒï¼‰ã€‚è¿™ç§â€œä»æ•°æ®Aæ¨ç†ç»“æ„/å±æ€§Bâ€çš„èŒƒå¼ä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ï¼ˆä»è´¨è°±æ•°æ®æ¨ç†åˆ†å­ç»“æ„ï¼‰åœ¨æ–¹æ³•è®ºä¸Šé«˜åº¦ç›¸å…³ï¼Œéƒ½å±äºç§‘å­¦å‘ç°ä¸­çš„é€†å‘æ¨ç†é—®é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†DisQ-HNetï¼ˆDQHï¼‰ï¼Œä¸€ä¸ªç”¨äºä»é…å¯¹T1åŠ æƒå’ŒFLAIR MRIåˆæˆtau-PETå›¾åƒçš„æ¡†æ¶ï¼Œå¹¶æ­ç¤ºäº†æ¯ç§æ¨¡æ€å¯¹é¢„æµ‹çš„è´¡çŒ®ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ï¼ˆiï¼‰åŸºäºéƒ¨åˆ†ä¿¡æ¯åˆ†è§£ï¼ˆPIDï¼‰å¼•å¯¼çš„ã€çŸ¢é‡é‡åŒ–çš„ç¼–ç å™¨ï¼Œå°†æ½œåœ¨ä¿¡æ¯åˆ’åˆ†ä¸ºå†—ä½™ã€ç‹¬ç‰¹å’Œäº’è¡¥éƒ¨åˆ†ï¼›ï¼ˆiiï¼‰Half-UNetè§£ç å™¨ã€‚è¯¥ç ”ç©¶åœ¨åŒ…æ‹¬é˜¿å°”èŒ¨æµ·é»˜ç—…åˆ†ç±»åœ¨å†…çš„ä¸‹æ¸¸ä»»åŠ¡ä¸­è¯„ä¼°äº†æ¨¡å‹ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯åŒ»å­¦å½±åƒï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•è®ºâ€”â€”ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®å’Œå¯è§£é‡Šçš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œå¤æ‚ä¿¡å·ï¼ˆæ­¤å¤„ä¸ºç”Ÿç‰©æ ‡è®°ç‰©ï¼‰çš„é¢„æµ‹ä¸åˆæˆâ€”â€”åœ¨æ–¹æ³•è®ºä¸Šä¸â€œè´¨è°±ç»“æ„æ¨ç†â€æœ‰ç›¸ä¼¼ä¹‹å¤„ï¼Œåè€…ä¹Ÿæ¶‰åŠä»å¤æ‚ã€å¤šæºæ•°æ®ï¼ˆè´¨è°±å³°ï¼‰æ¨ç†å‡ºç»“æ„ä¿¡æ¯ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Tau positron emission tomography (tau-PET) provides an in vivo marker of Alzheimer's disease pathology, but cost and limited availability motivate MRI-based alternatives. We introduce DisQ-HNet (DQH), a framework that synthesizes tau-PET from paired T1-weighted and FLAIR MRI while exposing how each modality contributes to the prediction. The method combines (i) a Partial Information Decomposition (PID)-guided, vector-quantized encoder that partitions latent information into redundant, unique, and complementary components, and (ii) a Half-UNet decoder that preserves anatomical detail using pseudo-skip connections conditioned on structural edge cues rather than direct encoder feature reuse. Across multiple baselines (VAE, VQ-VAE, and UNet), DisQ-HNet maintains reconstruction fidelity and better preserves disease-relevant signal for downstream AD tasks, including Braak staging, tau localization, and classification. PID-based Shapley analysis provides modality-specific attribution of synthesized uptake patterns.

</details>

---

### 9. [Autoregressive Visual Decoding from EEG Signals](https://arxiv.org/abs/2602.22555)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22555`](https://arxiv.org/abs/2602.22555)
- ğŸ‘¥ ä½œè€…: Sicheng Dai, Hongwang Xiao, Shan Yu ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22555.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯ä»å¤æ‚çš„ã€é«˜ç»´çš„æ—¶åºä¿¡å·ï¼ˆEEGï¼‰ä¸­è§£ç /é‡å»ºè§†è§‰ä¿¡æ¯ã€‚è¿™ç§â€œä»å¤æ‚æµ‹é‡æ•°æ®é€†å‘æ¨ç†å‡ºåŸå§‹ç»“æ„æˆ–å†…å®¹â€çš„ç ”ç©¶èŒƒå¼ï¼Œä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ï¼ˆä»è´¨è°±å³°é€†å‘æ¨ç†åˆ†å­ç»“æ„ï¼‰åœ¨é—®é¢˜å®šä¹‰å’ŒæŠ€æœ¯æŒ‘æˆ˜ä¸Šé«˜åº¦ç›¸ä¼¼ï¼Œéƒ½å±äºä¿¡å·è§£è¯‘å’Œé€†å‘æ¨ç†é—®é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†AVDEï¼Œä¸€ä¸ªä»è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·è¿›è¡Œè§†è§‰è§£ç çš„è½»é‡é«˜æ•ˆæ¡†æ¶ã€‚é¦–å…ˆï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„EEGæ¨¡å‹LaBraMï¼Œå¹¶é€šè¿‡å¯¹æ¯”å­¦ä¹ è¿›è¡Œå¾®è°ƒï¼Œä»¥å¯¹é½EEGå’Œå›¾åƒè¡¨ç¤ºã€‚å…¶æ¬¡ï¼Œé‡‡ç”¨åŸºäºâ€œä¸‹ä¸€å°ºåº¦é¢„æµ‹â€ç­–ç•¥çš„è‡ªå›å½’ç”Ÿæˆæ¡†æ¶ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„VQ-VAEå°†å›¾åƒç¼–ç ä¸ºå¤šå°ºåº¦ä»¤ç‰Œæ˜ å°„ï¼Œå¹¶è®­ç»ƒä¸€ä¸ªTransformerä»¥EEGåµŒå…¥ä½œä¸ºæœ€ç²—ç³™è¡¨ç¤ºï¼Œè‡ªå›å½’åœ°é¢„æµ‹æ›´ç»†å°ºåº¦çš„ä»¤ç‰Œã€‚å®éªŒè¡¨æ˜ï¼ŒAVDEåœ¨å›¾åƒæ£€ç´¢å’Œé‡å»ºä»»åŠ¡ä¸Šä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†å¦‚ä½•ä»å¤æ‚çš„ã€éç»“æ„åŒ–çš„ç”Ÿç‰©ä¿¡å·ï¼ˆEEGï¼‰ä¸­è§£ç å‡ºè§†è§‰ä¿¡æ¯ï¼Œè¿™ç§â€œä»å¤æ‚ä¿¡å·æ¨ç†ç»“æ„/å†…å®¹â€çš„èŒƒå¼ä¸â€œè´¨è°±ç»“æ„æ¨ç†â€å…·æœ‰æ¦‚å¿µä¸Šçš„ç›¸ä¼¼æ€§ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Electroencephalogram (EEG) signals have become a popular medium for decoding visual information due to their cost-effectiveness and high temporal resolution. However, current approaches face significant challenges in bridging the modality gap between EEG and image data. These methods typically rely on complex adaptation processes involving multiple stages, making it hard to maintain consistency and manage compounding errors. Furthermore, the computational overhead imposed by large-scale diffusion models limit their practicality in real-world brain-computer interface (BCI) applications. In this work, we present AVDE, a lightweight and efficient framework for visual decoding from EEG signals. First, we leverage LaBraM, a pre-trained EEG model, and fine-tune it via contrastive learning to align EEG and image representations. Second, we adopt an autoregressive generative framework based on a "next-scale prediction" strategy: images are encoded into multi-scale token maps using a pre-trained VQ-VAE, and a transformer is trained to autoregressively predict finer-scale tokens starting from EEG embeddings as the coarsest representation. This design enables coherent generation while preserving a direct connection between the input EEG signals and the reconstructed images. Experiments on two datasets show that AVDE outperforms previous state-of-the-art methods in both image retrieval and reconstruction tasks, while using only 10% of the parameters. In addition, visualization of intermediate outputs shows that the generative process of AVDE reflects the hierarchical nature of human visual perception. These results highlight the potential of autoregressive models as efficient and interpretable tools for practical BCI applications.

</details>

---

### 10. [Molecule Mixture Detection and Design for MC Systems with Non-linear, Cross-reactive Receiver Arrays](https://arxiv.org/abs/2602.22799)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22799`](https://arxiv.org/abs/2602.22799)
- ğŸ‘¥ ä½œè€…: Bastian Heinlein, Kaikai Zhu, SÃ¼meyye Carkit-Yilmaz ç­‰9äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22799.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯åˆ†å­é€šä¿¡ç³»ç»Ÿä¸­çš„åˆ†å­æ··åˆç‰©æ£€æµ‹å’Œè®¾è®¡ï¼Œè¿™ä¸ã€åŒ–å­¦ä¿¡æ¯å­¦ã€‘é¢†åŸŸç›´æ¥ç›¸å…³ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠåŒ–å­¦ä¼ æ„Ÿå™¨ï¼ˆè´¨è°±åˆ†æä¸­å¸¸ç”¨ä¼ æ„Ÿå™¨ç±»å‹ï¼‰çš„ä¿¡å·å¤„ç†å’Œåˆ†æã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶äº†ç©ºæ°”åˆ†å­é€šä¿¡ï¼ˆMCï¼‰ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿä½¿ç”¨å•†ä¸šä¼ æ„Ÿå™¨è¿›è¡Œåˆ†å­æ··åˆç‰©æ£€æµ‹å’Œè®¾è®¡ã€‚è¿™äº›ä¼ æ„Ÿå™¨é€šå¸¸è¡¨ç°å‡ºéçº¿æ€§å’Œäº¤å‰ååº”è¡Œä¸ºã€‚è®ºæ–‡æå‡ºäº†å‡ ç§æ£€æµ‹å™¨å’Œä¼ è¾“æ–¹æ¡ˆï¼Œç”¨äºå¤„ç†æ¥æ”¶å™¨ï¼ˆRXï¼‰ä½¿ç”¨éçº¿æ€§ã€äº¤å‰ååº”ä¼ æ„Ÿå™¨çš„æƒ…å†µã€‚æ‰€æœ‰æ–¹æ¡ˆéƒ½åŸºäºé€šè¿‡æ— è¿¹å˜æ¢ï¼ˆUnscented Transformï¼‰é¦ˆå…¥éçº¿æ€§RXçš„ç¬¦å·ä¼¼ç„¶çš„ä¸€é˜¶å’ŒäºŒé˜¶çŸ©ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡ä¸ºæ— ç¬¦å·é—´å¹²æ‰°ï¼ˆISIï¼‰çš„ä¼ è¾“åœºæ™¯æå‡ºäº†ä¸€ä¸ªè¿‘ä¼¼æœ€å¤§ä¼¼ç„¶ï¼ˆAMLï¼‰ç¬¦å·æ£€æµ‹å™¨ï¼Œä»¥åŠä¸€ä¸ªè€ƒè™‘æ¥æ”¶å™¨ç‰¹æ€§çš„äº’è¡¥æ··åˆç‰©å­—æ¯è¡¨è®¾è®¡ç®—æ³•ã€‚å½“åœ¨é«˜æ•°æ®é€Ÿç‡ä¸‹å­˜åœ¨æ˜¾è‘—ISIæ—¶ï¼ŒAMLæ£€æµ‹å™¨å¯ä»¥è¿›è¡Œè°ƒæ•´ä»¥åˆ©ç”¨ç»Ÿè®¡ISIçŸ¥è¯†ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ä¸ªç»“åˆå¤šä¸ªç¬¦å·é—´éš”ä¿¡æ¯çš„åºåˆ—æ£€æµ‹å™¨ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡è€ƒè™‘å‘å°„æœºå™ªå£°ã€ISIå’Œä¸€èˆ¬çš„éçº¿æ€§ã€äº¤å‰ååº”RXé˜µåˆ—ï¼Œä¸ºä¸€å¤§ç±»MCç³»ç»Ÿå®ç°äº†å¯é é€šä¿¡ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Air-based molecular communication (MC) has the potential to be one of the first MC systems to be deployed in real-world applications, enabled by commercially available sensors. However, these sensors usually exhibit non-linear and cross-reactive behavior, contrary to the idealizing assumption of linear and perfectly molecule type-specific sensing often made in the MC literature. To address this mismatch, we propose several detectors and transmission schemes for a molecule mixture communication system where the receiver (RX) employs non-linear, cross-reactive sensors. All proposed schemes are based on the first- and second-order moments of the symbol likelihoods that are fed through the non-linear RX using the Unscented Transform. In particular, we propose an approximate maximum likelihood (AML) symbol-by-symbol detector for inter-symbol-interference (ISI)-free transmission scenarios and a complementary mixture alphabet design algorithm which accounts for the RX characteristics. When significant ISI is present at high data rates, the AML detector can be adapted to exploit statistical ISI knowledge. Additionally, we propose a sequence detector which combines information from multiple symbol intervals. For settings where sequence detection is not possible due to extremely limited computational power at the RX, we propose an adaptive transmission scheme which can be combined with symbol-by-symbol detection. Using computer simulations, we validate all proposed detectors and algorithms based on the responses of commercially available sensors as well as artificially generated sensor data incorporating the characteristics of metal-oxide semiconductor sensors. By employing a general system model that accounts for transmitter noise, ISI, and general non-linear, cross-reactive RX arrays, this work enables reliable communication for a large class of MC systems.

</details>

---

### 11. [FlexMS is a flexible framework for benchmarking deep learning-based mass spectrum prediction tools in metabolomics](https://arxiv.org/abs/2602.22822)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22822`](https://arxiv.org/abs/2602.22822)
- ğŸ‘¥ ä½œè€…: Yunhua Zhong, Yixuan Tang, Yifan Li ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22822.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1å’Œæ ‡å‡†2ï¼šè®ºæ–‡çš„æ ¸å¿ƒä¸»é¢˜æ˜¯å¼€å‘ä¸€ä¸ªç”¨äºè¯„ä¼°æ·±åº¦å­¦ä¹ è´¨è°±é¢„æµ‹æ¨¡å‹çš„åŸºå‡†æ¡†æ¶ï¼ˆFlexMSï¼‰ï¼Œè¿™ç›´æ¥å›´ç»•ã€è´¨è°±åˆ†æã€‘å’Œã€åŒ–å­¦ä¿¡æ¯å­¦ã€‘ä¸­çš„ã€è´¨è°±ç»“æ„æ¨ç†ã€‘ä¸»é¢˜ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶æœ¬èº«æ˜¯ä¸€ä¸ªç”¨äºæ¨¡å‹è¯„ä¼°å’Œæ¯”è¾ƒçš„å·¥å…·/èµ„æºï¼Œç¬¦åˆæ ‡å‡†2ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†FlexMSï¼Œä¸€ä¸ªç”¨äºåœ¨ä»£è°¢ç»„å­¦ä¸­åŸºå‡†æµ‹è¯•åŸºäºæ·±åº¦å­¦ä¹ çš„è´¨è°±é¢„æµ‹å·¥å…·çš„çµæ´»æ¡†æ¶ã€‚è´¨è°±æŠ€æœ¯ä»¥è´¨è·æ¯”å³°çš„å½¢å¼æä¾›æœ‰ä»·å€¼çš„ç¢ç‰‡åŒ–çº¿ç´¢ï¼Œå¯¹äºåŒ–å­¦åˆ†å­çš„é‰´å®šå’Œæ€§è´¨é¢„æµ‹è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå®éªŒè°±å›¾çš„ç¼ºä¹é˜»ç¢äº†åˆ†å­é‰´å®šï¼Œå› æ­¤è¿«åˆ‡éœ€è¦å»ºç«‹è®¡ç®—æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨é¢„æµ‹åˆ†å­ç»“æ„è°±å›¾æ–¹é¢å‰æ™¯å¹¿é˜”ï¼Œä½†ç”±äºæ–¹æ³•çš„å¼‚è´¨æ€§å’Œç¼ºä¹æ˜ç¡®å®šä¹‰çš„åŸºå‡†ï¼Œæ•´ä½“è¯„ä¼°ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åˆ›å»ºäº†åŸºå‡†æ¡†æ¶FlexMSï¼Œç”¨äºæ„å»ºå’Œè¯„ä¼°è´¨è°±é¢„æµ‹ä¸­çš„å¤šç§æ¨¡å‹æ¶æ„ã€‚FlexMSæ”¯æŒåŠ¨æ€æ„å»ºä¼—å¤šä¸åŒçš„æ¨¡å‹æ¶æ„ç»„åˆï¼ŒåŒæ—¶ä½¿ç”¨ä¸åŒçš„æŒ‡æ ‡åœ¨é¢„å¤„ç†çš„å…¬å…±æ•°æ®é›†ä¸Šè¯„ä¼°å…¶æ€§èƒ½ã€‚æœ¬æ–‡æä¾›äº†å¯¹å½±å“æ€§èƒ½å› ç´ çš„è§è§£ï¼ŒåŒ…æ‹¬æ•°æ®é›†çš„ç»“æ„å¤šæ ·æ€§ã€å­¦ä¹ ç‡å’Œæ•°æ®ç¨€ç–æ€§ç­‰è¶…å‚æ•°ã€é¢„è®­ç»ƒæ•ˆæœã€å…ƒæ•°æ®æ¶ˆèè®¾ç½®ä»¥åŠè·¨é¢†åŸŸè¿ç§»å­¦ä¹ åˆ†æã€‚è¿™ä¸ºé€‰æ‹©åˆé€‚çš„æ¨¡å‹æä¾›äº†å®ç”¨æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œæ£€ç´¢åŸºå‡†æ¨¡æ‹Ÿäº†å®é™…çš„é‰´å®šåœºæ™¯ï¼Œå¹¶æ ¹æ®é¢„æµ‹çš„è°±å›¾å¯¹æ½œåœ¨åŒ¹é…è¿›è¡Œè¯„åˆ†ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

The identification and property prediction of chemical molecules is of central importance in the advancement of drug discovery and material science, where the tandem mass spectrometry technology gives valuable fragmentation cues in the form of mass-to-charge ratio peaks. However, the lack of experimental spectra hinders the attachment of each molecular identification, and thus urges the establishment of prediction approaches for computational models. Deep learning models appear promising for predicting molecular structure spectra, but overall assessment remains challenging as a result of the heterogeneity in methods and the lack of well-defined benchmarks. To address this, our contribution is the creation of benchmark framework FlexMS for constructing and evaluating diverse model architectures in mass spectrum prediction. With its easy-to-use flexibility, FlexMS supports the dynamic construction of numerous distinct combinations of model architectures, while assessing their performance on preprocessed public datasets using different metrics. In this paper, we provide insights into factors influencing performance, including the structural diversity of datasets, hyperparameters like learning rate and data sparsity, pretraining effects, metadata ablation settings and cross-domain transfer learning analysis. This provides practical guidance in choosing suitable models. Moreover, retrieval benchmarks simulate practical identification scenarios and score potential matches based on predicted spectra.

</details>

---

### 12. [MEDNA-DFM: A Dual-View FiLM-MoE Model for Explainable DNA Methylation Prediction](https://arxiv.org/abs/2602.22850)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22850`](https://arxiv.org/abs/2602.22850)
- ğŸ‘¥ ä½œè€…: Yi He, Yina Cao, Jixiu Zhai ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22850.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„ä¸»è¦ç ”ç©¶å†…å®¹æ˜¯å¼€å‘ç”¨äºDNAåºåˆ—ï¼ˆä¸€ç§åŒ–å­¦/ç”Ÿç‰©åˆ†å­ï¼‰ç”²åŸºåŒ–æ¨¡å¼é¢„æµ‹å’Œè§£é‡Šçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¿™å±äºã€åŒ–å­¦ä¿¡æ¯å­¦ã€‘çš„èŒƒç•´ï¼Œæ¶‰åŠåˆ†å­åºåˆ—æ•°æ®çš„å»ºæ¨¡å’Œæ¨ç†ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†MEDNA-DFMï¼Œä¸€ä¸ªç”¨äºDNAç”²åŸºåŒ–é¢„æµ‹çš„é«˜æ€§èƒ½ã€å¯è§£é‡Šçš„åŒè§†å›¾FiLM-MoEæ¨¡å‹ã€‚å‡†ç¡®çš„DNAç”²åŸºåŒ–è®¡ç®—é‰´å®šå¯¹äºç†è§£è¡¨è§‚é—ä¼ è°ƒæ§è‡³å…³é‡è¦ã€‚è™½ç„¶æ·±åº¦å­¦ä¹ åœ¨è¿™ä¸€äºŒå…ƒåˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶â€œé»‘ç®±â€æ€§è´¨é˜»ç¢äº†ç”Ÿç‰©å­¦æ´å¯Ÿã€‚æˆ‘ä»¬é€šè¿‡å¼•å…¥é«˜æ€§èƒ½æ¨¡å‹MEDNA-DFMä»¥åŠæœºåˆ¶å¯å‘çš„ä¿¡å·çº¯åŒ–ç®—æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼ŒMEDNA-DFMèƒ½æœ‰æ•ˆæ•æ‰ä¿å®ˆçš„ç”²åŸºåŒ–æ¨¡å¼ï¼Œåœ¨ä¸åŒç‰©ç§é—´å®ç°ç¨³å¥åŒºåˆ†ã€‚åœ¨å¤–éƒ¨ç‹¬ç«‹æ•°æ®é›†ä¸Šçš„éªŒè¯è¯å®ï¼Œæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æ˜¯ç”±ä¿å®ˆçš„å†…åœ¨åŸºåºï¼ˆå¦‚GCå«é‡ï¼‰é©±åŠ¨çš„ï¼Œè€Œéç³»ç»Ÿå‘è‚²ä¸Šçš„æ¥è¿‘æ€§ã€‚æ­¤å¤–ï¼Œåº”ç”¨æˆ‘ä»¬å¼€å‘çš„ç®—æ³•æå–çš„åŸºåºæ¯”å…ˆå‰çš„ç ”ç©¶å…·æœ‰æ˜¾è‘—æ›´é«˜çš„å¯é æ€§ã€‚æœ€åï¼Œæ¥è‡ªæœè‡6mAæ¡ˆä¾‹ç ”ç©¶çš„å®è¯è¯æ®ä¿ƒä½¿æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªâ€œåºåˆ—-ç»“æ„ååŒâ€å‡è¯´ï¼Œè¡¨æ˜GAGGæ ¸å¿ƒåŸºåºå’Œä¸Šæ¸¸çš„A-tractå…ƒä»¶ååŒä½œç”¨ã€‚æˆ‘ä»¬é€šè¿‡è®¡ç®—æœºè¯±å˜è¿›ä¸€æ­¥éªŒè¯äº†è¿™ä¸€å‡è¯´ï¼Œç¡®è®¤æ¶ˆé™¤ä»»ä¸€æˆ–ä¸¤ä¸ªå…ƒä»¶éƒ½ä¼šæ˜¾è‘—é™ä½æ¨¡å‹çš„è¯†åˆ«èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ºç”²åŸºåŒ–é¢„æµ‹æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œå¹¶å±•ç¤ºäº†å¯è§£é‡Šçš„æ·±åº¦å­¦ä¹ å¦‚ä½•æ¨åŠ¨æ–¹æ³•å­¦åˆ›æ–°å’Œç”Ÿç‰©å­¦å‡è¯´çš„äº§ç”Ÿã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Accurate computational identification of DNA methylation is essential for understanding epigenetic regulation. Although deep learning excels in this binary classification task, its "black-box" nature impedes biological insight. We address this by introducing a high-performance model MEDNA-DFM, alongside mechanism-inspired signal purification algorithms. Our investigation demonstrates that MEDNA-DFM effectively captures conserved methylation patterns, achieving robust distinction across diverse species. Validation on external independent datasets confirms that the model's generalization is driven by conserved intrinsic motifs (e.g., GC content) rather than phylogenetic proximity. Furthermore, applying our developed algorithms extracted motifs with significantly higher reliability than prior studies. Finally, empirical evidence from a Drosophila 6mA case study prompted us to propose a "sequence-structure synergy" hypothesis, suggesting that the GAGG core motif and an upstream A-tract element function cooperatively. We further validated this hypothesis via in silico mutagenesis, confirming that the ablation of either or both elements significantly degrades the model's recognition capabilities. This work provides a powerful tool for methylation prediction and demonstrates how explainable deep learning can drive both methodological innovation and the generation of biological hypotheses.

</details>

---

### 13. [MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis](https://arxiv.org/abs/2602.22955)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22955`](https://arxiv.org/abs/2602.22955)
- ğŸ‘¥ ä½œè€…: Feng Guo, Jiaxiang Liu, Yang Li ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22955.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šæ¨¡æ€åŒ»å­¦å½±åƒæ•°æ®é›†ï¼ˆMM-NeuroOncoï¼‰å’Œè¯„ä¼°åŸºå‡†ï¼ˆMM-NeuroOnco-Benchï¼‰ã€‚è™½ç„¶å…¶ç›´æ¥åº”ç”¨é¢†åŸŸæ˜¯åŒ»å­¦å½±åƒï¼Œä½†è¯¥å·¥ä½œæ ¸å¿ƒæ˜¯æ„å»ºå’Œåˆ©ç”¨é«˜è´¨é‡ã€è¯­ä¹‰ä¸°å¯Œçš„å¤šæ¨¡æ€æ•°æ®é›†æ¥è®­ç»ƒå’Œè¯„ä¼°AIæ¨¡å‹ã€‚è¿™ç§æ„å»ºæ•°æ®é›†å’ŒåŸºå‡†çš„æ–¹æ³•è®ºä¸ã€åŒ–å­¦ä¿¡æ¯å­¦ã€‘å’Œã€è´¨è°±åˆ†æã€‘ä¸­æ„å»ºç”¨äºæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°çš„åŒ–å­¦/è´¨è°±æ•°æ®é›†ï¼ˆå¦‚è´¨è°±åº“ã€åˆ†å­å±æ€§æ•°æ®é›†ï¼‰åœ¨ç†å¿µå’ŒæŠ€æœ¯è·¯å¾„ä¸Šé«˜åº¦ç›¸å…³ï¼Œå±äºé‡è¦çš„æ•°æ®èµ„æºã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†MM-NeuroOncoï¼Œä¸€ä¸ªç”¨äºåŸºäºMRIçš„è„‘è‚¿ç˜¤è¯Šæ–­çš„å¤§è§„æ¨¡å¤šæ¨¡æ€åŸºå‡†å’ŒæŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ã€‚å‡†ç¡®çš„è„‘è‚¿ç˜¤è¯Šæ–­è¦æ±‚æ¨¡å‹ä¸ä»…èƒ½æ£€æµ‹ç—…å˜ï¼Œè¿˜èƒ½ç”ŸæˆåŸºäºå½±åƒå­¦è¡¨ç°çš„ä¸´åºŠå¯è§£é‡Šæ¨ç†ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å…¬å…±æ•°æ®é›†åœ¨æ³¨é‡Šä¸°å¯Œæ€§å’Œè¯Šæ–­è¯­ä¹‰æ–¹é¢ä»ç„¶æœ‰é™ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†MM-NeuroOncoï¼Œå®ƒåŒ…å«æ¥è‡ª20ä¸ªæ•°æ®æºçš„24,726ä¸ªMRIåˆ‡ç‰‡ï¼Œé…å¯¹äº†å¤§çº¦200,000ä¸ªæ¶µç›–ä¸åŒè‚¿ç˜¤äºšå‹å’Œæˆåƒæ¨¡å¼çš„è¯­ä¹‰ä¸°å¯Œçš„å¤šæ¨¡æ€æŒ‡ä»¤ã€‚ä¸ºäº†ç¼“è§£è¯Šæ–­è¯­ä¹‰æ³¨é‡Šçš„ç¨€ç¼ºæ€§å’Œé«˜æˆæœ¬ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç”¨äºè‡ªåŠ¨åŒ–åŒ»å­¦ä¿¡æ¯è¡¥å…¨å’Œè´¨é‡æ§åˆ¶çš„å¤šæ¨¡å‹åä½œæµç¨‹ï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆè¶…è¶Šä»…æ©ç æ³¨é‡Šçš„è¯Šæ–­ç›¸å…³è¯­ä¹‰ã€‚åŸºäºæ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æ„å»ºäº†MM-NeuroOnco-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¦æœ‰æ‹’ç»æ„ŸçŸ¥è®¾ç½®çš„äººå·¥æ ‡æ³¨è¯„ä¼°åŸºå‡†ï¼Œä»¥å‡å°‘å°é—­å¼é—®é¢˜æ ¼å¼å›ºæœ‰çš„åè§ã€‚å¯¹åä¸ªä»£è¡¨æ€§æ¨¡å‹çš„è¯„ä¼°è¡¨æ˜ï¼Œå³ä½¿æ˜¯æœ€å¼ºçš„åŸºçº¿æ¨¡å‹Gemini 3 Flashï¼Œåœ¨è¯Šæ–­ç›¸å…³é—®é¢˜ä¸Šä¹Ÿä»…è¾¾åˆ°41.88%çš„å‡†ç¡®ç‡ï¼Œçªæ˜¾äº†å¤šæ¨¡æ€è„‘è‚¿ç˜¤è¯Šæ–­ç†è§£çš„å·¨å¤§æŒ‘æˆ˜ã€‚åˆ©ç”¨MM-NeuroOncoï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†NeuroOnco-GPTï¼Œç»è¿‡å¾®è°ƒåï¼Œå…¶åœ¨è¯Šæ–­é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡ç»å¯¹æå‡äº†27%ã€‚è¿™ä¸€ç»“æœè¯æ˜äº†æˆ‘ä»¬çš„æ•°æ®é›†å’ŒåŸºå‡†åœ¨æ¨è¿›åŸºäºä¸´åºŠçš„å¤šæ¨¡æ€è¯Šæ–­æ¨ç†æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Accurate brain tumor diagnosis requires models to not only detect lesions but also generate clinically interpretable reasoning grounded in imaging manifestations, yet existing public datasets remain limited in annotation richness and diagnostic semantics. To bridge this gap, we introduce MM-NeuroOnco, a large-scale multimodal benchmark and instruction-tuning dataset for brain tumor MRI understanding, consisting of 24,726 MRI slices from 20 data sources paired with approximately 200,000 semantically enriched multimodal instructions spanning diverse tumor subtypes and imaging modalities. To mitigate the scarcity and high cost of diagnostic semantic annotations, we develop a multi-model collaborative pipeline for automated medical information completion and quality control, enabling the generation of diagnosis-related semantics beyond mask-only annotations. Building upon this dataset, we further construct MM-NeuroOnco-Bench, a manually annotated evaluation benchmark with a rejection-aware setting to reduce biases inherent in closed-ended question formats. Evaluation across ten representative models shows that even the strongest baseline, Gemini 3 Flash, achieves only 41.88% accuracy on diagnosis-related questions, highlighting the substantial challenges of multimodal brain tumor diagnostic understanding. Leveraging MM-NeuroOnco, we further propose NeuroOnco-GPT, which achieves a 27% absolute accuracy improvement on diagnostic questions following fine-tuning. This result demonstrates the effectiveness of our dataset and benchmark in advancing clinically grounded multimodal diagnostic reasoning. Code and dataset are publicly available at: this https URL

</details>

---

### 14. [SPM-Bench: Benchmarking Large Language Models for Scanning Probe Microscopy](https://arxiv.org/abs/2602.22971)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22971`](https://arxiv.org/abs/2602.22971)
- ğŸ‘¥ ä½œè€…: Peiyao Xiao, Xiaogang Li, Chengliang Xu ç­‰13äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22971.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†2ï¼šè®ºæ–‡æå‡ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–æ•°æ®åˆæˆç®¡é“å’ŒåŸºå‡†æµ‹è¯•SPM-Benchï¼Œå…¶æ–¹æ³•è®ºï¼ˆä»ç§‘å­¦æ–‡çŒ®ä¸­æå–å¤šæ¨¡æ€æ•°æ®ã€æ„å»ºé¢†åŸŸä¸“ç”¨æ•°æ®é›†ï¼‰ä¸ºæ„å»ºç”¨äºâ€œåŒ–å­¦å¤§æ¨¡å‹â€è®­ç»ƒå’Œè¯„ä¼°çš„åŒ–å­¦é¢†åŸŸæ•°æ®é›†æä¾›äº†ç›´æ¥ç›¸å…³çš„æŠ€æœ¯æ€è·¯å’Œå¯å€Ÿé‰´çš„èŒƒå¼ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è®ºæ–‡æå‡ºäº†SPM-Benchï¼Œä¸€ä¸ªç”¨äºæ‰«ææ¢é’ˆæ˜¾å¾®é•œï¼ˆSPMï¼‰é¢†åŸŸçš„å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºä¸€ä¸ªå…¨è‡ªåŠ¨çš„æ•°æ®åˆæˆç®¡é“ï¼Œè¯¥ç®¡é“åˆ©ç”¨Anchor-Gated Sieveï¼ˆAGSï¼‰æŠ€æœ¯ä»arXivå’ŒæœŸåˆŠè®ºæ–‡ï¼ˆ2023-2025å¹´ï¼‰ä¸­é«˜æ•ˆæå–é«˜è´¨é‡çš„å›¾åƒ-æ–‡æœ¬å¯¹ã€‚è¿™é¡¹å·¥ä½œè™½ç„¶èšç„¦äºSPMé¢†åŸŸï¼Œä½†å…¶æå‡ºçš„è‡ªåŠ¨åŒ–ç§‘å­¦æ•°æ®åˆæˆèŒƒå¼ã€ä»æµ·é‡ç§‘å­¦æ–‡çŒ®ï¼ˆåŒ…æ‹¬arXivï¼‰ä¸­æå–ç»“æ„åŒ–å¤šæ¨¡æ€æ•°æ®çš„æ–¹æ³•ï¼Œä»¥åŠæ„å»ºé¢†åŸŸä¸“ç”¨åŸºå‡†æµ‹è¯•çš„æ¡†æ¶ï¼Œä¸åŒ–å­¦ä¿¡æ¯å­¦ä¸­æ„å»ºç”¨äºè®­ç»ƒå’Œè¯„ä¼°â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„æ•°æ®é›†å’Œèµ„æºçš„éœ€æ±‚é«˜åº¦ç›¸å…³ã€‚å®ƒä¸ºå¦‚ä½•ä»ç§‘å­¦æ–‡çŒ®ä¸­è‡ªåŠ¨æ„å»ºé«˜è´¨é‡ã€é¢†åŸŸç‰¹å®šçš„è®­ç»ƒå’Œè¯„ä¼°æ•°æ®æä¾›äº†ä¸€ä¸ªå¯æ¨å¹¿çš„èŒƒä¾‹ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

As LLMs achieved breakthroughs in general reasoning, their proficiency in specialized scientific domains reveals pronounced gaps in existing benchmarks due to data contamination, insufficient complexity, and prohibitive human labor costs. Here we present SPM-Bench, an original, PhD-level multimodal benchmark specifically designed for scanning probe microscopy (SPM). We propose a fully automated data synthesis pipeline that ensures both high authority and low-cost. By employing Anchor-Gated Sieve (AGS) technology, we efficiently extract high-value image-text pairs from arXiv and journal papers published between 2023 and 2025. Through a hybrid cloud-local architecture where VLMs return only spatial coordinates "llbox" for local high-fidelity cropping, our pipeline achieves extreme token savings while maintaining high dataset purity. To accurately and objectively evaluate the performance of the LLMs, we introduce the Strict Imperfection Penalty F1 (SIP-F1) score. This metric not only establishes a rigorous capability hierarchy but also, for the first time, quantifies model "personalities" (Conservative, Aggressive, Gambler, or Wise). By correlating these results with model-reported confidence and perceived difficulty, we expose the true reasoning boundaries of current AI in complex physical scenarios. These insights establish SPM-Bench as a generalizable paradigm for automated scientific data synthesis.

</details>

---

### 15. [Induction Meets Biology: Mechanisms of Repeat Detection in Protein Language Models](https://arxiv.org/abs/2602.23179)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.23179`](https://arxiv.org/abs/2602.23179)
- ğŸ‘¥ ä½œè€…: Gal Kesten-Pomeranz, Yaniv Nikankin, Anja Reusch ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.23179.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯æ¢ç©¶è›‹ç™½è´¨è¯­è¨€æ¨¡å‹ï¼ˆä¸€ç§ç”¨äºç”Ÿç‰©åˆ†å­çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼‰å†…éƒ¨æ£€æµ‹åºåˆ—é‡å¤æ¨¡å¼çš„æœºåˆ¶ï¼Œè¿™ç›´æ¥å…³è”åˆ°â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„å¯è§£é‡Šæ€§å’Œå…¶å¦‚ä½•ç¼–ç åŒ–å­¦/ç»“æ„çŸ¥è¯†ï¼Œå¯¹äºæ„å»ºå’Œç†è§£ç”¨äºç»“æ„æ¨ç†çš„æ¨¡å‹è‡³å…³é‡è¦ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è®ºæ–‡ç ”ç©¶äº†è›‹ç™½è´¨è¯­è¨€æ¨¡å‹ï¼ˆPLMsï¼‰å†…éƒ¨æ£€æµ‹è›‹ç™½è´¨åºåˆ—ä¸­é‡å¤ç‰‡æ®µï¼ˆåŒ…æ‹¬ç²¾ç¡®é‡å¤å’Œè¿‘ä¼¼é‡å¤ï¼‰çš„æœºåˆ¶ã€‚ä½œè€…å‘ç°PLMsé€šè¿‡ç»“åˆåŸºäºè¯­è¨€çš„æ¨¡å¼åŒ¹é…ï¼ˆå¦‚å½’çº³å¤´ï¼‰å’Œä¸“é—¨çš„ç”Ÿç‰©å­¦çŸ¥è¯†ï¼ˆå¦‚ç¼–ç æ°¨åŸºé…¸ç›¸ä¼¼æ€§çš„ç¥ç»å…ƒï¼‰æ¥è§£å†³è¿™ä¸€ç”Ÿç‰©å­¦ä»»åŠ¡ã€‚è¿™é¡¹å·¥ä½œå±äºå¯¹â€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆæ­¤å¤„ç‰¹æŒ‡é¢å‘ç”Ÿç‰©å¤§åˆ†å­çš„è¯­è¨€æ¨¡å‹ï¼‰å†…éƒ¨å·¥ä½œæœºåˆ¶çš„å¯è§£é‡Šæ€§ç ”ç©¶ã€‚å®ƒæ­ç¤ºäº†PLMså¦‚ä½•å­¦ä¹ å’Œåˆ©ç”¨åŒ–å­¦/ç”Ÿç‰©å­¦å…ˆéªŒçŸ¥è¯†ï¼ˆå¦‚æ°¨åŸºé…¸ç›¸ä¼¼æ€§ï¼‰æ¥å®Œæˆç‰¹å®šçš„ç»“æ„æ¨ç†ä»»åŠ¡ï¼Œè¿™å¯¹äºç†è§£å’Œæ”¹è¿›ç”¨äºâ€œè´¨è°±ç»“æ„æ¨ç†â€æˆ–æ›´å¹¿æ³›çš„åˆ†å­ç»“æ„é¢„æµ‹çš„æ¨¡å‹å…·æœ‰å¯å‘æ„ä¹‰ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Protein sequences are abundant in repeating segments, both as exact copies and as approximate segments with mutations. These repeats are important for protein structure and function, motivating decades of algorithmic work on repeat identification. Recent work has shown that protein language models (PLMs) identify repeats, by examining their behavior in masked-token prediction. To elucidate their internal mechanisms, we investigate how PLMs detect both exact and approximate repeats. We find that the mechanism for approximate repeats functionally subsumes that of exact repeats. We then characterize this mechanism, revealing two main stages: PLMs first build feature representations using both general positional attention heads and biologically specialized components, such as neurons that encode amino-acid similarity. Then, induction heads attend to aligned tokens across repeated segments, promoting the correct answer. Our results reveal how PLMs solve this biological task by combining language-based pattern matching with specialized biological knowledge, thereby establishing a basis for studying more complex evolutionary processes in PLMs.

</details>

---

### 16. [Inferential Mechanics Part 1: Causal Mechanistic Theories of Machine Learning in Chemical Biology with Implications](https://arxiv.org/abs/2602.23303)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.23303`](https://arxiv.org/abs/2602.23303)
- ğŸ‘¥ ä½œè€…: Ilya Balabin, Thomas M. Kaiser
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.23303.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹ç›´æ¥å›´ç»•åŒ–å­¦ç”Ÿç‰©å­¦ä¸­æœºå™¨å­¦ä¹ æ¨¡å‹çš„å› æœæ¨ç†åŸºç¡€ç†è®ºã€‚å®ƒæ—¨åœ¨ä¸ºæ„å»ºèƒ½å¤Ÿç†è§£æœºåˆ¶è€Œä¸ä»…ä»…æ˜¯å…³è”çš„ã€æ›´å¼ºå¤§çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€æä¾›æ•°å­¦å’Œç†è®ºæ¡†æ¶ï¼Œè¿™ä¸å…³æ³¨ä¸»é¢˜ä¸­â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„å¯é æ€§å’Œå¯è§£é‡Šæ€§å‘å±•é«˜åº¦ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡æ˜¯ç³»åˆ—æ–‡ç« çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œæ—¨åœ¨ä¸ºåŒ–å­¦ç”Ÿç‰©å­¦ä¸­çš„æœºå™¨å­¦ä¹ å»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„å› æœåŠ›å­¦ç†è®ºæ¡†æ¶ã€‚å®ƒæ‰¹åˆ¤äº†å½“å‰å°†æœºå™¨å­¦ä¹ æ¨¡å‹è§†ä¸ºé»‘ç®±çš„åšæ³•ï¼Œå¹¶å¼ºè°ƒéœ€è¦ç†è§£æ•°æ®èƒŒåçš„å› æœç»“æ„ã€‚è®ºæ–‡æå‡ºäº†â€œç„¦ç‚¹â€è¿™ä¸€æ–°æ¦‚å¿µï¼Œå³æœºå™¨å­¦ä¹ ç®—æ³•ä»å¤§æ•°æ®é›†ä¸­èšç„¦äºéšè—åº•å±‚æœºåˆ¶çš„èƒ½åŠ›ã€‚ä½œè€…ä»¥AktæŠ‘åˆ¶å‰‚å®¶æ—ä¸ºä¾‹æä¾›äº†åˆæ­¥è¯æ˜ã€‚è¯¥å·¥ä½œç›´æ¥é’ˆå¯¹åŒ–å­¦å’Œç”Ÿç‰©å­¦é¢†åŸŸæœºå™¨å­¦ä¹ æ¨¡å‹çš„åŸºç¡€ç†è®ºï¼Œæ—¨åœ¨çº æ­£å½“å‰æ–¹æ³•åœ¨å› æœå…³ç³»ä¸Šçš„ç¼ºé™·ï¼Œè¿™å¯¹äºæ„å»ºèƒ½å¤Ÿè¿›è¡Œå¯é æ¨ç†è€Œä¸ä»…ä»…æ˜¯æ¨¡å¼åŒ¹é…çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€è‡³å…³é‡è¦ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Machine learning techniques are now routinely encountered in research laboratories across the globe. Impressive progress has been made through ML and AI techniques with regards to large data set processing. This progress has increased the ability of the experimenter to digest data and make novel predictions regarding phenomena of interest. However, machine learning predictors generated from data sets taken from the natural sciences are often treated as black boxes which are used broadly and generally without detailed consideration of the causal structure of the data set of interest. Work has been attempted to bring causality into discussions of machine learning models of natural phenomena; however, a firm and unified theoretical treatment is lacking. This series of three papers explores the union of chemical theory, biological theory, probability theory and causality that will correct current causal flaws of machine learning in the natural sciences. This paper, Part 1 of the series, provides the formal framework of the foundational causal structure of phenomena in chemical biology and is extended to machine learning through the novel concept of focus, defined here as the ability of a machine learning algorithm to narrow down to a hidden underpinning mechanism in large data sets. Initial proof of these principles on a family of Akt inhibitors is also provided. The second paper containing Part 2 will provide a formal exploration of chemical similarity, and Part 3 will present extensive experimental evidence of how hidden causal structures weaken all machine learning in chemical biology. This series serves to establish for chemical biology a new kind of mathematical framework for modeling mechanisms in Nature without the need for the tools of reductionism: inferential mechanics.

</details>

---

### 17. [CrossLLM-Mamba: Multimodal State Space Fusion of LLMs for RNA Interaction Prediction](https://arxiv.org/abs/2602.22236)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22236`](https://arxiv.org/abs/2602.22236)
- ğŸ‘¥ ä½œè€…: Rabeya Tus Sadia, Qiang Ye, Qiang Cheng
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22236.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆBioLLMsï¼‰çš„è¡¨ç¤ºè¿›è¡Œå¤šæ¨¡æ€ç”Ÿç‰©åˆ†å­ç›¸äº’ä½œç”¨çš„é¢„æµ‹ä¸æ¨ç†ã€‚å…¶æ–¹æ³•è®ºï¼ˆåŸºäºLLMçš„è¡¨ç¤ºå­¦ä¹ ä¸çŠ¶æ€ç©ºé—´æ¨¡å‹è¿›è¡ŒåŠ¨æ€æ¨ç†ï¼‰ç›´æ¥å›´ç»•â€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆæ‰©å±•è‡³ç”Ÿç‰©å¤§åˆ†å­ï¼‰å’Œâ€œç»“æ„æ¨ç†â€ï¼ˆé¢„æµ‹åˆ†å­é—´ç›¸äº’ä½œç”¨ç»“æ„ï¼‰çš„ä¸»é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºCrossLLM-Mambaçš„æ–°å‹æ¡†æ¶ï¼Œç”¨äºé¢„æµ‹RNAç›¸å…³çš„ç›¸äº’ä½œç”¨ï¼ˆå¦‚RNA-è›‹ç™½è´¨ã€RNA-å°åˆ†å­ï¼‰ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨åŒå‘Mambaç¼–ç å™¨ï¼Œå®ç°ä¸åŒæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ESM-2, RiNALMoï¼‰åµŒå…¥ä¹‹é—´çš„æ·±åº¦â€œå¯¹è¯â€ï¼Œé€šè¿‡éšè—çŠ¶æ€ä¼ æ’­å°†ç›¸äº’ä½œç”¨å»ºæ¨¡ä¸ºåŠ¨æ€åºåˆ—è½¬æ¢ã€‚è¯¥æ¡†æ¶æ—¨åœ¨ä»ç”Ÿç‰©åºåˆ—çš„è¡¨ç¤ºä¸­å­¦ä¹ å¹¶é¢„æµ‹å¤æ‚çš„åˆ†å­é—´ç›¸äº’ä½œç”¨ã€‚è™½ç„¶å…¶ç›´æ¥åº”ç”¨æ˜¯ç”Ÿç‰©åˆ†å­ç›¸äº’ä½œç”¨ï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•è®ºâ€”â€”åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œå¹¶é€šè¿‡å…ˆè¿›çš„åºåˆ—æ¨¡å‹ï¼ˆMambaï¼‰è¿›è¡Œå¤šæ¨¡æ€èåˆä¸åŠ¨æ€æ¨ç†â€”â€”ä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€å’Œä»å¤æ‚æ•°æ®ï¼ˆç±»æ¯”äºè´¨è°±æ•°æ®ï¼‰ä¸­è¿›è¡Œâ€œç»“æ„æ¨ç†â€çš„ç ”ç©¶ä¸»é¢˜åœ¨æ–¹æ³•è®ºä¸Šé«˜åº¦ç›¸å…³ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Accurate prediction of RNA-associated interactions is essential for understanding cellular regulation and advancing drug discovery. While Biological Large Language Models (BioLLMs) such as ESM-2 and RiNALMo provide powerful sequence representations, existing methods rely on static fusion strategies that fail to capture the dynamic, context-dependent nature of molecular binding. We introduce CrossLLM-Mamba, a novel framework that reformulates interaction prediction as a state-space alignment problem. By leveraging bidirectional Mamba encoders, our approach enables deep ``crosstalk'' between modality-specific embeddings through hidden state propagation, modeling interactions as dynamic sequence transitions rather than static feature overlaps. The framework maintains linear computational complexity, making it scalable to high-dimensional BioLLM embeddings. We further incorporate Gaussian noise injection and Focal Loss to enhance robustness against hard-negative samples. Comprehensive experiments across three interaction categories, RNA-protein, RNA-small molecule, and RNA-RNA demonstrate that CrossLLM-Mamba achieves state-of-the-art performance. On the RPI1460 benchmark, our model attains an MCC of 0.892, surpassing the previous best by 5.2\%. For binding affinity prediction, we achieve Pearson correlations exceeding 0.95 on riboswitch and repeat RNA subtypes. These results establish state-space modeling as a powerful paradigm for multi-modal biological interaction prediction.

</details>

---

### 18. [VAE-MS: An Asymmetric Variational Autoencoder for Mutational Signature Extraction](https://arxiv.org/abs/2602.22239)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22239`](https://arxiv.org/abs/2602.22239)
- ğŸ‘¥ ä½œè€…: Ida Egendal, Rasmus Froberg BrÃ¸ndum, Dan J Woodcock ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22239.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼ˆå˜åˆ†è‡ªç¼–ç å™¨ï¼‰ï¼Œç”¨äºä»é«˜ç»´ã€å¤æ‚çš„ç”Ÿç‰©åŒ»å­¦æ•°æ®ï¼ˆçªå˜è°±ï¼‰ä¸­æå–å¯è§£é‡Šçš„æ½œåœ¨ç‰¹å¾ã€‚è¿™ç§â€œä»æ•°æ®ä¸­å­¦ä¹ è¡¨ç¤ºå¹¶è¿›è¡Œæ¨ç†â€çš„æ–¹æ³•è®ºï¼Œä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­ä»è´¨è°±æ•°æ®æ¨æ–­åˆ†å­ç»“æ„æˆ–ç‰¹å¾çš„æ ¸å¿ƒä»»åŠ¡åœ¨æŠ€æœ¯è·¯çº¿ä¸Šé«˜åº¦ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡æå‡ºäº†VAE-MSï¼Œä¸€ç§ç”¨äºä»ç™Œç—‡åŸºå› ç»„æ•°æ®ä¸­æå–çªå˜ç‰¹å¾çš„éå¯¹ç§°å˜åˆ†è‡ªç¼–ç å™¨æ¨¡å‹ã€‚çªå˜ç‰¹å¾åˆ†ææ—¨åœ¨è¯†åˆ«å¯¼è‡´DNAçªå˜çš„æ½œåœ¨ç”Ÿç‰©å­¦è¿‡ç¨‹ã€‚è¯¥ç ”ç©¶å°†ç¥ç»ç½‘ç»œï¼ˆç‰¹åˆ«æ˜¯æ¦‚ç‡ç”Ÿæˆæ¨¡å‹VAEï¼‰åº”ç”¨äºä»é«˜ç»´ã€ç¨€ç–çš„çªå˜è®¡æ•°æ•°æ®ä¸­å­¦ä¹ å¯è§£é‡Šçš„æ½œåœ¨æ¨¡å¼ï¼ˆå³â€œç‰¹å¾â€ï¼‰ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ä»å¤æ‚çš„ç”Ÿç‰©åŒ»å­¦æ•°æ®ä¸­æå–æœ‰æ„ä¹‰çš„ã€å¯è§£é‡Šçš„è¡¨ç¤ºæ–¹é¢çš„èƒ½åŠ›ã€‚å…¶æ–¹æ³•è®ºâ€”â€”ä½¿ç”¨æ·±åº¦ç”Ÿæˆæ¨¡å‹å¯¹é«˜ç»´ç§‘å­¦æ•°æ®è¿›è¡Œé™ç»´å’Œç‰¹å¾å‘ç°â€”â€”ä¸åŒ–å­¦ä¿¡æ¯å­¦ä¸­åˆ©ç”¨æ¨¡å‹ä»è´¨è°±ç­‰å¤æ‚æ•°æ®ä¸­æ¨æ–­åˆ†å­ç‰¹å¾æˆ–ç»“æ„çš„ç ”ç©¶èŒƒå¼å…·æœ‰ç›¸ä¼¼æ€§ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Mutational signature analysis has emerged as a powerful method for uncovering the underlying biological processes driving cancer development. However, the signature extraction process, typically performed using non-negative matrix factorization (NMF), often lacks reliability and clinical applicability. To address these limitations, several solutions have been introduced, including the use of neural networks to achieve more accurate estimates and probabilistic methods to better capture natural variation in the data. In this work, we introduce a Variational Autoencoder for Mutational Signatures (VAE-MS), a novel model that leverages both an asymmetric architecture and probabilistic methods for the extraction of mutational signatures. VAE-MS is compared to with three state-of-the-art models for mutational signature extraction: SigProfilerExtractor, the NMF-based gold standard; MUSE-XAE, an autoencoder that employs an asymmetric design without probabilistic components; and SigneR, a Bayesian NMF model, to illustrate the strength in combining a nonlinear extraction with a probabilistic model. In the ability to reconstruct input data and generalize to unseen data, models with probabilistic components (VAE-MS, SigneR) dramatically outperformed models without (SigProfilerExtractor, MUSE-XAE). The NMF-baed models (SigneR, SigProfilerExtractor) had the most accurate reconstructions in simulated data, while VAE-MS reconstructed more accurately on real cancer data. Upon evaluating the ability to extract signatures consistently, no model exhibited a clear advantage over the others. Software for VAE-MS is available at this https URL .

</details>

---

### 19. [Machine Learning on Heterogeneous, Edge, and Quantum Hardware for Particle Physics (ML-HEQUPP)](https://arxiv.org/abs/2602.22248)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22248`](https://arxiv.org/abs/2602.22248)
- ğŸ‘¥ ä½œè€…: Julia Gonski, Jenni Ott, Shiva Abbaszadeh ç­‰100äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22248.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ¶‰åŠåœ¨ç§‘å­¦è®¡ç®—ä¸­ï¼ˆç‰¹åˆ«æ˜¯ç²’å­ç‰©ç†ï¼‰éƒ¨ç½²å’Œä¼˜åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹æ‰€éœ€çš„ç¡¬ä»¶å’Œç³»ç»Ÿæ¶æ„ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸä¸åŒï¼Œä½†å…¶å¯¹å¤§è§„æ¨¡ã€ä½å»¶è¿Ÿç§‘å­¦MLæ¨¡å‹åœ¨ä¸“ç”¨ç¡¬ä»¶ä¸Šå®ç°çš„æŠ€æœ¯è®¨è®ºï¼Œä¸æ„å»ºå’Œéƒ¨ç½²éœ€è¦å¤„ç†æµ·é‡æ•°æ®ã€è¿›è¡Œå¤æ‚æ¨ç†çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€ç³»ç»Ÿæ‰€é¢ä¸´çš„æ ¸å¿ƒå·¥ç¨‹æŒ‘æˆ˜ç›´æ¥ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†åœ¨ç²’å­ç‰©ç†å®éªŒä¸­åº”ç”¨æœºå™¨å­¦ä¹ æ‰€é¢ä¸´çš„ç¡¬ä»¶æŒ‘æˆ˜å’Œæœºé‡ï¼Œç‰¹åˆ«å…³æ³¨å¼‚æ„è®¡ç®—ã€è¾¹ç¼˜è®¡ç®—å’Œé‡å­ç¡¬ä»¶ã€‚è™½ç„¶é¢†åŸŸä¸åŒï¼Œä½†è®ºæ–‡ä¸­æ·±å…¥è®¨è®ºäº†ä¸ºåº”å¯¹æç«¯æ•°æ®é€Ÿç‡å’Œå®æ—¶æ¨ç†éœ€æ±‚ï¼Œåœ¨ä¸“ç”¨ç¡¬ä»¶ï¼ˆå¦‚ä½åŠŸè€—è¾¹ç¼˜è®¾å¤‡ã€å¯é‡æ„ç¡¬ä»¶ã€æ¨¡æ‹Ÿè®¡ç®—ï¼‰ä¸Šéƒ¨ç½²å’Œä¼˜åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆåŒ…æ‹¬å¯èƒ½çš„æœªæ¥å¤§æ¨¡å‹ï¼‰çš„ç­–ç•¥ã€‚è¿™äº›å…³äºåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹é«˜æ•ˆéƒ¨ç½²å’Œè¿è¡Œå¤æ‚æ¨¡å‹çš„æŠ€æœ¯è®¨è®ºï¼Œå¯¹äºæ—¨åœ¨å¤„ç†æµ·é‡åŒ–åˆç‰©è´¨è°±æ•°æ®ã€éœ€è¦è¿›è¡Œå®æ—¶æˆ–è¿‘å®æ—¶ç»“æ„æ¨ç†çš„â€œåŒ–å­¦å¤§æ¨¡å‹â€ç³»ç»Ÿå…·æœ‰é‡è¦çš„å‚è€ƒä»·å€¼ï¼Œæ¶‰åŠæ¨¡å‹å‹ç¼©ã€ç¡¬ä»¶ååŒè®¾è®¡ç­‰å…±æ€§æŒ‘æˆ˜ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

The next generation of particle physics experiments will face a new era of challenges in data acquisition, due to unprecedented data rates and volumes along with extreme environments and operational constraints. Harnessing this data for scientific discovery demands real-time inference and decision-making, intelligent data reduction, and efficient processing architectures beyond current capabilities. Crucial to the success of this experimental paradigm are several emerging technologies, such as artificial intelligence and machine learning (AI/ML) and silicon microelectronics, and the advent of quantum algorithms and processing. Their intersection includes areas of research such as low-power and low-latency devices for edge computing, heterogeneous accelerator systems, reconfigurable hardware, novel codesign and synthesis strategies, readout for cryogenic or high-radiation environments, and analog computing. This white paper presents a community-driven vision to identify and prioritize research and development opportunities in hardware-based ML systems and corresponding physics applications, contributing towards a successful transition to the new data frontier of fundamental science.

</details>

---

### 20. [Flow Matching is Adaptive to Manifold Structures](https://arxiv.org/abs/2602.22486)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22486`](https://arxiv.org/abs/2602.22486)
- ğŸ‘¥ ä½œè€…: Shivam Kumar, Yixin Wang, Lizhen Lin
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22486.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç†è®ºåˆ†æç›´æ¥å›´ç»•ç”Ÿæˆå»ºæ¨¡æ–¹æ³•ï¼ˆæµåŒ¹é…ï¼‰å±•å¼€ï¼Œè¯¥æ–¹æ³•åœ¨åˆ†å­ç»“æ„ç”Ÿæˆç­‰åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œè€Œåˆ†å­ç»“æ„ç”Ÿæˆæ˜¯'è´¨è°±ç»“æ„æ¨ç†'å’Œ'åŒ–å­¦å¤§æ¨¡å‹'ï¼ˆç‰¹åˆ«æ˜¯ç”Ÿæˆæ¨¡å‹ï¼‰çš„æ ¸å¿ƒåº”ç”¨ä¹‹ä¸€ã€‚è®ºæ–‡ä¸ºè¿™ç±»æ¨¡å‹åœ¨æµå½¢æ•°æ®ä¸Šçš„æœ‰æ•ˆæ€§æä¾›äº†ç†è®ºè§£é‡Šã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡ä»ç†è®ºä¸Šåˆ†æäº†æµåŒ¹é…ï¼ˆFlow Matchingï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºç”Ÿæˆå»ºæ¨¡çš„æ— æ¨¡æ‹Ÿæ›¿ä»£æ–¹æ¡ˆï¼Œç‰¹åˆ«é€‚ç”¨äºæ•°æ®é›†ä¸­åœ¨ä½ç»´æµå½¢ä¸Šçš„é«˜ç»´åœºæ™¯ã€‚è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºï¼Œå½“ç›®æ ‡åˆ†å¸ƒæ”¯æ’‘åœ¨å…‰æ»‘æµå½¢ä¸Šæ—¶ï¼Œä¸ºæµåŒ¹é…æ–¹æ³•å»ºç«‹äº†éæ¸è¿‘æ”¶æ•›ä¿è¯å’Œç»Ÿè®¡ä¸€è‡´æ€§ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒæµåŒ¹é…èƒ½å¤Ÿè‡ªé€‚åº”äºæ•°æ®çš„å†…åœ¨å‡ ä½•ç»“æ„ï¼Œè§„é¿ç»´åº¦ç¾éš¾ï¼Œå…¶æ”¶æ•›é€Ÿç‡ä»…ä¾èµ–äºå†…åœ¨ç»´åº¦ã€‚è¿™ä¸€ç†è®ºåˆ†æä¸ºæµåŒ¹é…åœ¨åˆ†å­ç»“æ„ç”Ÿæˆç­‰é¢†åŸŸçš„æˆåŠŸæä¾›äº†åŸç†æ€§è§£é‡Šã€‚ç”±äºåˆ†å­ç»“æ„ç”Ÿæˆæ˜¯åŒ–å­¦ä¿¡æ¯å­¦å’Œè´¨è°±åˆ†æä¸­ç»“æ„æ¨ç†çš„æ ¸å¿ƒé—®é¢˜ï¼Œè¯¥è®ºæ–‡æå‡ºçš„ç†è®ºæ¡†æ¶å’Œåˆ†ææ–¹æ³•ä¸ºå¼€å‘ç”¨äºè´¨è°±ç»“æ„æ¨ç†çš„ç”Ÿæˆå¼åŒ–å­¦å¤§æ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯åŸºäºæµçš„æ¨¡å‹ï¼‰æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œç†è®ºä¿è¯ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Flow matching has emerged as a simulation-free alternative to diffusion-based generative modeling, producing samples by solving an ODE whose time-dependent velocity field is learned along an interpolation between a simple source distribution (e.g., a standard normal) and a target data distribution. Flow-based methods often exhibit greater training stability and have achieved strong empirical performance in high-dimensional settings where data concentrate near a low-dimensional manifold, such as text-to-image synthesis, video generation, and molecular structure generation. Despite this success, existing theoretical analyses of flow matching assume target distributions with smooth, full-dimensional densities, leaving its effectiveness in manifold-supported settings largely unexplained. To this end, we theoretically analyze flow matching with linear interpolation when the target distribution is supported on a smooth manifold. We establish a non-asymptotic convergence guarantee for the learned velocity field, and then propagate this estimation error through the ODE to obtain statistical consistency of the implicit density estimator induced by the flow-matching objective. The resulting convergence rate is near minimax-optimal, depends only on the intrinsic dimension, and reflects the smoothness of both the manifold and the target distribution. Together, these results provide a principled explanation for how flow matching adapts to intrinsic data geometry and circumvents the curse of dimensionality.

</details>

---

### 21. [Discovery of Interpretable Physical Laws in Materials via Language-Model-Guided Symbolic Regression](https://arxiv.org/abs/2602.22967)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.22967`](https://arxiv.org/abs/2602.22967)
- ğŸ‘¥ ä½œè€…: Yifeng Guan, Chuyi Liu, Dongzhan Zhou ç­‰7äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.22967.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼•å¯¼çš„ã€ç”¨äºå‘ç°ææ–™ç§‘å­¦ä¸­ç‰©ç†å®šå¾‹çš„æ¡†æ¶ã€‚è¿™ç›´æ¥å±äº'åŒ–å­¦å¤§æ¨¡å‹'çš„ç ”ç©¶èŒƒç•´ï¼Œå³åˆ©ç”¨å…ˆè¿›çš„äººå·¥æ™ºèƒ½æ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯LLMï¼‰æ¥è§£å†³åŒ–å­¦å’Œææ–™ç§‘å­¦ä¸­çš„å¤æ‚é—®é¢˜ï¼Œå¦‚ä»æ•°æ®ä¸­æ¨å¯¼ interpretable çš„ç‰©ç†è§„å¾‹ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼•å¯¼ç¬¦å·å›å½’ï¼ˆSymbolic Regressionï¼‰æ¥ä»é«˜ç»´æ•°æ®ä¸­å‘ç°å¯è§£é‡Šç‰©ç†å®šå¾‹çš„æ¡†æ¶ã€‚è¯¥æ–¹æ³•æ—¨åœ¨ç¼“è§£ä¼ ç»Ÿç¬¦å·å›å½’åœ¨æœç´¢å·¨å¤§å¯èƒ½å½¢å¼ç©ºé—´æ—¶äº§ç”Ÿçš„ç»„åˆçˆ†ç‚¸é—®é¢˜ã€‚ç ”ç©¶è€…é€šè¿‡åˆ©ç”¨LLMä¸­åµŒå…¥çš„ç§‘å­¦çŸ¥è¯†æ¥å¼•å¯¼æœç´¢è¿‡ç¨‹ï¼Œä»è€Œé«˜æ•ˆåœ°è¯†åˆ«æ•°æ®ä¸­çš„ç‰©ç†å®šå¾‹ã€‚è¯¥æ–¹æ³•åœ¨é’™é’›çŸ¿ææ–™çš„å…³é”®å±æ€§å»ºæ¨¡ä¸Šè¿›è¡Œäº†éªŒè¯ï¼ŒæˆåŠŸåœ°å°†æœ‰æ•ˆæœç´¢ç©ºé—´å‡å°‘äº†çº¦10^5å€ï¼Œå¹¶è¯†åˆ«å‡ºäº†ç”¨äºä½“æ¨¡é‡ã€å¸¦éš™å’Œææ°§ååº”æ´»æ€§çš„æ–°å…¬å¼ã€‚è¿™äº›å…¬å¼ä¸ä»…æä¾›äº†æœ‰æ„ä¹‰çš„ç‰©ç†è§è§£ï¼Œè€Œä¸”åœ¨å‡†ç¡®æ€§å’Œç®€æ´æ€§ä¸Šè¶…è¶Šäº†ä»¥å¾€çš„å…¬å¼ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Discovering interpretable physical laws from high-dimensional data is a fundamental challenge in scientific research. Traditional methods, such as symbolic regression, often produce complex, unphysical formulas when searching a vast space of possible forms. We introduce a framework that guides the search process by leveraging the embedded scientific knowledge of large language models, enabling efficient identification of physical laws in the data. We validate our approach by modeling key properties of perovskite materials. Our method mitigates the combinatorial explosion commonly encountered in traditional symbolic regression, reducing the effective search space by a factor of approximately $10^5$. A set of novel formulas for bulk modulus, band gap, and oxygen evolution reaction activity are identified, which not only provide meaningful physical insights but also outperform previous formulas in accuracy and simplicity.

</details>

---

### 22. [Efficient Graph Coloring with Neural Networks: A Physics-Inspired Approach for Large Graphs](https://arxiv.org/abs/2408.01503)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2408.01503`](https://arxiv.org/abs/2408.01503)
- ğŸ‘¥ ä½œè€…: Lorenzo Colantonio, Andrea Cacioppo, Federico Scarpati ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2408.01503.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§ç”¨äºè§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜ï¼ˆå›¾ç€è‰²ï¼‰çš„ç¥ç»æ±‚è§£å™¨æ¡†æ¶ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯å›¾è®ºï¼Œä½†è¯¥æ–¹æ³•è®ºï¼ˆç»“åˆGNNä¸ç‰©ç†åŸç†çš„ç¥ç»æ¡†æ¶ï¼‰å¯¹äºæ„å»ºç”¨äºåˆ†å­æ€§è´¨é¢„æµ‹ã€åˆ†å­å›¾ç”Ÿæˆæˆ–åŒ–å­¦ååº”æ¨ç†çš„'åŒ–å­¦å¤§æ¨¡å‹'å…·æœ‰é‡è¦çš„å€Ÿé‰´æ„ä¹‰ã€‚è¿™ç±»æ¨¡å‹çš„æ ¸å¿ƒæŒ‘æˆ˜ä¹‹ä¸€å°±æ˜¯å¤„ç†åˆ†å­å›¾è¡¨ç¤ºå’Œç›¸å…³çš„ç»„åˆä¼˜åŒ–é—®é¢˜ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å—ç‰©ç†å­¦å¯å‘çš„ç¥ç»æ¡†æ¶ï¼Œç”¨äºè§£å†³å¤§è§„æ¨¡å›¾ç€è‰²é—®é¢˜ï¼Œè¿™æ˜¯ä¸€ç§å…¸å‹çš„ç»„åˆä¼˜åŒ–é—®é¢˜ã€‚è¯¥æ¡†æ¶ç»“åˆäº†å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å’Œç»Ÿè®¡åŠ›å­¦åŸç†ï¼Œé€šè¿‡é›†æˆåŸºäºç§æ¤çš„ç›‘ç£ä¿¡å·ã€å¯¹ç§°æ€§ç ´ç¼ºæ­£åˆ™åŒ–å’Œè¿­ä»£å™ªå£°é€€ç«ç¥ç»åŠ¨åŠ›å­¦ï¼Œæ¥å¯¼èˆªèšé›†çš„è§£ç©ºé—´ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå½“è¿­ä»£æ¬¡æ•°ä¸å›¾è§„æ¨¡å‘ˆäºŒæ¬¡æ–¹å…³ç³»æ—¶ï¼Œå­¦ä¹ åˆ°çš„æ±‚è§£å™¨åœ¨éšæœºå›¾ä¸­èƒ½è¾¾åˆ°æ¥è¿‘ç†è®ºåŠ¨æ€ç›¸å˜çš„ç®—æ³•é˜ˆå€¼ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿä»å°çš„è®­ç»ƒå›¾æ³›åŒ–åˆ°è§„æ¨¡å¤§å‡ ä¸ªæ•°é‡çº§çš„å®ä¾‹ï¼Œè¯æ˜äº†ç¥ç»æ¶æ„å¯ä»¥å­¦ä¹ åˆ°åœ¨ç»„åˆä¼˜åŒ–çš„ç¡¬è¿é€šåŒºåŸŸä»ç„¶æœ‰æ•ˆçš„å¯æ‰©å±•ç®—æ³•ç­–ç•¥ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Combinatorial optimization problems near algorithmic phase transitions represent a fundamental challenge for both classical algorithms and machine learning approaches. Among them, graph coloring stands as a prototypical constraint satisfaction problem exhibiting sharp dynamical and satisfiability thresholds. Here we introduce a physics-inspired neural framework that learns to solve large-scale graph coloring instances by combining graph neural networks with statistical-mechanics principles. Our approach integrates a planting-based supervised signal, symmetry-breaking regularization, and iterative noise-annealed neural dynamics to navigate clustered solution landscapes. When the number of iterations scales quadratically with graph size, the learned solver reaches algorithmic thresholds close to the theoretical dynamical transition in random graphs and achieves near-optimal detection performance in the planted inference regime. The model generalizes from small training graphs to instances orders of magnitude larger, demonstrating that neural architectures can learn scalable algorithmic strategies that remain effective in hard connectivity regions. These results establish a general paradigm for learning neural solvers that operate near fundamental phase boundaries in combinatorial optimization and inference.

</details>

---

### 23. [CLIP-Free, Label Free, Unsupervised Concept Bottleneck Models](https://arxiv.org/abs/2503.10981)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2503.10981`](https://arxiv.org/abs/2503.10981)
- ğŸ‘¥ ä½œè€…: Fawaz Sammani, Jonas Fischer, Nikos Deligiannis
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2503.10981.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§æ–°å‹çš„ã€æ— éœ€å¤–éƒ¨æ ‡æ³¨æˆ–CLIPæ¨¡å‹çš„æ¦‚å¿µç“¶é¢ˆæ¨¡å‹ï¼ˆCBMï¼‰ã€‚CBMæ˜¯ä¸€ç§æ—¨åœ¨æé«˜AIæ¨¡å‹å¯è§£é‡Šæ€§çš„æ¶æ„ï¼Œé€šè¿‡å°†ç‰¹å¾æ˜ å°„åˆ°äººç±»å¯è§£é‡Šçš„æ¦‚å¿µã€‚è¿™é¡¹å·¥ä½œåœ¨æœºå™¨å­¦ä¹ å¯è§£é‡Šæ€§æ–¹é¢å±äºå‰æ²¿æ¢ç´¢ï¼Œå…¶æ–¹æ³•è®ºå¯¹äºæ„å»ºå¯è§£é‡Šçš„'åŒ–å­¦å¤§æ¨¡å‹'ï¼ˆä¾‹å¦‚ï¼Œå°†åˆ†å­ç‰¹å¾æ˜ å°„åˆ°åŒ–å­¦å®˜èƒ½å›¢æˆ–ååº”ç±»å‹ç­‰æ¦‚å¿µï¼‰å…·æœ‰ç›´æ¥çš„å¯å‘å’Œå‚è€ƒä»·å€¼ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€CLIPæ¨¡å‹ã€æ— éœ€å›¾åƒ-æ¦‚å¿µæ ‡æ³¨ã€ä¸”èƒ½ä»¥æ— ç›‘ç£æ–¹å¼æ¨å¯¼çº¿æ€§åˆ†ç±»å™¨çš„æ¦‚å¿µç“¶é¢ˆæ¨¡å‹ï¼ˆCBMï¼‰æ„å»ºæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†ä»»ä½•å†»ç»“çš„è§†è§‰åˆ†ç±»å™¨çš„åˆ†å¸ƒï¼ˆåœ¨ç¦»æ•£ç±»åˆ«ç´¢å¼•ä¸Šï¼‰ä¸å…¶å¯¹åº”çš„ã€ä»æ–‡æœ¬ç±»åˆ«åç§°è¡ç”Ÿçš„è§†è§‰-è¯­è¨€å¯¹åº”åˆ†å¸ƒå¯¹é½ï¼ŒåŒæ—¶ä¿æŒåˆ†ç±»å™¨çš„æ€§èƒ½ï¼Œä»è€Œå°†åˆ†ç±»å™¨è½¬æ¢ä¸ºCBMã€‚è¯¥æ–¹æ³•ä¸éœ€è¦çœŸå®å›¾åƒ-ç±»åˆ«æ ‡æ³¨ï¼Œå…·æœ‰å¾ˆé«˜çš„æ•°æ®æ•ˆç‡ï¼Œå¹¶ä¿ç•™äº†åˆ†ç±»å™¨çš„æ¨ç†è¿‡ç¨‹ã€‚åœ¨è¶…è¿‡40ä¸ªè§†è§‰åˆ†ç±»å™¨ä¸Šçš„åº”ç”¨å’Œæµ‹è¯•è¡¨æ˜ï¼Œæ‰€å¾—åˆ°çš„æ— ç›‘ç£ã€æ— æ ‡ç­¾ã€æ— CLIPçš„CBMï¼ˆU-F^2-CBMï¼‰è®¾ç«‹äº†æ–°çš„æ€§èƒ½æ ‡æ†ï¼Œç”šè‡³è¶…è¿‡äº†æœ‰ç›‘ç£çš„åŸºäºCLIPçš„CBMã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Concept Bottleneck Models (CBMs) map dense feature representations into human-interpretable concepts which are then combined linearly to make a prediction. However, modern CBMs rely on the CLIP model to obtain image-concept annotations, and it remains unclear how to design CBMs without the CLIP bottleneck. Methods that do not use CLIP instead require manual, labor intensive annotation to associate feature representations with concepts. Furthermore, all CBMs necessitate training a linear classifier to map the extracted concepts to class labels. In this work, we lift all three limitations simultaneously by proposing a method that converts any frozen visual classifier into a CBM without requiring image-concept labels (label-free), without relying on the CLIP model (CLIP-free), and by deriving the linear classifier in an unsupervised manner. Our method is formulated by aligning the original classifier's distribution (over discrete class indices) with its corresponding vision-language counterpart distribution derived from textual class names, while preserving the classifier's performance. The approach requires no ground-truth image-class annotations, and is highly data-efficient and preserves the classifier's reasoning process. Applied and tested on over 40 visual classifiers, our resulting unsupervised, label-free and CLIP-free CBM (U-F$^2$-CBM) sets a new state of the art, surpassing even supervised CLIP-based CBMs. We also show that our method can be used for zero-shot image captioning, outperforming existing methods based on CLIP, and achieving state-of-art.

</details>

---

### 24. [The Spacetime of Diffusion Models: An Information Geometry Perspective](https://arxiv.org/abs/2505.17517)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2505.17517`](https://arxiv.org/abs/2505.17517)
- ğŸ‘¥ ä½œè€…: RafaÅ‚ Karczewski, Markus Heinonen, Alison Pouplin ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2505.17517.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹å›´ç»•æ‰©æ•£æ¨¡å‹çš„å‡ ä½•ç»“æ„å’Œæ½œåœ¨è¡¨ç¤ºï¼Œè¿™ä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€ä¸»é¢˜ä¸­ç”¨äºåˆ†å­ç”Ÿæˆå’Œè®¾è®¡çš„ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚æ‰©æ•£æ¨¡å‹ï¼‰ç›´æ¥ç›¸å…³ã€‚è®ºæ–‡æå‡ºçš„å‡ ä½•è§†è§’å’Œç¼–è¾‘è·ç¦»ä¸ºç†è§£å’Œæ“ä½œè¿™ç±»å¤§æ¨¡å‹æä¾›äº†æ–°çš„ç†è®ºåŸºç¡€ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ä»ä¿¡æ¯å‡ ä½•çš„è§’åº¦æå‡ºäº†å¯¹æ‰©æ•£æ¨¡å‹æ½œåœ¨ç©ºé—´çš„æ–°é¢–å‡ ä½•è§†è§’ã€‚ä½œè€…æŒ‡å‡ºï¼Œä¼ ç»Ÿçš„åŸºäºç¡®å®šæ€§æ¦‚ç‡æµODEè§£ç å™¨çš„å›æ‹‰æ–¹æ³•å­˜åœ¨æ ¹æœ¬æ€§ç¼ºé™·ï¼Œå› ä¸ºå®ƒå¼ºåˆ¶è¦æ±‚æµ‹åœ°çº¿åœ¨æ•°æ®ç©ºé—´ä¸­è§£ç ä¸ºç›´çº¿æ®µï¼Œä»è€Œå¿½ç•¥äº†æ•°æ®çš„å†…åœ¨å‡ ä½•ç»“æ„ã€‚ä½œä¸ºè¡¥å……ï¼Œæ‰©æ•£æ¨¡å‹ä¹Ÿå…è®¸é€šè¿‡åå‘SDEè¿›è¡Œéšæœºè§£ç ï¼Œè¿™ä½¿å¾—å¯ä»¥ä½¿ç”¨Fisher-Raoåº¦é‡è¿›è¡Œä¿¡æ¯å‡ ä½•å¤„ç†ã€‚ç„¶è€Œï¼Œé€‰æ‹©x_Tä½œä¸ºæ½œåœ¨è¡¨ç¤ºä¼šç”±äºæ— è®°å¿†æ€§è€Œå¯¼è‡´è¯¥åº¦é‡åç¼©ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…å¼•å…¥äº†ä¸€ä¸ªæ½œåœ¨æ—¶ç©ºz=(x_t, t)ï¼Œè¯¥æ—¶ç©ºç´¢å¼•äº†æ‰€æœ‰å™ªå£°å°ºåº¦ä¸‹çš„å»å™ªåˆ†å¸ƒæ—p(x_0 | x_t)ï¼Œä»è€Œäº§ç”Ÿäº†ä¸€ä¸ªéå¹³å‡¡çš„å‡ ä½•ç»“æ„ã€‚ä»–ä»¬è¯æ˜äº†è¿™äº›åˆ†å¸ƒå½¢æˆäº†ä¸€ä¸ªæŒ‡æ•°æ—ï¼Œå¹¶æ¨å¯¼äº†æ›²çº¿é•¿åº¦çš„æ— æ¨¡æ‹Ÿä¼°è®¡å™¨ï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„æµ‹åœ°çº¿è®¡ç®—ã€‚ç”±æ­¤äº§ç”Ÿçš„ç»“æ„å¼•å…¥äº†ä¸€ç§åŸåˆ™æ€§çš„æ‰©æ•£ç¼–è¾‘è·ç¦»ï¼Œå…¶ä¸­æµ‹åœ°çº¿è¿½è¸ªæ•°æ®ä¹‹é—´å™ªå£°å’Œå»å™ªç¼–è¾‘çš„æœ€å°åºåˆ—ã€‚ä½œè€…è¿˜å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨åˆ†å­ç³»ç»Ÿï¼ˆåŒ…æ‹¬çº¦æŸå˜ä½“ï¼Œå¦‚ä½æ–¹å·®è·ƒè¿å’ŒåŒºåŸŸè§„é¿ï¼‰ä¸­è¿‡æ¸¡è·¯å¾„é‡‡æ ·çš„å¥½å¤„ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£å’Œæ“ä½œæ‰©æ•£æ¨¡å‹çš„æ½œåœ¨å‡ ä½•ç»“æ„æä¾›äº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„ä¸»é¢˜ç›¸å…³ï¼Œå› ä¸ºå®ƒä¸ºç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚ç”¨äºåˆ†å­è®¾è®¡çš„æ‰©æ•£æ¨¡å‹ï¼‰æä¾›äº†ç†è®ºåŸºç¡€å’Œå‡ ä½•è§£é‡Šã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

We present a novel geometric perspective on the latent space of diffusion models. We first show that the standard pullback approach, utilizing the deterministic probability flow ODE decoder, is fundamentally flawed. It provably forces geodesics to decode as straight segments in data space, effectively ignoring any intrinsic data geometry beyond the ambient Euclidean space. Complementing this view, diffusion also admits a stochastic decoder via the reverse SDE, which enables an information geometric treatment with the Fisher-Rao metric. However, a choice of $x_T$ as the latent representation collapses this metric due to memorylessness. We address this by introducing a latent spacetime $z=(x_t,t)$ that indexes the family of denoising distributions $p(x_0 | x_t)$ across all noise scales, yielding a nontrivial geometric structure. We prove these distributions form an exponential family and derive simulation-free estimators for curve lengths, enabling efficient geodesic computation. The resulting structure induces a principled Diffusion Edit Distance, where geodesics trace minimal sequences of noise and denoise edits between data. We also demonstrate benefits for transition path sampling in molecular systems, including constrained variants such as low-variance transitions and region avoidance. Code is available at: this https URL .

</details>

---

### 25. [Random Matrix Theory-guided sparse PCA for single-cell RNA-seq data](https://arxiv.org/abs/2509.15429)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2509.15429`](https://arxiv.org/abs/2509.15429)
- ğŸ‘¥ ä½œè€…: Victor ChardÃ¨s
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2509.15429.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§ç”¨äºåˆ†æé«˜é€šé‡ç”Ÿç‰©åˆ†å­æ•°æ®ï¼ˆå•ç»†èƒRNA-seqï¼‰çš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚è™½ç„¶æ ‡é¢˜æœªç›´æ¥æåŠâ€œåŒ–å­¦ä¿¡æ¯å­¦â€ï¼Œä½†å•ç»†èƒRNA-seqæ•°æ®åˆ†ææ˜¯åŒ–å­¦ç”Ÿç‰©å­¦å’Œè®¡ç®—ç”Ÿç‰©å­¦äº¤å‰é¢†åŸŸçš„æ ¸å¿ƒä»»åŠ¡ï¼Œå±äºå¹¿ä¹‰çš„åŒ–å­¦ä¿¡æ¯å­¦èŒƒç•´ã€‚è®ºæ–‡æå‡ºçš„RMTå¼•å¯¼çš„ç¨€ç–PCAæ–¹æ³•æ˜¯ä¸€ç§æ–°é¢–çš„æ•°æ®åˆ†æå’Œç‰¹å¾æå–æŠ€æœ¯ï¼Œå¯ç”¨äºä»å¤æ‚çš„åŒ–å­¦/ç”Ÿç‰©æµ‹é‡æ•°æ®ä¸­æ¨æ–­æœ‰æ„ä¹‰çš„æ¨¡å¼ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºéšæœºçŸ©é˜µç†è®ºï¼ˆRMTï¼‰çš„ç¨€ç–ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰æ–¹æ³•ï¼Œç”¨äºå¤„ç†å•ç»†èƒRNAæµ‹åºæ•°æ®ã€‚å•ç»†èƒRNA-seqæ•°æ®å™ªå£°å¤§ï¼Œå˜å¼‚æ€§æ¥æºäºç”Ÿç‰©å­¦å·®å¼‚å’ŒæŠ€æœ¯å› ç´ ï¼Œä½¿å¾—è®¡ç®—æµç¨‹éš¾ä»¥é€‚åº”å¼‚æ„æ•°æ®é›†æˆ–ä¸æ–­å‘å±•çš„æŠ€æœ¯ã€‚å°½ç®¡PCAåœ¨é«˜ç»´æ•°æ®ä¸­å­˜åœ¨å·²çŸ¥åå·®ï¼Œä½†ç”±äºå…¶å¯è§£é‡Šæ€§å’Œé²æ£’æ€§ï¼Œå¤§å¤šæ•°ç ”ç©¶ä»ä¾èµ–å…¶è¿›è¡Œé™ç»´ã€‚æœ¬æ–‡æ”¹è¿›äº†PCAï¼Œæå‡ºäº†ä¸€ç§RMTå¼•å¯¼çš„æ–¹æ³•ï¼Œåˆ©ç”¨ç°æœ‰çš„ç¨€ç–PCAç®—æ³•æ¥æ¨æ–­ç¨€ç–ä¸»æˆåˆ†ã€‚ä½œè€…é¦–å…ˆå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åŒç™½åŒ–ç®—æ³•ï¼Œè¯¥ç®—æ³•è‡ªæ´½åœ°ä¼°è®¡äº†æ¯ä¸ªåŸºå› åœ¨å•ä¸ªç»†èƒä¸­å—è½¬å½•ç»„å™ªå£°å½±å“çš„å¤§å°ï¼Œè€Œæ— éœ€å‡è®¾ç‰¹å®šçš„å™ªå£°åˆ†å¸ƒã€‚è¿™ä½¿å¾—èƒ½å¤Ÿä½¿ç”¨åŸºäºRMTçš„æ ‡å‡†è‡ªåŠ¨é€‰æ‹©ç¨€ç–åº¦æ°´å¹³ï¼Œä»è€Œä½¿ç¨€ç–PCAå‡ ä¹æ— éœ€å‚æ•°è°ƒæ•´ã€‚è¿™ç§åŸºäºæ•°å­¦çš„æ–¹æ³•ä¿ç•™äº†PCAçš„å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶å®ç°äº†å¯¹ç¨€ç–ä¸»æˆåˆ†çš„ç¨³å¥ã€æ— éœ€æ‰‹åŠ¨å¹²é¢„çš„æ¨æ–­ã€‚åœ¨ä¸ƒç§å•ç»†èƒRNA-seqæŠ€æœ¯å’Œå››ç§ç¨€ç–PCAç®—æ³•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç³»ç»Ÿåœ°æ”¹å–„äº†ä¸»å­ç©ºé—´çš„é‡å»ºï¼Œå¹¶åœ¨ç»†èƒç±»å‹åˆ†ç±»ä»»åŠ¡ä¸­æŒç»­ä¼˜äºåŸºäºPCAã€è‡ªç¼–ç å™¨å’Œæ‰©æ•£çš„æ–¹æ³•ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Single-cell RNA-seq provides detailed molecular snapshots of individual cells but is notoriously noisy. Variability stems from biological differences and technical factors, such as amplification bias and limited RNA capture efficiency, making it challenging to adapt computational pipelines to heterogeneous datasets or evolving technologies. As a result, most studies still rely on principal component analysis (PCA) for dimensionality reduction, valued for its interpretability and robustness, in spite of its known bias in high dimensions. Here, we improve upon PCA with a Random Matrix Theory (RMT)-based approach that guides the inference of sparse principal components using existing sparse PCA algorithms. We first introduce a novel biwhitening algorithm which self-consistently estimates the magnitude of transcriptomic noise affecting each gene in individual cells, without assuming a specific noise distribution. This enables the use of an RMT-based criterion to automatically select the sparsity level, rendering sparse PCA nearly parameter-free. Our mathematically grounded approach retains the interpretability of PCA while enabling robust, hands-off inference of sparse principal components. Across seven single-cell RNA-seq technologies and four sparse PCA algorithms, we show that this method systematically improves the reconstruction of the principal subspace and consistently outperforms PCA-, autoencoder-, and diffusion-based methods in cell-type classification tasks.

</details>

---

### 26. [Object-Centric Representation Learning for Enhanced 3D Semantic Scene Graph Prediction](https://arxiv.org/abs/2510.04714)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2510.04714`](https://arxiv.org/abs/2510.04714)
- ğŸ‘¥ ä½œè€…: KunHo Heo, GiHyun Kim, SuYeon Kim ç­‰4äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2510.04714.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ç”¨äº3Dåœºæ™¯ç†è§£çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å¯¹è±¡æ£€æµ‹å’Œå…³ç³»é¢„æµ‹ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯æœºå™¨äººè§†è§‰ï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•è®ºâ€”â€”è®¾è®¡åˆ¤åˆ«æ€§ç‰¹å¾ç¼–ç å™¨ã€ä½¿ç”¨å¯¹æ¯”å­¦ä¹ è¿›è¡Œé¢„è®­ç»ƒã€æ•´åˆå¤šæ¨¡æ€ï¼ˆå‡ ä½•å’Œè¯­ä¹‰ï¼‰ç‰¹å¾â€”â€”æ˜¯æœºå™¨å­¦ä¹ åœ¨ç»“æ„åŒ–æ•°æ®æ¨ç†ä¸­çš„é«˜çº§åº”ç”¨ã€‚è¿™äº›æ–¹æ³•ä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€å’Œâ€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­æ‰€éœ€çš„ã€ä»å¤æ‚æ•°æ®ï¼ˆå¦‚åˆ†å­å›¾æˆ–è´¨è°±å›¾ï¼‰ä¸­å­¦ä¹ è¡¨ç¤ºå’Œå…³ç³»æœ‰æ¦‚å¿µä¸Šçš„ç›¸ä¼¼æ€§ã€‚è®ºæ–‡æå‡ºçš„æŠ€æœ¯ï¼ˆå¦‚å¯¹æ¯”é¢„è®­ç»ƒã€ç‰¹å¾è§£è€¦ï¼‰å¯ä»¥å¯å‘åŒ–å­¦ä¿¡æ¯å­¦ä¸­ç±»ä¼¼é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶äº†3Dè¯­ä¹‰åœºæ™¯å›¾é¢„æµ‹ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨æ£€æµ‹3Dåœºæ™¯ä¸­çš„å¯¹è±¡åŠå…¶è¯­ä¹‰å…³ç³»ï¼Œæ˜¯æœºå™¨äººå’ŒAR/VRåº”ç”¨çš„å…³é”®æŠ€æœ¯ã€‚å…ˆå‰çš„ç ”ç©¶è™½ç„¶è§£å†³äº†æ•°æ®é›†é™åˆ¶å¹¶æ¢ç´¢äº†åŒ…æ‹¬å¼€æ”¾è¯æ±‡è®¾ç½®åœ¨å†…çš„å„ç§æ–¹æ³•ï¼Œä½†ç»å¸¸æœªèƒ½ä¼˜åŒ–å¯¹è±¡å’Œå…³ç³»ç‰¹å¾çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œè¡¨ç°å‡ºå¯¹å›¾ç¥ç»ç½‘ç»œçš„è¿‡åº¦ä¾èµ–ï¼Œå°½ç®¡å…¶åˆ¤åˆ«èƒ½åŠ›ä¸è¶³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œä½œè€…é€šè¿‡å¹¿æ³›åˆ†æè¯æ˜ï¼Œå¯¹è±¡ç‰¹å¾çš„è´¨é‡åœ¨å†³å®šæ•´ä½“åœºæ™¯å›¾å‡†ç¡®æ€§æ–¹é¢èµ·ç€å…³é”®ä½œç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä»–ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜åº¦åˆ¤åˆ«æ€§çš„å¯¹è±¡ç‰¹å¾ç¼–ç å™¨ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§å¯¹æ¯”é¢„è®­ç»ƒç­–ç•¥ï¼Œå°†å¯¹è±¡è¡¨ç¤ºå­¦ä¹ ä¸åœºæ™¯å›¾é¢„æµ‹è§£è€¦ã€‚è¿™ç§è®¾è®¡ä¸ä»…æé«˜äº†å¯¹è±¡åˆ†ç±»çš„å‡†ç¡®æ€§ï¼Œè¿˜ç›´æ¥æ”¹å–„äº†å…³ç³»é¢„æµ‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå½“å°†é¢„è®­ç»ƒçš„ç¼–ç å™¨æ’å…¥ç°æœ‰æ¡†æ¶æ—¶ï¼Œåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šéƒ½è§‚å¯Ÿåˆ°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œè™½ç„¶ç°æœ‰æ–¹æ³•å°šæœªå……åˆ†åˆ©ç”¨å…³ç³»ä¿¡æ¯çš„æ•´åˆï¼Œä½†ä½œè€…æœ‰æ•ˆåœ°ç»“åˆäº†å‡ ä½•å’Œè¯­ä¹‰ç‰¹å¾ï¼Œå®ç°äº†æ›´ä¼˜çš„å…³ç³»é¢„æµ‹ã€‚åœ¨3DSSGæ•°æ®é›†ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºå…ˆå‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

3D Semantic Scene Graph Prediction aims to detect objects and their semantic relationships in 3D scenes, and has emerged as a crucial technology for robotics and AR/VR applications. While previous research has addressed dataset limitations and explored various approaches including Open-Vocabulary settings, they frequently fail to optimize the representational capacity of object and relationship features, showing excessive reliance on Graph Neural Networks despite insufficient discriminative capability. In this work, we demonstrate through extensive analysis that the quality of object features plays a critical role in determining overall scene graph accuracy. To address this challenge, we design a highly discriminative object feature encoder and employ a contrastive pretraining strategy that decouples object representation learning from the scene graph prediction. This design not only enhances object classification accuracy but also yields direct improvements in relationship prediction. Notably, when plugging in our pretrained encoder into existing frameworks, we observe substantial performance improvements across all evaluation metrics. Additionally, whereas existing approaches have not fully exploited the integration of relationship information, we effectively combine both geometric and semantic features to achieve superior relationship prediction. Comprehensive experiments on the 3DSSG dataset demonstrate that our approach significantly outperforms previous state-of-the-art methods. Our code is publicly available at this https URL .

</details>

---

### 27. [Learning Hamiltonian Flow Maps: Mean Flow Consistency for Large-Timestep Molecular Dynamics](https://arxiv.org/abs/2601.22123)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2601.22123`](https://arxiv.org/abs/2601.22123)
- ğŸ‘¥ ä½œè€…: Winfried Ripken, Michael Plainer, Gregor Lied ç­‰8äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2601.22123.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¡†æ¶æ¥å­¦ä¹ å“ˆå¯†é¡¿ç³»ç»Ÿçš„æ¼”åŒ–æ˜ å°„ï¼Œè¿™ç›´æ¥å±äºåˆ©ç”¨å¤§æ¨¡å‹/æœºå™¨å­¦ä¹ æ–¹æ³•ç†è§£å’Œæ¨¡æ‹Ÿå¤æ‚åŒ–å­¦/ç‰©ç†ç³»ç»Ÿï¼ˆå¦‚åˆ†å­åŠ¨åŠ›å­¦ï¼‰çš„èŒƒç•´ï¼Œä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€ä¸»é¢˜ç›´æ¥ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§å­¦ä¹ å“ˆå¯†é¡¿æµæ˜ å°„çš„æ¡†æ¶ï¼Œç”¨äºæ¨¡æ‹Ÿå“ˆå¯†é¡¿ç³»ç»Ÿçš„é•¿æ—¶é—´æ¼”åŒ–ã€‚è¯¥æ–¹æ³•é€šè¿‡é¢„æµ‹é€‰å®šæ—¶é—´è·¨åº¦å†…çš„å¹³å‡ç›¸ç©ºé—´æ¼”åŒ–ï¼Œå®ç°äº†è¿œè¶…ç»å…¸ç§¯åˆ†å™¨ç¨³å®šæ€§é™åˆ¶çš„å¤§æ—¶é—´æ­¥é•¿æ›´æ–°ã€‚æ ¸å¿ƒæ˜¯æ–½åŠ äº†ä¸€ä¸ªå…³äºæ—¶é—´å¹³å‡å“ˆå¯†é¡¿åŠ¨åŠ›å­¦çš„â€œå¹³å‡æµä¸€è‡´æ€§â€æ¡ä»¶ã€‚ä¸å…ˆå‰æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•å…è®¸åœ¨æ— éœ€è®¿é—®æœªæ¥çŠ¶æ€çš„æƒ…å†µä¸‹ï¼Œåœ¨ç‹¬ç«‹çš„ç›¸ç©ºé—´æ ·æœ¬ä¸Šè¿›è¡Œè®­ç»ƒï¼Œé¿å…äº†æ˜‚è´µçš„è½¨è¿¹ç”Ÿæˆã€‚è¯¥æ–¹æ³•åœ¨åŒ…æ‹¬ä½¿ç”¨æœºå™¨å­¦ä¹ åŠ›åœºï¼ˆMLFFï¼‰çš„åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿåœ¨å†…çš„å¤šç§å“ˆå¯†é¡¿ç³»ç»Ÿä¸­å¾—åˆ°éªŒè¯ã€‚è¯¥æ¡†æ¶æ—¨åœ¨å…‹æœå°æ—¶é—´æ­¥é•¿çš„é™åˆ¶ï¼Œé€šè¿‡æœºå™¨å­¦ä¹ æ¨¡å‹ç›´æ¥å­¦ä¹ ä»ç›¸ç©ºé—´çŠ¶æ€åˆ°æœªæ¥çŠ¶æ€æ¼”åŒ–çš„æ˜ å°„ï¼Œè¿™ä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€ä¸­åˆ©ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹å­¦ä¹ å¤æ‚ç‰©ç†/åŒ–å­¦ç³»ç»Ÿæ¼”åŒ–è§„å¾‹çš„æ ¸å¿ƒä¸»é¢˜é«˜åº¦ç›¸å…³ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Simulating the long-time evolution of Hamiltonian systems is limited by the small timesteps required for stable numerical integration. To overcome this constraint, we introduce a framework to learn Hamiltonian Flow Maps by predicting the mean phase-space evolution over a chosen time span, enabling stable large-timestep updates far beyond the stability limits of classical integrators. To this end, we impose a Mean Flow consistency condition for time-averaged Hamiltonian dynamics. Unlike prior approaches, this allows training on independent phase-space samples without access to future states, avoiding expensive trajectory generation. Validated across diverse Hamiltonian systems, our method in particular improves upon molecular dynamics simulations using machine-learned force fields (MLFF). Our models maintain comparable training and inference cost, but support significantly larger integration timesteps while trained directly on widely-available trajectory-free MLFF datasets.

</details>

---

### 28. [A Minimum Variance Path Principle for Accurate and Stable Score-Based Density Ratio Estimation](https://arxiv.org/abs/2602.00834)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.00834`](https://arxiv.org/abs/2602.00834)
- ğŸ‘¥ ä½œè€…: Wei Chen, Jiacheng Li, Shigui Li ç­‰7äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.00834.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯æ”¹è¿›åŸºäºåˆ†æ•°çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå¯†åº¦æ¯”ä¼°è®¡ç­‰ä»»åŠ¡ã€‚è™½ç„¶æœªæ˜ç¡®æåŠåŒ–å­¦æˆ–è´¨è°±ï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•è®ºâ€”â€”å¼€å‘æ›´ä¼˜çš„ç”Ÿæˆæ¨¡å‹æˆ–æ¦‚ç‡æ¨¡å‹è®­ç»ƒæ¡†æ¶â€”â€”æ˜¯æ„å»ºâ€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆå¦‚ç”¨äºåˆ†å­ç”Ÿæˆã€æ€§è´¨é¢„æµ‹çš„ç”Ÿæˆæ¨¡å‹ï¼‰å’Œè¿›è¡Œâ€œè´¨è°±ç»“æ„æ¨ç†â€ï¼ˆå¦‚ä»è´¨è°±æ•°æ®æ¨æ–­åˆ†å­ç»“æ„çš„æ¦‚ç‡å»ºæ¨¡ï¼‰æ‰€ä¾èµ–çš„åŸºç¡€æŠ€æœ¯ä¹‹ä¸€ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶äº†åŸºäºåˆ†æ•°çš„å¯†åº¦æ¯”ä¼°è®¡æ–¹æ³•ã€‚ä½œè€…å‘ç°ï¼Œå°½ç®¡åŸºäºåˆ†æ•°çš„æ–¹æ³•åœ¨ç†è®ºä¸Šæ˜¯è·¯å¾„æ— å…³çš„ï¼Œä½†åœ¨å®é™…è®­ç»ƒä¸­å´è¡¨ç°å‡ºè·¯å¾„ä¾èµ–æ€§ã€‚ä»–ä»¬é€šè¿‡è¯æ˜å®é™…è®­ç»ƒç›®æ ‡ä¸ç†æƒ³ç›®æ ‡ä¹‹é—´ç›¸å·®ä¸€ä¸ªå…³é”®çš„è¢«å¿½è§†é¡¹â€”â€”åˆ†æ•°å‡½æ•°çš„è·¯å¾„æ–¹å·®â€”â€”æ¥è§£å†³è¿™ä¸€æ‚–è®ºã€‚ä¸ºæ­¤ï¼Œä»–ä»¬æå‡ºäº†â€œæœ€å°æ–¹å·®è·¯å¾„â€ï¼ˆMVPï¼‰åŸåˆ™æ¥æœ€å°åŒ–è¯¥è·¯å¾„æ–¹å·®ã€‚ä¸»è¦è´¡çŒ®æ˜¯æ¨å¯¼å‡ºäº†æ–¹å·®çš„é—­å¼è¡¨è¾¾å¼ï¼Œä½¿ä¼˜åŒ–å˜å¾—å¯è¡Œã€‚é€šè¿‡ä½¿ç”¨çµæ´»çš„Kumaraswamyæ··åˆæ¨¡å‹å¯¹è·¯å¾„è¿›è¡Œå‚æ•°åŒ–ï¼Œè¯¥æ–¹æ³•å¯ä»¥å­¦ä¹ æ•°æ®è‡ªé€‚åº”çš„ä½æ–¹å·®è·¯å¾„ï¼Œè€Œæ— éœ€å¯å‘å¼æ‰‹åŠ¨é€‰æ‹©ã€‚è¿™ç§å¯¹å®Œæ•´ç›®æ ‡çš„ä¼˜åŒ–äº§ç”Ÿäº†æ›´å‡†ç¡®å’Œç¨³å®šçš„ä¼°è®¡å™¨ã€‚è¿™é¡¹å·¥ä½œä¸ºä¼˜åŒ–åŸºäºåˆ†æ•°çš„æ’å€¼æä¾›äº†ä¸€ä¸ªé€šç”¨æ¡†æ¶ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Score-based methods are powerful across machine learning, but they face a paradox: theoretically path-independent, yet practically path-dependent. We resolve this by proving that practical training objectives differ from the ideal, ground-truth objective by a crucial, overlooked term: the path variance of the score function. We propose the MVP (**M**imum **V**ariance **P**ath) Principle to minimize this path variance. Our key contribution is deriving a closed-form expression for the variance, making optimization tractable. By parameterizing the path with a flexible Kumaraswamy Mixture Model, our method learns data-adaptive, low-variance paths without heuristic manual selection. This principled optimization of the complete objective yields more accurate and stable estimators, establishing new state-of-the-art results on challenging benchmarks and providing a general framework for optimizing score-based interpolation.

</details>

---

### 29. [Phase Transitions for Feature Learning in Neural Networks](https://arxiv.org/abs/2602.01434)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.01434`](https://arxiv.org/abs/2602.01434)
- ğŸ‘¥ ä½œè€…: Andrea Montanari, Zihao Wang
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.01434.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯ç¥ç»ç½‘ç»œï¼ˆä½œä¸ºå¤§æ¨¡å‹çš„åŸºç¡€ç»„ä»¶ï¼‰åœ¨é«˜ç»´æ•°æ®ä¸‹çš„ç‰¹å¾å­¦ä¹ æœºåˆ¶å’Œç›¸å˜è¡Œä¸ºã€‚ç†è§£ç¥ç»ç½‘ç»œå¦‚ä½•ä»æ•°æ®ä¸­å­¦ä¹ æœ‰æ•ˆçš„ä½ç»´è¡¨ç¤ºï¼Œå¯¹äºæ„å»ºå’Œç†è§£â€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆä¾‹å¦‚ï¼Œä»åˆ†å­ç»“æ„æ•°æ®å­¦ä¹ åˆ†å­è¡¨ç¤ºï¼‰ä»¥åŠæ”¹è¿›â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­çš„ç‰¹å¾æå–è‡³å…³é‡è¦ã€‚è¿™å±äºæœºå™¨å­¦ä¹ åŸºç¡€ç†è®ºä¸åº”ç”¨ä¸»é¢˜çš„äº¤å‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶äº†ç¥ç»ç½‘ç»œåœ¨å­¦ä¹ å¤šç´¢å¼•æ¨¡å‹æ—¶çš„ç‰¹å¾å­¦ä¹ åŠ¨æ€ã€‚åœ¨æ­¤è®¾ç½®ä¸‹ï¼Œå“åº”å˜é‡ä»…é€šè¿‡ä¸€ä¸ªkç»´æŠ•å½±ä¾èµ–äºé«˜ç»´åå˜é‡ã€‚ç‰¹å¾å­¦ä¹ å³å­¦ä¹ è¿™ä¸ªæ½œåœ¨ç©ºé—´ã€‚ä½œè€…åœ¨æ¯”ä¾‹æ¸è¿‘ï¼ˆn, dâ†’âˆï¼Œ n/dâ†’Î´ï¼‰çš„æ¡†æ¶ä¸‹ï¼Œç ”ç©¶äº†ä¸¤å±‚ç¥ç»ç½‘ç»œçš„æ¢¯åº¦ä¸‹é™åŠ¨åŠ›å­¦ï¼Œå…¶ä¸­æ½œåœ¨ç©ºé—´ç»´åº¦kå’Œéšè—ç¥ç»å…ƒæ•°é‡må›ºå®šã€‚å…ˆå‰å·¥ä½œè¡¨æ˜ï¼Œå½“Î´è¶…è¿‡ä¸€ä¸ªä¾èµ–äºæ•°æ®åˆ†å¸ƒçš„é˜ˆå€¼Î´_algæ—¶ï¼Œé€šè¿‡å¤šé¡¹å¼æ—¶é—´ç®—æ³•è¿›è¡Œç‰¹å¾å­¦ä¹ æ˜¯å¯èƒ½çš„ã€‚æœ¬æ–‡æ¨å¯¼å‡ºäº†ä¸¤å±‚ç½‘ç»œçš„ç±»ä¼¼é˜ˆå€¼Î´_NNã€‚è¯¥é˜ˆå€¼ç”±ä»¥ä¸‹åœºæ™¯å†³å®šï¼šè®­ç»ƒé¦–å…ˆè®¿é—®ç»éªŒé£é™©æ¢¯åº¦è¾ƒå¤§çš„ç‚¹ï¼Œå­¦ä¹ è¿™äº›æ¢¯åº¦æ‰€è·¨è¶Šçš„æ–¹å‘ï¼›ç„¶åæ¢¯åº¦å˜å°ï¼ŒåŠ¨åŠ›å­¦ç”±HessiançŸ©é˜µçš„è´Ÿæ–¹å‘ä¸»å¯¼ã€‚é˜ˆå€¼Î´_NNå¯¹åº”äºç¬¬äºŒé˜¶æ®µHessianè°±çš„ç›¸å˜ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

According to a popular viewpoint, neural networks learn from data by first identifying low-dimensional representations, and subsequently fitting the best model in this space. Recent works provide a formalization of this phenomenon when learning multi-index models. In this setting, we are given $n$ i.i.d. pairs $({\boldsymbol x}_i,y_i)$, where the covariate vectors ${\boldsymbol x}_i\in\mathbb{R}^d$ are isotropic, and responses $y_i$ only depend on ${\boldsymbol x}_i$ through a $k$-dimensional projection ${\boldsymbol \Theta}_*^{\sf T}{\boldsymbol x}_i$. Feature learning amounts to learning the latent space spanned by ${\boldsymbol \Theta}_*$. In this context, we study the gradient descent dynamics of two-layer neural networks under the proportional asymptotics $n,d\to\infty$, $n/d\to\delta$, while the dimension of the latent space $k$ and the number of hidden neurons $m$ are kept fixed. Earlier work establishes that feature learning via polynomial-time algorithms is possible if $\delta> \delta_{\text{alg}}$, for $\delta_{\text{alg}}$ a threshold depending on the data distribution, and is impossible (within a certain class of algorithms) below $\delta_{\text{alg}}$. Here we derive an analogous threshold $\delta_{\text{NN}}$ for two-layer networks. Our characterization of $\delta_{\text{NN}}$ opens the way to study the dependence of learning dynamics on the network architecture and training algorithm. The threshold $\delta_{\text{NN}}$ is determined by the following scenario. Training first visits points for which the gradient of the empirical risk is large and learns the directions spanned by these gradients. Then the gradient becomes smaller and the dynamics becomes dominated by negative directions of the Hessian. The threshold $\delta_{\text{NN}}$ corresponds to a phase transition in the spectrum of the Hessian in this second phase.

</details>

---

### 30. [Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives](https://arxiv.org/abs/2602.01749)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.01749`](https://arxiv.org/abs/2602.01749)
- ğŸ‘¥ ä½œè€…: Lin Chen, Samuel Drapeau, Fanghao Shao ç­‰8äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.01749.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯æ”¹è¿›ç”Ÿæˆæµç½‘ç»œï¼ˆGFlowNetï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºç»“æ„åŒ–å¯¹è±¡ï¼ˆå¦‚åˆ†å­ã€å›¾ï¼‰ç”Ÿæˆçš„ç”Ÿæˆæ¨¡å‹ã€‚GFlowNetæ˜¯æ„å»ºâ€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆç”¨äºåˆ†å­ç”Ÿæˆã€ä¼˜åŒ–ï¼‰çš„é‡è¦å·¥å…·ä¹‹ä¸€ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ—¨åœ¨æ›´å¥½åœ°æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨ï¼Œè¿™å¯¹äºåœ¨åŒ–å­¦ç©ºé—´ä¸­è¿›è¡Œé«˜æ•ˆæœç´¢å’Œå‘ç°æ–°åˆ†å­ç»“æ„å…·æœ‰ç›´æ¥æ„ä¹‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶äº†ç”Ÿæˆæµç½‘ç»œï¼ˆGFlowNetï¼‰ä¸­çš„æ¢ç´¢-åˆ©ç”¨æƒè¡¡é—®é¢˜ã€‚ä½œè€…é€šè¿‡è¿›ä¸€æ­¥æ¢ç´¢GFlowNetä¸é©¬å°”å¯å¤«é“¾ä¹‹é—´çš„è”ç³»ï¼Œå»ºç«‹äº†GFlowNetç›®æ ‡ä¸é©¬å°”å¯å¤«é“¾å¯é€†æ€§ä¹‹é—´çš„ç­‰ä»·å…³ç³»ï¼Œä»è€Œæ­ç¤ºäº†è®­ç»ƒä¸­éšå«çº¦æŸçš„æ ¹æºï¼Œå¹¶æä¾›äº†ä¸€ä¸ªå°†é©¬å°”å¯å¤«é“¾æ€§è´¨é€‚é…åˆ°GFlowNetçš„æ¡†æ¶ã€‚åŸºäºè¿™äº›ç†è®ºå‘ç°ï¼Œä½œè€…æå‡ºäº†Î±-GFNï¼Œé€šè¿‡ä¸€ä¸ªå¯è°ƒå‚æ•°Î±æ¥æ³›åŒ–å‰å‘ä¸åå‘ç­–ç•¥çš„æ··åˆã€‚è¿™ç§æ³›åŒ–ä½¿å¾—èƒ½å¤Ÿç›´æ¥æ§åˆ¶æ¢ç´¢-åˆ©ç”¨åŠ¨æ€ä»¥å¢å¼ºæ¨¡å¼å‘ç°èƒ½åŠ›ï¼ŒåŒæ—¶ç¡®ä¿æ”¶æ•›åˆ°å”¯ä¸€çš„æµã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒÎ±-GFNç›®æ ‡ consistently ä¼˜äºå…ˆå‰çš„GFlowNetç›®æ ‡ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $\alpha$-GFNs, which generalize the mixing via a tunable parameter $\alpha$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $\alpha$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \times$ increase in the number of discovered modes.

</details>

---

### 31. [VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations](https://arxiv.org/abs/2602.02334)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.02334`](https://arxiv.org/abs/2602.02334)
- ğŸ‘¥ ä½œè€…: Fatemeh Zargarbashi, Dhruv Agrawal, Jakob Buhmann ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.02334.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§åŸºäºï¼ˆæ®‹å·®ï¼‰å‘é‡é‡åŒ–è‡ªç¼–ç å™¨çš„ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºè§£è€¦æ•°æ®ä¸­çš„é£æ ¼ä¸å†…å®¹ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯äººä½“è¿åŠ¨ï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•è®ºâ€”â€”ä½¿ç”¨é‡åŒ–è‡ªç¼–ç å™¨å­¦ä¹ è§£è€¦çš„ã€å±‚æ¬¡åŒ–çš„è¡¨ç¤ºâ€”â€”ä¸â€œåŒ–å­¦å¤§æ¨¡å‹â€ä¸­ç”¨äºåˆ†å­è¡¨ç¤ºå­¦ä¹ ï¼ˆä¾‹å¦‚ï¼Œè§£è€¦åˆ†å­çš„åŠŸèƒ½å›¢å’Œéª¨æ¶ï¼‰æˆ–â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­è§£è€¦è´¨è°±ä¿¡å·çš„ä¸åŒæ¥æºï¼ˆå¦‚ç¢ç‰‡åŒ–æ¨¡å¼ä¸åˆ†å­å­ç»“æ„ï¼‰çš„æŠ€æœ¯è·¯çº¿é«˜åº¦ç›¸ä¼¼ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œç”¨äºæœ‰æ•ˆè§£è€¦äººä½“è¿åŠ¨æ•°æ®ä¸­çš„é£æ ¼å’Œå†…å®¹ï¼Œä»¥ä¿ƒè¿›é£æ ¼è¿ç§»ã€‚è¯¥æ–¹æ³•åŸºäºå†…å®¹å¯¹åº”ç²—ç•¥è¿åŠ¨å±æ€§è€Œé£æ ¼æ•æ‰æ›´ç²¾ç»†ã€å¯Œæœ‰è¡¨ç°åŠ›çš„ç»†èŠ‚è¿™ä¸€æ´è§ã€‚ä¸ºäº†å»ºæ¨¡è¿™ç§å±‚æ¬¡ç»“æ„ï¼Œä½œè€…é‡‡ç”¨æ®‹å·®å‘é‡é‡åŒ–å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆRVQ-VAEsï¼‰æ¥å­¦ä¹ ä»ç²—åˆ°ç»†çš„è¿åŠ¨è¡¨ç¤ºã€‚é€šè¿‡å°†ç æœ¬å­¦ä¹ ä¸å¯¹æ¯”å­¦ä¹ ä»¥åŠä¸€ç§æ–°é¢–çš„ä¿¡æ¯æ³„æ¼æŸå¤±ç›¸ç»“åˆï¼Œä»¥åœ¨ä¸åŒç æœ¬ä¸­ç»„ç»‡å†…å®¹å’Œé£æ ¼ï¼Œä»è€Œè¿›ä¸€æ­¥å¢å¼ºè§£è€¦ã€‚ä½œè€…åˆ©ç”¨è¿™ç§è§£è€¦è¡¨ç¤ºï¼Œé€šè¿‡ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ¨ç†æ—¶æŠ€æœ¯â€œé‡åŒ–ç äº¤æ¢â€ï¼Œå®ç°äº†æ— éœ€å¯¹æœªè§é£æ ¼è¿›è¡Œä»»ä½•å¾®è°ƒçš„è¿åŠ¨é£æ ¼è¿ç§»ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Human motion data is inherently rich and complex, containing both semantic content and subtle stylistic features that are challenging to model. We propose a novel method for effective disentanglement of the style and content in human motion data to facilitate style transfer. Our approach is guided by the insight that content corresponds to coarse motion attributes while style captures the finer, expressive details. To model this hierarchy, we employ Residual Vector Quantized Variational Autoencoders (RVQ-VAEs) to learn a coarse-to-fine representation of motion. We further enhance the disentanglement by integrating codebook learning with contrastive learning and a novel information leakage loss to organize the content and the style across different codebooks. We harness this disentangled representation using our simple and effective inference-time technique Quantized Code Swapping, which enables motion style transfer without requiring any fine-tuning for unseen styles. Our framework demonstrates strong versatility across multiple inference applications, including style transfer, style removal, and motion blending.

</details>

---

### 32. [Document Reconstruction Unlocks Scalable Long-Context RLVR](https://arxiv.org/abs/2602.08237)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.08237`](https://arxiv.org/abs/2602.08237)
- ğŸ‘¥ ä½œè€…: Yao Xiao, Lei Wang, Yue Deng ç­‰9äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.08237.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒæ¡†æ¶ï¼Œç”¨äºæå‡å¤§è¯­è¨€æ¨¡å‹å¤„ç†é•¿ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ã€‚è™½ç„¶åº”ç”¨åœºæ™¯æ˜¯é€šç”¨æ–‡æ¡£é‡å»ºï¼Œä½†å…¶æ ¸å¿ƒæ–¹æ³•â€”â€”ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ï¼ˆæ­¤å¤„ä¸ºæ–‡æ¡£è¡¥å…¨ï¼‰ä¸Šçš„è¡¨ç°â€”â€”æ˜¯è®­ç»ƒå’Œä¼˜åŒ–â€œåŒ–å­¦å¤§æ¨¡å‹â€æˆ–ç”¨äºâ€œè´¨è°±ç»“æ„æ¨ç†â€çš„ä¸“ä¸šåŒ–è¯­è¨€/å¤šæ¨¡æ€æ¨¡å‹æ—¶å¯èƒ½é‡‡ç”¨çš„å…³é”®æŠ€æœ¯ä¹‹ä¸€ï¼Œç‰¹åˆ«æ˜¯å½“éœ€è¦æ¨¡å‹æ ¹æ®ä¸å®Œæ•´çš„åŒ–å­¦ä¿¡æ¯ï¼ˆå¦‚éƒ¨åˆ†è´¨è°±å³°æˆ–åˆ†å­æè¿°ï¼‰è¿›è¡Œæ¨ç†å’Œè¡¥å…¨æ—¶ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡ç ”ç©¶äº†ä¸€ç§æ— ç›‘ç£æ–¹æ³•æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œæ— éœ€æ˜‚è´µçš„äººå·¥æ ‡æ³¨æˆ–æ•™å¸ˆæ¨¡å‹çš„ç›‘ç£ã€‚å…·ä½“æ–¹æ³•æ˜¯ï¼šé¦–å…ˆåœ¨é•¿æ–‡æ¡£ä¸­ç”¨ç‰¹æ®Šå ä½ç¬¦æ›¿æ¢å‡ ä¸ªæ®µè½ï¼Œç„¶åé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒLLMsï¼Œé€šè¿‡ä»ä¸€ç»„å€™é€‰é€‰é¡¹ä¸­æ­£ç¡®è¯†åˆ«å’Œæ’åºç¼ºå¤±çš„æ®µè½æ¥é‡å»ºæ–‡æ¡£ã€‚è¿™ç§è®­ç»ƒèŒƒå¼ä½¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰å…¨å±€å™äº‹è¿è´¯æ€§ï¼Œä»è€Œæ˜¾è‘—æå‡é•¿ä¸Šä¸‹æ–‡æ€§èƒ½ã€‚ä½œè€…åœ¨ä¸¤ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè¿˜è¿›è¡Œäº†å¹¿æ³›çš„æ¶ˆèç ”ç©¶ï¼Œåˆ†æäº†å¥–åŠ±è®¾è®¡ã€æ•°æ®ç­–åˆ’ç­–ç•¥ã€è®­ç»ƒæ–¹æ¡ˆå’Œæ•°æ®ç¼©æ”¾æ•ˆåº”å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.

</details>

---

### 33. [Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation](https://arxiv.org/abs/2602.12125)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.12125`](https://arxiv.org/abs/2602.12125)
- ğŸ‘¥ ä½œè€…: Wenkai Yang, Weijie Liu, Ruobing Xie ç­‰6äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.12125.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯æ”¹è¿›å¤§è¯­è¨€æ¨¡å‹çš„è’¸é¦æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ç­–ç•¥è’¸é¦ã€‚æ¨¡å‹è’¸é¦æ˜¯æ„å»ºé«˜æ•ˆâ€œåŒ–å­¦å¤§æ¨¡å‹â€ï¼ˆä¾‹å¦‚ï¼Œå°†å¤§å‹åŒ–å­¦é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†å‹ç¼©åˆ°æ›´å°ã€æ›´æ˜“éƒ¨ç½²çš„æ¨¡å‹ä¸­ï¼‰å’Œä¸“ä¸šåŒ–â€œè´¨è°±ç»“æ„æ¨ç†â€æ¨¡å‹çš„å…³é”®æŠ€æœ¯ã€‚æœ¬æ–‡æå‡ºçš„å¹¿ä¹‰ç­–ç•¥è’¸é¦æ¡†æ¶ä¸ºä¼˜åŒ–è¿™ä¸€è¿‡ç¨‹æä¾›äº†æ–°çš„ç†è®ºè§†è§’å’Œå®ç”¨æ–¹æ³•ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡é¦–å…ˆä»ç†è®ºä¸Šè¯æ˜äº†ç­–ç•¥è’¸é¦ï¼ˆOPDï¼‰æ˜¯å¯†é›†KLçº¦æŸå¼ºåŒ–å­¦ä¹ çš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œå…¶ä¸­å¥–åŠ±å‡½æ•°å’ŒKLæ­£åˆ™åŒ–æ€»æ˜¯ç­‰æƒé‡ï¼Œä¸”å‚è€ƒæ¨¡å‹å¯ä»¥æ˜¯ä»»ä½•æ¨¡å‹ã€‚ç„¶åï¼Œä½œè€…æå‡ºäº†å¹¿ä¹‰ç­–ç•¥è’¸é¦ï¼ˆG-OPDï¼‰æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥çµæ´»çš„å‚è€ƒæ¨¡å‹å’Œæ§åˆ¶å¥–åŠ±é¡¹ç›¸å¯¹äºKLæ­£åˆ™åŒ–ç›¸å¯¹æƒé‡çš„å¥–åŠ±ç¼©æ”¾å› å­ï¼Œæ‰©å±•äº†æ ‡å‡†OPDç›®æ ‡ã€‚é€šè¿‡åœ¨æ•°å­¦æ¨ç†å’Œä»£ç ç”Ÿæˆä»»åŠ¡ä¸Šçš„ç»¼åˆå®éªŒï¼Œä½œè€…å¾—å‡ºäº†ä¸¤ä¸ªæ–°é¢–çš„è§è§£ï¼šï¼ˆ1ï¼‰å°†å¥–åŠ±ç¼©æ”¾å› å­è®¾ç½®ä¸ºå¤§äº1ï¼ˆå³å¥–åŠ±å¤–æ¨ï¼‰ï¼Œåœ¨å¹¿æ³›çš„å¸ˆç”Ÿè§„æ¨¡é…å¯¹ä¸­ consistently ä¼˜äºæ ‡å‡†OPDã€‚ï¼ˆ2ï¼‰åœ¨å¼ºåˆ°å¼±çš„è’¸é¦è®¾ç½®ä¸­ï¼Œé€šè¿‡é€‰æ‹©æ•™å¸ˆRLä¹‹å‰çš„åŸºæ¨¡å‹ä½œä¸ºå‚è€ƒæ¨¡å‹æ¥è¿›è¡Œå¥–åŠ±æ ¡æ­£ï¼Œå¯ä»¥è·å¾—æ›´å‡†ç¡®çš„å¥–åŠ±ä¿¡å·å¹¶è¿›ä¸€æ­¥æé«˜è’¸é¦æ€§èƒ½ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.

</details>

---

### 34. [Symmetry in language statistics shapes the geometry of model representations](https://arxiv.org/abs/2602.15029)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.15029`](https://arxiv.org/abs/2602.15029)
- ğŸ‘¥ ä½œè€…: Dhruva Karkada, Daniel J. Korchinski, Andres Nava ç­‰5äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.15029.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯æ¢ç´¢å’Œè§£é‡Šå¤§è¯­è¨€æ¨¡å‹å†…éƒ¨è¡¨ç¤ºçš„å‡ ä½•ç»“æ„åŠå…¶ä¸æ•°æ®ç»Ÿè®¡å¯¹ç§°æ€§çš„å…³ç³»ã€‚è™½ç„¶ç ”ç©¶å¯¹è±¡æ˜¯é€šç”¨è¯­è¨€æ¨¡å‹ï¼Œä½†å…¶æ­ç¤ºçš„è¡¨ç¤ºå­¦ä¹ åŸç†ï¼ˆå¯¹ç§°æ€§è¯±å¯¼å‡ ä½•ç»“æ„ï¼‰å¯¹äºç†è§£å’Œè®¾è®¡â€œåŒ–å­¦å¤§æ¨¡å‹â€çš„åˆ†å­è¡¨ç¤ºï¼ˆä¾‹å¦‚ï¼Œå‘¨æœŸè¡¨å…ƒç´ çš„å‡ ä½•æ’åˆ—ã€å®˜èƒ½å›¢çš„å¯¹ç§°æ€§ï¼‰ä»¥åŠâ€œè´¨è°±ç»“æ„æ¨ç†â€ä¸­è´¨è°±ç‰¹å¾ä¸åˆ†å­å­ç»“æ„ä¹‹é—´çš„æ˜ å°„å…³ç³»å…·æœ‰é‡è¦çš„å¯å‘æ„ä¹‰ã€‚è¿™å±äºæœºå™¨å­¦ä¹ åŸºç¡€ç†è®ºä¸åŒ–å­¦ä¿¡æ¯å­¦åº”ç”¨çš„äº¤å‰ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æ—¨åœ¨è§£é‡Šè¯­è¨€æ¨¡å‹å†…éƒ¨è¡¨ç¤ºä¸­è§‚å¯Ÿåˆ°çš„å‡ ä½•ç»“æ„ï¼ˆå¦‚æœˆä»½ç»„ç»‡æˆåœ†å½¢ï¼Œå¹´ä»½å½¢æˆä¸€ç»´æµå½¢ï¼‰ã€‚ä½œè€…é¦–å…ˆå±•ç¤ºäº†è¯­è¨€ç»Ÿè®¡ä¸­å­˜åœ¨å¹³ç§»å¯¹ç§°æ€§ï¼ˆä¾‹å¦‚ï¼Œä»»æ„ä¸¤ä¸ªæœˆåœ¨æ–‡æœ¬ä¸­å…±ç°çš„é¢‘ç‡ä»…å–å†³äºå®ƒä»¬ä¹‹é—´çš„æ—¶é—´é—´éš”ï¼‰ã€‚ä»–ä»¬è¯æ˜äº†è¿™ç§å¯¹ç§°æ€§æ”¯é…ç€é«˜ç»´è¯åµŒå…¥æ¨¡å‹ä¸­çš„å‡ ä½•ç»“æ„ï¼Œå¹¶è§£æåœ°æ¨å¯¼äº†è¯è¡¨ç¤ºçš„æµå½¢å‡ ä½•ã€‚è¿™äº›é¢„æµ‹ä¸å¤§å‹æ–‡æœ¬åµŒå…¥æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å®è¯ç»“æœç›¸åŒ¹é…ã€‚æ­¤å¤–ï¼Œå³ä½¿ç›¸å…³ç»Ÿè®¡å—åˆ°æ‰°åŠ¨ï¼Œåœ¨ä¸­ç­‰åµŒå…¥ç»´åº¦ä¸‹ï¼Œè¡¨ç¤ºå‡ ä½•ä»ç„¶ä¿æŒç¨³å¥ã€‚ä½œè€…è¯æ˜ï¼Œå½“å…±ç°ç»Ÿè®¡ç”±æ½œåœ¨å˜é‡æ§åˆ¶æ—¶ï¼Œè¿™ç§ç¨³å¥æ€§ä¼šè‡ªç„¶å‡ºç°ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¡¨ç¤ºæµå½¢å…·æœ‰æ™®éçš„èµ·æºï¼šè‡ªç„¶æ•°æ®ç»Ÿè®¡ä¸­çš„å¯¹ç§°æ€§ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

The internal representations learned by language models consistently exhibit striking geometric structure: calendar months organize into a circle, historical years form a smooth one-dimensional manifold, and cities' latitudes and longitudes can be decoded using a linear probe. To explain this neural code, we first show that language statistics exhibit translation symmetry (for example, the frequency with which any two months co-occur in text depends only on the time interval between them). We prove that this symmetry governs these geometric structures in high-dimensional word embedding models, and we analytically derive the manifold geometry of word representations. These predictions empirically match large text embedding models and large language models. Moreover, the representational geometry persists at moderate embedding dimension even when the relevant statistics are perturbed (e.g., by removing all sentences in which two months co-occur). We prove that this robustness emerges naturally when the co-occurrence statistics are controlled by an underlying latent variable. These results suggest that representational manifolds have a universal origin: symmetry in the statistics of natural data.

</details>

---

### 35. [Understanding protein function with a multimodal retrieval-augmented foundation model](https://arxiv.org/abs/2508.04724)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2508.04724`](https://arxiv.org/abs/2508.04724)
- ğŸ‘¥ ä½œè€…: Timothy Fei Truong Jr, Tristan Bepler
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2508.04724.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªç”¨äºè›‹ç™½è´¨åºåˆ—ç†è§£å’Œè®¾è®¡çš„åŒ–å­¦å¤§æ¨¡å‹ï¼ˆPoET-2ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„åŒ–å­¦ä¿¡æ¯å­¦é¢†åŸŸçš„å¤§æ¨¡å‹åº”ç”¨ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†PoET-2ï¼Œä¸€ä¸ªå¤šæ¨¡æ€ã€æ£€ç´¢å¢å¼ºçš„è›‹ç™½è´¨åŸºç¡€æ¨¡å‹ã€‚å®ƒé€šè¿‡ç»“åˆå®¶æ—ç‰¹å¼‚æ€§è¿›åŒ–çº¦æŸçš„ä¸Šä¸‹æ–‡å­¦ä¹ å’Œå¯é€‰çš„ç»“æ„æ¡ä»¶ï¼Œæ¥å­¦ä¹ è›‹ç™½è´¨åºåˆ—çš„ç”Ÿæˆåˆ†å¸ƒã€‚è¯¥æ¨¡å‹é‡‡ç”¨åˆ†å±‚Transformerç¼–ç å™¨å’Œå…·æœ‰å› æœä¸æ©ç è¯­è¨€å»ºæ¨¡ç›®æ ‡çš„åŒè§£ç å™¨æ¶æ„ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å®Œå…¨ç”Ÿæˆå’ŒåŒå‘è¡¨ç¤ºå­¦ä¹ ä¸¤ç§æ¨¡å¼ä¸‹å·¥ä½œã€‚PoET-2åœ¨é›¶æ ·æœ¬å˜ä½“æ•ˆåº”é¢„æµ‹ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤šé‡çªå˜å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„æ’å…¥ç¼ºå¤±çªå˜æ–¹é¢ã€‚åœ¨ç›‘ç£è®¾ç½®ä¸‹ï¼ŒPoET-2çš„åµŒå…¥åœ¨å­¦ä¹ å’Œé¢„æµ‹åºåˆ—-åŠŸèƒ½å…³ç³»æ–¹é¢ä¼˜äºå…ˆå‰çš„æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å°æ•°æ®é›†ä¸Šã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†å°†æ£€ç´¢å¢å¼ºä¸å¤šæ¨¡æ€ã€ä»¥å®¶æ—ä¸ºä¸­å¿ƒçš„å»ºæ¨¡ç›¸ç»“åˆï¼Œå¯¹äºæ¨è¿›è›‹ç™½è´¨åŸºç¡€æ¨¡å‹çš„ç›Šå¤„ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Protein language models (PLMs) learn probability distributions over natural protein sequences. By learning from hundreds of millions of natural protein sequences, protein understanding and design capabilities emerge. Recent works have shown that scaling these models improves structure prediction, but does not seem to improve mutation understanding and representation quality for protein function prediction. We introduce PoET-2, a multimodal, retrieval-augmented protein foundation model that incorporates in-context learning of family-specific evolutionary constraints with optional structure conditioning to learn generative distributions over protein sequences. PoET-2 uses a hierarchical transformer encoder that is equivariant to sequence context ordering and a dual decoder architecture with both causal and masked language modeling objectives, allowing PoET-2 to operate in both fully generative and bidirectional representation learning modes. PoET-2 achieves state-of-the-art performance on zero-shot variant effect prediction, excelling at scoring variants with multiple mutations and challenging indel mutations. In supervised settings, PoET-2 embeddings outperform previous methods for learning sequence-function relationships, especially with small datasets. This work highlights the benefits of combining retrieval augmentation with multimodal, family-centric modeling for advancing protein foundation models.

</details>

---

### 36. [TokEye: Fast Signal Extraction for Fluctuating Time Series via Offline Self-Supervised Learning From Fusion Diagnostics to Bioacoustics](https://arxiv.org/abs/2602.20317)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.20317`](https://arxiv.org/abs/2602.20317)
- ğŸ‘¥ ä½œè€…: Nathaniel Chen, Kouroche Bouchiat, Peter Steiner ç­‰9äºº
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.20317.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯å¼€å‘ä¸€ä¸ªä»å¤šè¯Šæ–­ä¿¡å·ï¼ˆåŒ…æ‹¬è´¨è°±ç›¸å…³çš„è¯Šæ–­ï¼Œå¦‚æŸå‘å°„å…‰è°±ï¼‰ä¸­è‡ªåŠ¨æå–æ¨¡å¼çš„æ¡†æ¶ã€‚è¿™ç›´æ¥æ¶‰åŠè´¨è°±åˆ†æé¢†åŸŸï¼ˆä½œä¸ºèšå˜ç­‰ç¦»å­ä½“è¯Šæ–­çš„ä¸€éƒ¨åˆ†ï¼‰å’Œç”¨äºä¿¡å·å¤„ç†çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä¸â€œè´¨è°±ç»“æ„æ¨ç†â€ä¸»é¢˜ç›¸å…³ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªâ€œä¿¡å·ä¼˜å…ˆâ€çš„è‡ªç›‘ç£æ¡†æ¶ï¼Œç”¨äºä»å„ç§ä¼ æ„Ÿå™¨çš„é«˜å™ªå£°æ—¶é¢‘æ•°æ®ä¸­è‡ªåŠ¨æå–ç›¸å¹²å’Œç¬æ€æ¨¡å¼ã€‚è¯¥æ–¹æ³•å¼€å‘äº†ä¸€ç§é€šç”¨å·¥å…·ï¼Œé€šè¿‡åœ¨å¤šé€šé“ä¿¡å·å¤„ç†ä¸­é‡‡ç”¨éçº¿æ€§æœ€ä¼˜æŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨å¿«é€Ÿç¥ç»ç½‘ç»œä»£ç†ï¼Œä»DIII-Dæ‰˜å¡é©¬å…‹çš„å¿«ç£ã€ç”µå­å›æ—‹è¾å°„ã€CO2å¹²æ¶‰ä»ªå’ŒæŸå‘å°„å…‰è°±æµ‹é‡ä¸­æå–ç›¸å¹²ã€å‡†ç›¸å¹²å’Œç¬æ€æ¨¡å¼ã€‚è¯¥æ¡†æ¶åœ¨DIII-Dã€TJ-IIå’Œéèšå˜è°±å›¾æ•°æ®ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚æ¨ç†å»¶è¿Ÿä¸º0.5ç§’ï¼Œä½¿å¾—è¯¥æ¡†æ¶èƒ½å¤Ÿå®ç°å®æ—¶æ¨¡å¼è¯†åˆ«å’Œå¤§è§„æ¨¡è‡ªåŠ¨åŒ–æ•°æ®åº“ç”Ÿæˆï¼Œç”¨äºå…ˆè¿›çš„ç­‰ç¦»å­ä½“æ§åˆ¶ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

Next-generation fusion facilities like ITER face a "data deluge," generating petabytes of multi-diagnostic signals daily that challenge manual analysis. We present a "signals-first" self-supervised framework for the automated extraction of coherent and transient modes from high-noise time-frequency data across a variety of sensors. We also develop a general-purpose method and tool for extracting coherent, quasi-coherent, and transient modes for fluctuation measurements in tokamaks by employing non-linear optimal techniques in multichannel signal processing with a fast neural network surrogate on fast magnetics, electron cyclotron emission, CO2 interferometers, and beam emission spectroscopy measurements from DIII-D. Results are tested on data from DIII-D, TJ-II, and non-fusion spectrograms. With an inference latency of 0.5 seconds, this framework enables real-time mode identification and large-scale automated database generation for advanced plasma control. Repository is in this https URL .

</details>

---

### 37. [Not Just How Much, But Where: Decomposing Epistemic Uncertainty into Per-Class Contributions](https://arxiv.org/abs/2602.21160)

**åŸºæœ¬ä¿¡æ¯**

- ğŸ”— arXiv: [`2602.21160`](https://arxiv.org/abs/2602.21160)
- ğŸ‘¥ ä½œè€…: Mame Diarra Toure, David A. Stephens
- ğŸ“„ PDF: [ä¸‹è½½](https://arxiv.org/pdf/2602.21160.pdf)

**ğŸ’¡ ç›¸å…³æ€§åˆ†æ**

æ»¡è¶³æ ‡å‡†1ï¼šè®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶å†…å®¹æ˜¯æ”¹è¿›è´å¶æ–¯æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ã€‚è™½ç„¶åº”ç”¨é¢†åŸŸæ˜¯åŒ»å­¦å›¾åƒï¼Œä½†å…¶æå‡ºçš„åˆ†è§£è®¤çŸ¥ä¸ç¡®å®šæ€§çš„æ–¹æ³•å…·æœ‰æ™®é€‚æ€§ï¼Œå¯ä»¥åº”ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦æˆ–è´¨è°±åˆ†æä¸­çš„åˆ†ç±»æˆ–å›å½’é—®é¢˜ï¼Œä»¥æ›´å¥½åœ°ç†è§£å’Œåˆ©ç”¨å¤§æ¨¡å‹ï¼ˆå¦‚ç”¨äºå…‰è°±è§£é‡Šçš„æ¨¡å‹ï¼‰çš„é¢„æµ‹ä¸ç¡®å®šæ€§ã€‚

**ğŸ“– ä¸­æ–‡æ‘˜è¦**

åœ¨å®‰å…¨å…³é”®åˆ†ç±»ä¸­ï¼Œå¤±è´¥çš„ä»£ä»·é€šå¸¸æ˜¯ä¸å¯¹ç§°çš„ï¼Œç„¶è€Œè´å¶æ–¯æ·±åº¦å­¦ä¹ ç”¨å•ä¸€æ ‡é‡äº’ä¿¡æ¯ï¼ˆMIï¼‰æ¥æ€»ç»“è®¤çŸ¥ä¸ç¡®å®šæ€§ï¼Œæ— æ³•åŒºåˆ†æ¨¡å‹çš„æœªçŸ¥æ€§æ¶‰åŠçš„æ˜¯è‰¯æ€§ç±»åˆ«è¿˜æ˜¯å®‰å…¨å…³é”®ç±»åˆ«ã€‚æœ¬æ–‡æå‡ºå°†MIåˆ†è§£ä¸ºæ¯ä¸ªç±»åˆ«çš„å‘é‡C_k(x)ã€‚è¯¥åˆ†è§£æºäºç†µçš„äºŒé˜¶æ³°å‹’å±•å¼€ï¼›1/Î¼_kæƒé‡æ ¡æ­£äº†è¾¹ç•ŒæŠ‘åˆ¶ï¼Œå¹¶ä½¿C_kåœ¨ç¨€æœ‰å’Œå¸¸è§ç±»åˆ«ä¹‹é—´å…·æœ‰å¯æ¯”æ€§ã€‚é€šè¿‡æ„é€ ï¼Œâˆ‘_k C_k â‰ˆ MIï¼Œå¹¶ä¸”ä¼´éšçš„ååº¦è¯Šæ–­æ ‡è®°äº†è¿‘ä¼¼é€€åŒ–çš„è¾“å…¥ã€‚åœ¨æè¿°äº†C_kçš„å…¬ç†æ€§è´¨åï¼Œæˆ‘ä»¬åœ¨ä¸‰ä¸ªä»»åŠ¡ä¸ŠéªŒè¯äº†å®ƒï¼šï¼ˆiï¼‰ç³–å°¿ç—…è§†ç½‘è†œç—…å˜çš„é€‰æ‹©æ€§é¢„æµ‹ï¼Œå…¶ä¸­å…³é”®ç±»åˆ«çš„C_kå°†é€‰æ‹©æ€§é£é™©æ¯”MIé™ä½äº†34.7%ï¼Œæ¯”æ–¹å·®åŸºçº¿é™ä½äº†56.2%ï¼›ï¼ˆiiï¼‰ä¸´åºŠå’Œå›¾åƒåŸºå‡†ä¸Šçš„åˆ†å¸ƒå¤–æ£€æµ‹ï¼Œå…¶ä¸­âˆ‘_k C_kè¾¾åˆ°äº†æœ€é«˜çš„AUROCï¼Œå¹¶ä¸”æ¯ä¸ªç±»åˆ«çš„è§†å›¾æš´éœ²äº†MIä¸å¯è§çš„ä¸å¯¹ç§°åç§»ï¼›ï¼ˆiiiï¼‰å—æ§çš„æ ‡ç­¾å™ªå£°ç ”ç©¶ï¼Œå…¶ä¸­åœ¨ç«¯åˆ°ç«¯è´å¶æ–¯è®­ç»ƒä¸‹ï¼Œâˆ‘_k C_kå¯¹æ³¨å…¥çš„å¶ç„¶å™ªå£°çš„æ•æ„Ÿæ€§ä½äºMIï¼Œè€Œä¸¤ç§åº¦é‡åœ¨è¿ç§»å­¦ä¹ ä¸‹éƒ½ä¼šé€€åŒ–ã€‚

<details>
<summary><b>ğŸ” æŸ¥çœ‹åŸæ–‡æ‘˜è¦</b></summary>

In safety-critical classification, the cost of failure is often asymmetric, yet Bayesian deep learning summarises epistemic uncertainty with a single scalar, mutual information (MI), that cannot distinguish whether a model's ignorance involves a benign or safety-critical class. We decompose MI into a per-class vector $C_k(x)=\sigma_k^{2}/(2\mu_k)$, with $\mu_k{=}\mathbb{E}[p_k]$ and $\sigma_k^2{=}\mathrm{Var}[p_k]$ across posterior samples. The decomposition follows from a second-order Taylor expansion of the entropy; the $1/\mu_k$ weighting corrects boundary suppression and makes $C_k$ comparable across rare and common classes. By construction $\sum_k C_k \approx \mathrm{MI}$, and a companion skewness diagnostic flags inputs where the approximation degrades. After characterising the axiomatic properties of $C_k$, we validate it on three tasks: (i) selective prediction for diabetic retinopathy, where critical-class $C_k$ reduces selective risk by 34.7\% over MI and 56.2\% over variance baselines; (ii) out-of-distribution detection on clinical and image benchmarks, where $\sum_k C_k$ achieves the highest AUROC and the per-class view exposes asymmetric shifts invisible to MI; and (iii) a controlled label-noise study in which $\sum_k C_k$ shows less sensitivity to injected aleatoric noise than MI under end-to-end Bayesian training, while both metrics degrade under transfer learning. Across all tasks, the quality of the posterior approximation shapes uncertainty at least as strongly as the choice of metric, suggesting that how uncertainty is propagated through the network matters as much as how it is measured.

</details>

---

## ğŸ“Š æ•°æ®ç»Ÿè®¡
- ç´¯è®¡è¿è¡Œå¤©æ•°ï¼š1
- ç´¯è®¡è®ºæ–‡æ•°é‡ï¼š37

## ğŸ“ å†å²è®°å½•

> æš‚æ— å†å²æ•°æ®

